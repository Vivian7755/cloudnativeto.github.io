[{"categories":null,"contents":"招聘对象 本次社会招聘的要求为不限工作年限的同学。\n岗位类型 研发类：容器、kubernetes、service mesh等云原生方向，Go、C/C++、Java等语言。\n中信银行介绍 本行成立于1987年，是中国改革开放中最早成立的新兴商业银行之一，是中国最早参与国内外金融市场融资的商业银行，并以屡创中国现代金融史上多个第一而蜚声海内外，为中国经济建设做出了积极贡献。2007年4月，本行实现在上海证券交易所和香港联合交易所A+H股同步上市。\n本行以建设成为有担当、有温度、有特色、有尊严的最佳综合金融服务企业为发展愿景，充分发挥中信集团金融与实业并举的独特竞争优势，坚持“以客为尊”，秉承“平安中信、合规经营、科技立行、服务实体、市场导向、创造价值”的经营理念，向企业客户和机构客户提供公司银行业务、国际业务、金融市场业务、机构业务、投资银行业务、交易银行业务、托管业务等综合金融解决方案，向个人客户提供零售银行、信用卡、消费金融、财富管理、私人银行、出国金融、电子银行等多元化金融产品及服务，全方位满足企业、机构及个人客户的综合金融服务需求。\n截至2019年末，本行在国内151个大中城市设有1,401家营业网点，同时在境内外下设6家附属机构，包括中信国际金融控股有限公司、信银（香港）投资有限公司、中信金融租赁有限公司、浙江临安中信村镇银行股份有限公司、中信百信银行股份有限公司和哈萨克斯坦阿尔金银行。其中，中信国际金融控股有限公司子公司中信银行（国际）有限公司在香港、澳门、纽约、洛杉矶、新加坡和中国内地设有38家营业网点。信银（香港）投资有限公司在香港和境内设有3家子公司。中信百信银行股份有限公司为本行与百度公司发起设立的国内首家具有独立法人资格的直销银行。阿尔金银行在哈萨克斯坦设有7家营业网点和1个私人银行中心。\n本行坚持服务实体经济，稳健经营，与时俱进。经过30余年的发展，本行已成为一家总资产规模超6万亿元、员工人数近6万名，具有强大综合实力和品牌竞争力的金融集团。2019年，本行在英国《银行家》杂志“全球银行品牌500强排行榜”中排名第19位；本行一级资本在英国《银行家》杂志“世界1000家银行排名”中排名第26位。\n岗位描述 1、负责部分功能或非功能设计方案的编写、评审和落地。参与部署方案的制定和相关投产。\n2、负责对复杂关键技术问题进行技术攻关；负责新增组件的设计、开发、单元测试工作；负责对开源软件进行扩展、优化工作；参与代码评审工作。\n3、参与性能测试、高可用测试、混沌测试等。\n4、负责Service Mesh平台的推广，对应用设计、开发和部署提供技术支持，参与制定应用接入流程和技术规范。\n5、指导、支持初级工程师，培养新人。\n岗位要求 1、有超过3年的复杂软件系统的设计、开发经验。\n2、有较强的Go语言高并发编程经验或熟悉C++编程。\n3、熟悉Docker,Kubernates，了解Service Mesh。\n4、熟悉Java,Spring Cloud。\n5、有过对较为复杂的开源软件从代码级别掌控的经验。\n内推方式 欢迎邮件简历并说明对应的职位，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/social-citic-servicemesh/","tags":null,"title":"[社会招聘] 中信软开Service Mesh研发工程师（中级，高级）"},{"categories":null,"contents":"招聘对象 本次社会招聘的要求为不限工作年限的同学。\n中信银行介绍 本行成立于1987年，是中国改革开放中最早成立的新兴商业银行之一，是中国最早参与国内外金融市场融资的商业银行，并以屡创中国现代金融史上多个第一而蜚声海内外，为中国经济建设做出了积极贡献。2007年4月，本行实现在上海证券交易所和香港联合交易所A+H股同步上市。\n本行以建设成为有担当、有温度、有特色、有尊严的最佳综合金融服务企业为发展愿景，充分发挥中信集团金融与实业并举的独特竞争优势，坚持“以客为尊”，秉承“平安中信、合规经营、科技立行、服务实体、市场导向、创造价值”的经营理念，向企业客户和机构客户提供公司银行业务、国际业务、金融市场业务、机构业务、投资银行业务、交易银行业务、托管业务等综合金融解决方案，向个人客户提供零售银行、信用卡、消费金融、财富管理、私人银行、出国金融、电子银行等多元化金融产品及服务，全方位满足企业、机构及个人客户的综合金融服务需求。\n截至2019年末，本行在国内151个大中城市设有1,401家营业网点，同时在境内外下设6家附属机构，包括中信国际金融控股有限公司、信银（香港）投资有限公司、中信金融租赁有限公司、浙江临安中信村镇银行股份有限公司、中信百信银行股份有限公司和哈萨克斯坦阿尔金银行。其中，中信国际金融控股有限公司子公司中信银行（国际）有限公司在香港、澳门、纽约、洛杉矶、新加坡和中国内地设有38家营业网点。信银（香港）投资有限公司在香港和境内设有3家子公司。中信百信银行股份有限公司为本行与百度公司发起设立的国内首家具有独立法人资格的直销银行。阿尔金银行在哈萨克斯坦设有7家营业网点和1个私人银行中心。\n本行坚持服务实体经济，稳健经营，与时俱进。经过30余年的发展，本行已成为一家总资产规模超6万亿元、员工人数近6万名，具有强大综合实力和品牌竞争力的金融集团。2019年，本行在英国《银行家》杂志“全球银行品牌500强排行榜”中排名第19位；本行一级资本在英国《银行家》杂志“世界1000家银行排名”中排名第26位。\n岗位描述 1、参与新一代技术组件的设计和开发工作。\n2、使用并扩展优化相关开源软件。\n岗位要求 1、有较强的Java语言、Spring Boot,Spring Cloud编程能力。\n2、对缓存、多线程、高并发、性能优化、redis、netty、分布式事务有经验者优先。\n3、有过对较为复杂的开源软件从代码级别掌控的经验。\n内推方式 欢迎邮件简历并说明对应的职位，我们将尽快安排面试。\n","permalink":"https://cloudnative.to/job/social-citic-component/","tags":null,"title":"[社会招聘] 中信软开技术组件研发工程师（初级、中级，高级）"},{"categories":["BPF"],"contents":"由范老师和我一起翻译的图书 《Linux内核观测技术BPF》 已经在 JD 上有现货，欢迎感兴趣 BPF 技术的同学选购。链接地址 https://item.jd.com/72110825905.html\n“eBPF 是我见过的 Linux 中最神奇的技术，没有之一，已成为 Linux 内核中顶级子模块，从 tcpdump 中用作网络包过滤的经典 cbpf，到成为通用 Linux 内核技术的 eBPF，已经完成华丽蜕变，为应用与神奇的内核打造了一座桥梁，在系统跟踪、观测、性能调优、安全和网络等领域发挥重要的角色。为 Service Mesh 打造了具备 API 感知和安全高效的容器网络方案 Cilium，其底层正是基于 eBPF 技术”\n1. BPF BPF（Berkeley Packet Filter ），中文翻译为伯克利包过滤器，是类 Unix 系统上数据链路层的一种原始接口，提供原始链路层封包的收发。1992 年，Steven McCanne 和 Van Jacobson 写了一篇名为《BSD数据包过滤：一种新的用户级包捕获架构》的论文。在文中，作者描述了他们如何在 Unix 内核实现网络数据包过滤，这种新的技术比当时最先进的数据包过滤技术快 20 倍。BPF 在数据包过滤上引入了两大革新：\n  一个新的虚拟机 (VM) 设计，可以有效地工作在基于寄存器结构的 CPU 之上；\n  应用程序使用缓存只复制与过滤数据包相关的数据，不会复制数据包的所有信息。这样可以最大程度地减少BPF 处理的数据；\n  由于这些巨大的改进，所有的 Unix 系统都选择采用 BPF 作为网络数据包过滤技术，直到今天，许多 Unix 内核的派生系统中（包括 Linux 内核）仍使用该实现。\ntcpdump 的底层采用 BPF 作为底层包过滤技术，我们可以在命令后面增加 ”-d“ 来查看 tcpdump 过滤条件的底层汇编指令。\n$ tcpdump -d \u0026#39;ip and tcp port 8080\u0026#39; (000) ldh [12] (001) jeq #0x800 jt 2\tjf 12 (002) ldb [23] (003) jeq #0x6 jt 4\tjf 12 (004) ldh [20] (005) jset #0x1fff jt 12\tjf 6 (006) ldxb 4*([14]\u0026amp;0xf) (007) ldh [x + 14] (008) jeq #0x1f90 jt 11\tjf 9 (009) ldh [x + 16] (010) jeq #0x1f90 jt 11\tjf 12 (011) ret #262144 (012) ret #0 图 1-1 tcpdump 底层汇编指令\nBPF 工作在内核层，BPF 的架构图如下 [来自于bpf-usenix93]：\n图 1-2 tcpdump 运行架构\n2. eBPF 2.1 eBPF 介绍 2014 年初，Alexei Starovoitov 实现了 eBPF（extended Berkeley Packet Filter）。经过重新设计，eBPF 演进为一个通用执行引擎，可基于此开发性能分析工具、软件定义网络等诸多场景。eBPF 最早出现在 3.18 内核中，此后原来的 BPF 就被称为经典 BPF，缩写 cBPF（classic BPF），cBPF 现在已经基本废弃。现在，Linux 内核只运行 eBPF，内核会将加载的 cBPF 字节码透明地转换成 eBPF 再执行。\neBPF 新的设计针对现代硬件进行了优化，所以 eBPF 生成的指令集比旧的 BPF 解释器生成的机器码执行得更快。扩展版本也增加了虚拟机中的寄存器数量，将原有的 2 个 32 位寄存器增加到 10 个 64 位寄存器。由于寄存器数量和宽度的增加，开发人员可以使用函数参数自由交换更多的信息，编写更复杂的程序。总之，这些改进使 eBPF 版本的速度比原来的 BPF 提高了 4 倍。\n   维度 cBPF eBPF     内核版本 Linux 2.1.75（1997年） Linux 3.18（2014年）[4.x for kprobe/uprobe/tracepoint/perf-event]   寄存器数目 2个：A, X 10个： R0–R9, 另外 R10 是一个只读的帧指针   寄存器宽度 32位 64位   存储 16 个内存位: M[0–15] 512 字节堆栈，无限制大小的 “map” 存储   限制的内核调用 非常有限，仅限于 JIT 特定 有限，通过 bpf_call 指令调用   目标事件 数据包、 seccomp-BPF 数据包、内核函数、用户函数、跟踪点 PMCs 等    表格 1-1 cBPF 与 eBPF 对比\n eBPF 在 Linux 3.18 版本以后引入，并不代表只能在内核 3.18+ 版本上运行，低版本的内核升级到最新也可以使用 eBPF 能力，只是可能部分功能受限，比如我就是在 Linux 发行版本 CentOS Linux release 7.7.1908 内核版本 3.10.0-1062.9.1.el7.x86_64 上运行 eBPF 在生产环境上搜集和排查网络问题。\n eBPF 实现的最初目标是优化处理网络过滤器的内部 BPF 指令集。当时，BPF 程序仍然限于内核空间使用，只有少数用户空间程序可以编写内核处理的 BPF 过滤器，例如：tcpdump和 seccomp。时至今日，这些程序仍基于旧的 BPF 解释器生成字节码，但内核中会将这些指令转换为高性能的表示。\n2014 年 6 月，eBPF 扩展到用户空间，这也成为了 BPF 技术的转折点。 正如 Alexei 在提交补丁的注释中写到：“这个补丁展示了 eBPF 的潜力”。当前，eBPF 不再局限于网络栈，已经成为内核顶级的子系统。eBPF 程序架构强调安全性和稳定性，看上去更像内核模块，但与内核模块不同，eBPF 程序不需要重新编译内核，并且可以确保 eBPF 程序运行完成，而不会造成系统的崩溃。\n图 2-1 BPF 架构图\n简述概括， eBPF 是一套通用执行引擎，提供了可基于系统或程序事件高效安全执行特定代码的通用能力，通用能力的使用者不再局限于内核开发者；eBPF 可由执行字节码指令、存储对象和 Helper 帮助函数组成，字节码指令在内核执行前必须通过 BPF 验证器 Verfier 的验证，同时在启用 BPF JIT 模式的内核中，会直接将字节码指令转成内核可执行的本地指令运行。\n同时，eBPF 也逐渐在观测（跟踪、性能调优等）、安全和网络等领域发挥重要的角色。Facebook、NetFlix 、CloudFlare 等知名互联网公司内部广泛采用基于 eBPF 技术的各种程序用于性能分析、排查问题、负载均衡、防范 DDoS 攻击，据相关信息显示在 Facebook 的机器上内置一系列 eBPF 的相关工具。\n相对于系统的性能分析和观测，eBPF 技术在网络技术中的表现，更是让人眼前一亮，BPF 技术与 XDP（eXpress Data Path） 和 TC（Traffic Control） 组合可以实现功能更加强大的网络功能，更可为 SDN 软件定义网络提供基础支撑。XDP 只作用与网络包的 Ingress 层面，BPF 钩子位于网络驱动中尽可能早的位置，无需进行原始包的复制就可以实现最佳的数据包处理性能，挂载的 BPF 程序是运行过滤的理想选择，可用于丢弃恶意或非预期的流量、进行 DDOS 攻击保护等场景；而 TC Ingress 比 XDP 技术处于更高层次的位置，BPF 程序在 L3 层之前运行，可以访问到与数据包相关的大部分元数据，是本地节点处理的理想的地方，可以用于流量监控或者 L3/L4 的端点策略控制，同时配合 TC egress 则可实现对于容器环境下更高维度和级别的网络结构。\n图 2-2 XDP 技术架构\neBPF 相关的知名的开源项目包括但不限于以下：\n Facebook 高性能 4 层负载均衡器 Katran； Cilium 为下一代微服务 ServiceMesh 打造了具备API感知和安全高效的容器网络方案；底层主要使用 XDP 和 TC 等相关技术； IO Visor 项目开源的 BCC、 BPFTrace 和 Kubectl-Trace： BCC 提供了更高阶的抽象，可以让用户采用 Python、C++ 和 Lua 等高级语言快速开发 BPF 程序；BPFTrace 采用类似于 awk 语言快速编写 eBPF 程序；Kubectl-Trace 则提供了在 kubernetes 集群中使用 BPF 程序调试的方便操作； CloudFlare 公司开源的 eBPF Exporter 和 bpf-tools：eBPF Exporter 将 eBPF 技术与监控 Prometheus 紧密结合起来；bpf-tools 可用于网络问题分析和排查；  越来越多的基于 eBPF 的项目如雨后脆笋一样开始蓬勃发展，而且逐步在社区中异军突起，成为一道风景线。比如 IO Visor 项目的 BCC 工具，为性能分析和观察提供了更加丰富的工具集：图片来源\n图 2-3 Linux bcc/BPF 观测工具\n同时，IO Visor 的 bpf-docs 包含了日常的文档，可以用于学习。\n 由于 eBPF 还在快速发展期，内核中的功能也日趋增强，一般推荐基于Linux 4.4+ (4.9 以上会更好) 内核的来使用 eBPF。部分 Linux Event 和 BPF 版本支持见下图：\n图 2-4 Linux 事件和 BPF 版本支持\n 2.2 eBPF 架构（观测） 基于 Linux 系统的观测工具中，eBPF 有着得天独厚的优势，高效、生产安全且内核中内置，特别的可以在内核中完成数据分析聚合比如直方图，与将数据发送到用户空间分析聚合相比，能够节省大量的数据复制传递带来的 CPU 消耗。\neBPF 整体结构图如下：\n图 2-5 eBPF 观测架构\neBPF 分为用户空间程序和内核程序两部分：\n 用户空间程序负责加载 BPF 字节码至内核，如需要也会负责读取内核回传的统计信息或者事件详情； 内核中的 BPF 字节码负责在内核中执行特定事件，如需要也会将执行的结果通过 maps 或者 perf-event 事件发送至用户空间；  其中用户空间程序与内核 BPF 字节码程序可以使用 map 结构实现双向通信，这为内核中运行的 BPF 字节码程序提供了更加灵活的控制。\n用户空间程序与内核中的 BPF 字节码交互的流程主要如下：\n 我们可以使用 LLVM 或者 GCC 工具将编写的 BPF 代码程序编译成 BPF 字节码； 然后使用加载程序 Loader 将字节码加载至内核；内核使用验证器（verfier） 组件保证执行字节码的安全性，以避免对内核造成灾难，在确认字节码安全后将其加载对应的内核模块执行；BPF 观测技术相关的程序程序类型可能是 kprobes/uprobes/tracepoint/perf_events 中的一个或多个，其中：  kprobes：实现内核中动态跟踪。 kprobes 可以跟踪到 Linux 内核中的导出函数入口或返回点，但是不是稳定 ABI 接口，可能会因为内核版本变化导致，导致跟踪失效。 uprobes：用户级别的动态跟踪。与 kprobes 类似，只是跟踪用户程序中的函数。 tracepoints：内核中静态跟踪。tracepoints 是内核开发人员维护的跟踪点，能够提供稳定的 ABI 接口，但是由于是研发人员维护，数量和场景可能受限。 perf_events：定时采样和 PMC。   内核中运行的 BPF 字节码程序可以使用两种方式将测量数据回传至用户空间  maps 方式可用于将内核中实现的统计摘要信息（比如测量延迟、堆栈信息）等回传至用户空间； perf-event 用于将内核采集的事件实时发送至用户空间，用户空间程序实时读取分析；     如无特殊说明，本文中所说的 BPF 都是泛指 BPF 技术。\n 2.3 eBPF 的限制 eBPF 技术虽然强大，但是为了保证内核的处理安全和及时响应，内核中的 eBPF 技术也给予了诸多限制，当然随着技术的发展和演进，限制也在逐步放宽或者提供了对应的解决方案。\n  eBPF 程序不能调用任意的内核参数，只限于内核模块中列出的 BPF Helper 函数，函数支持列表也随着内核的演进在不断增加。\n  eBPF 程序不允许包含无法到达的指令，防止加载无效代码，延迟程序的终止。\n  eBPF 程序中循环次数限制且必须在有限时间内结束，这主要是用来防止在 kprobes 中插入任意的循环，导致锁住整个系统；解决办法包括展开循环，并为需要循环的常见用途添加辅助函数。Linux 5.3 在 BPF 中包含了对有界循环的支持，它有一个可验证的运行时间上限。\n  eBPF 堆栈大小被限制在 MAX_BPF_STACK，截止到内核 Linux 5.8 版本，被设置为 512；参见 include/linux/filter.h，这个限制特别是在栈上存储多个字符串缓冲区时：一个char[256]缓冲区会消耗这个栈的一半。目前没有计划增加这个限制，解决方法是改用 bpf 映射存储，它实际上是无限的。\n/* BPF program can access up to 512 bytes of stack space. */ #define MAX_BPF_STACK\t512   eBPF 字节码大小最初被限制为 4096 条指令，截止到内核 Linux 5.8 版本， 当前已将放宽至 100 万指令（ BPF_COMPLEXITY_LIMIT_INSNS），参见：include/linux/bpf.h，对于无权限的BPF程序，仍然保留 4096 条限制 ( BPF_MAXINSNS )；新版本的 eBPF 也支持了多个 eBPF 程序级联调用，虽然传递信息存在某些限制，但是可以通过组合实现更加强大的功能。\n#define BPF_COMPLEXITY_LIMIT_INSNS 1000000 /* yes. 1M insns */  2.4 eBPF 与内核模块对比 在 Linux 观测方面，eBPF 总是会拿来与 kernel 模块方式进行对比，eBPF 在安全性、入门门槛上比内核模块都有优势，这两点在观测场景下对于用户来讲尤其重要。\n   维度 Linux 内核模块 eBPF     kprobes/tracepoints 支持 支持   安全性 可能引入安全漏洞或导致内核 Panic 通过验证器进行检查，可以保障内核安全   内核函数 可以调用内核函数 只能通过 BPF Helper 函数调用   编译性 需要编译内核 不需要编译内核，引入头文件即可   运行 基于相同内核运行 基于稳定 ABI 的 BPF 程序可以编译一次，各处运行   与应用程序交互 打印日志或文件 通过 perf_event 或 map 结构   数据结构丰富性 一般 丰富   入门门槛 高 低   升级 需要卸载和加载，可能导致处理流程中断 原子替换升级，不会造成处理流程中断   内核内置 视情况而定 内核内置支持    表格 2-1 eBPF 与 Linux 内核模块方式对比\n3. 应用案例 大名鼎鼎的性能分析大师 Brendan Gregg 等编写了诸多的 BCC 或 BPFTrace 的工具集可以拿来直接使用，完全可以满足我们日常问题分析和排查。\nBCC 在 CentOS 7 系统中可以通过 yum 快速安装\n# yum install bcc -y Resolving Dependencies --\u0026gt; Running transaction check ---\u0026gt; Package bcc.x86_64 0:0.8.0-1.el7 will be updated --\u0026gt; Processing Dependency: bcc(x86-64) = 0.8.0-1.el7 for package: python-bcc-0.8.0-1.el7.x86_64 ---\u0026gt; Package bcc.x86_64 0:0.10.0-1.el7 will be an update --\u0026gt; Processing Dependency: bcc-tools = 0.10.0-1.el7 for package: bcc-0.10.0-1.el7.x86_64 --\u0026gt; Running transaction check ---\u0026gt; Package bcc-tools.x86_64 0:0.8.0-1.el7 will be updated ---\u0026gt; Package bcc-tools.x86_64 0:0.10.0-1.el7 will be an update ---\u0026gt; Package python-bcc.x86_64 0:0.8.0-1.el7 will be updated ---\u0026gt; Package python-bcc.x86_64 0:0.10.0-1.el7 will be an update --\u0026gt; Finished Dependency Resolution ... 其他系统的安装方式参见：INSTALL.md\nBCC 中每一个工具都有一个对应的使用样例，比如 execsnoop.py 和 execsnoop_example.txt，在使用样例中有详细的使用说明，而且 BCC 中的工具使用的帮助文档格式基本类似，上手非常方便。\n BCC 的程序一般情况下都需要 root 用户来运行。\n 3.1 Linux 性能分析 60 秒 （BPF版本） 英文原文 Linux Performance Analysis in 60,000 Milliseconds，视频地址\nuptime dmesg | tail vmstat 1 mpstat -P ALL 1 pidstat 1 iostat -xz 1 free -m sar -n DEV 1 sar -n TCP,ETCP 1 top 60s 系列 BPF 版本如下：\n图 3-1 60s 排查之 BPF 版本\n对于在系统中运行的 \u0026ldquo;闪电侠\u0026rdquo; 程序，运行周期非常短，但是可能会带来系统的抖动延时，我们采用 top 命令查看一般情况下难以发现，我们可以使用 BCC 提供的工具 execsnoop  来进行排查：\n# Trace file opens with process and filename: opensnoop #/usr/share/bcc/tools/execsnoop PCOMM PID PPID RET ARGS sleep 3334 21029 0 /usr/bin/sleep 3 sleep 3339 21029 0 /usr/bin/sleep 3 conntrack 3341 1112 0 /usr/sbin/conntrack --stats conntrack 3342 1112 0 /usr/sbin/conntrack --count sleep 3344 21029 0 /usr/bin/sleep 3 iptables-save 3347 9211 0 /sbin/iptables-save -t filter iptables-save 3348 9211 0 /sbin/iptables-save -t nat 3.2 slab dentry 过大导致的网络抖动排查 现象\n网络 ping 的延时间歇性有规律出现抖动\n问题排查\n采用 execsnoop 分析发现，某个运行命令cat /proc/slabinfo的运行时间间隔与抖动的频率完全吻合，顺着这个的线索定位，我们发现云厂商提供的 Java 版本的云监控会定期调用 cat /proc/slabinfo 来获取内核缓存的信息；\n通过命令 slabtop 发现系统中的 dentry 项的内存占用非常大，系统内存 128G，dentry 占用 70G 以上，所以问题很快就定位到是系统在打开文件方面可能有相关问题；\n根因分析\n我们使用对于打开文件跟踪的 BCC 工具 opensnoop 很快就定位到是某个程序频繁创建和删除临时文件，最终定位为某个 PHP 程序设置的调用方式存在问题，导致每次请求会创建和删除临时文件；代码中将 http 调用中的 contentType 设置成了 Http::CONTENT_TYPE_UPLOAD，导致每次请求都会生成临时文件，修改成 application/x-www-form-urlencoded 问题解决。\n问题的原理可参考 记一次对网络抖动经典案例的分析 和 systemtap脚本分析系统中dentry SLAB占用过高问题\n3.3 生成火焰图 火焰图是帮助我们对系统耗时进行可视化的图表，能够对程序中那些代码经常被执行给出一个清晰的展现。Brendan Gregg 是火焰图的创建者，他在 GitHub 上维护了一组脚本可以轻松生成需要的可视化格式数据。使用 BCC 中的工具 profile 可很方面地收集道 CPU 路径的数据，基于数据采用工具可以轻松地生成火焰图，查找到程序的性能瓶颈。\n 使用 profile 搜集火焰图的程序没有任何限制和改造\n profile 工具可以让我们轻松对于系统或者程序的 CPU 性能路径进行可视化分析：\n/usr/share/bcc/tools/profile -h usage: profile [-h] [-p PID | -L TID] [-U | -K] [-F FREQUENCY | -c COUNT] [-d] [-a] [-I] [-f] [--stack-storage-size STACK_STORAGE_SIZE] [-C CPU] [duration] Profile CPU stack traces at a timed interval positional arguments: duration duration of trace, in seconds optional arguments: -h, --help show this help message and exit -p PID, --pid PID profile process with this PID only -L TID, --tid TID profile thread with this TID only -U, --user-stacks-only show stacks from user space only (no kernel space stacks) -K, --kernel-stacks-only show stacks from kernel space only (no user space stacks) -F FREQUENCY, --frequency FREQUENCY sample frequency, Hertz -c COUNT, --count COUNT sample period, number of events -d, --delimited insert delimiter between kernel/user stacks -a, --annotations add _[k] annotations to kernel frames -I, --include-idle include CPU idle stacks -f, --folded output folded format, one line per stack (for flame graphs) --stack-storage-size STACK_STORAGE_SIZE the number of unique stack traces that can be stored and displayed (default 16384) -C CPU, --cpu CPU cpu number to run profile on examples: ./profile # profile stack traces at 49 Hertz until Ctrl-C ./profile -F 99 # profile stack traces at 99 Hertz ./profile -c 1000000 # profile stack traces every 1 in a million events ./profile 5 # profile at 49 Hertz for 5 seconds only ./profile -f 5 # output in folded format for flame graphs ./profile -p 185 # only profile process with PID 185 ./profile -L 185 # only profile thread with TID 185 ./profile -U # only show user space stacks (no kernel) ./profile -K # only show kernel space stacks (no user) profile 配合 FlameGraph 可以轻松帮我们绘制出 CPU 使用的火焰图。\n$ profile -af 30 \u0026gt; out.stacks01 $ git clone https://github.com/brendangregg/FlameGraph $ cd FlameGraph $ ./flamegraph.pl --color=java \u0026lt; ../out.stacks01 \u0026gt; out.svg 图 3-2 火焰图\n3.3 排查网络调用来源 在生产场景下，会有些特定场景需要抓取连接到外网特定地址的程序，这时候我们可以采用 BCC 工具集中的 tcplife 来定位。\n/usr/share/bcc/tools/tcplife -h usage: tcplife [-h] [-T] [-t] [-w] [-s] [-p PID] [-L LOCALPORT] [-D REMOTEPORT] Trace the lifespan of TCP sessions and summarize optional arguments: -h, --help show this help message and exit -T, --time include time column on output (HH:MM:SS) -t, --timestamp include timestamp on output (seconds) -w, --wide wide column output (fits IPv6 addresses) -s, --csv comma separated values output -p PID, --pid PID trace this PID only -L LOCALPORT, --localport LOCALPORT comma-separated list of local ports to trace. -D REMOTEPORT, --remoteport REMOTEPORT comma-separated list of remote ports to trace. examples: ./tcplife # trace all TCP connect()s ./tcplife -t # include time column (HH:MM:SS) ./tcplife -w # wider colums (fit IPv6) ./tcplife -stT # csv output, with times \u0026amp; timestamps ./tcplife -p 181 # only trace PID 181 ./tcplife -L 80 # only trace local port 80 ./tcplife -L 80,81 # only trace local ports 80 and 81 ./tcplife -D 80 # only trace remote port 80 通过在机器上使用 tcplife 来获取的网络连接信息，我们可以看到包括了 PID、COMM、本地 IP 地址、本地端口、远程 IP 地址和远程端口，通过这些信息非常方便排查到连接到特定 IP 地址的程序，尤其是连接的过程非常短暂，通过 netstat 等其他工具不容易排查的场景。\n# /usr/share/bcc/tools/tcplife PID COMM IP LADDR LPORT RADDR RPORT TX_KB RX_KB MS 1776 blackbox_export 4 169.254.20.10 35830 169.254.20.10 53 0 0 0.36 27150 node-cache 4 169.254.20.10 53 169.254.20.10 35830 0 0 0.36 12511 coredns 4 127.0.0.1 58492 127.0.0.1 8080 0 0 0.32 ... 如果我们想知道更加详细的 TCP 状态情况，那么 tcptracer 可展示更加详细的 TCP 状态，其中 C 代表 Connect X 表示关闭， A 代表 Accept。\n# /usr/share/bcc/tools/tcptracer Tracing TCP established connections. Ctrl-C to end. T PID COMM IP SADDR DADDR SPORT DPORT C 21066 ilogtail 4 10.81.128.12 100.100.49.128 40906 80 X 21066 ilogtail 4 10.81.128.12 100.100.49.128 40906 80 C 21066 ilogtail 4 10.81.128.12 100.100.49.128 40908 80 X 21066 ilogtail 4 10.81.128.12 100.100.49.128 40908 80 tcpstates 还能够展示出来 TCP 状态机的流转情况：\n# /usr/share/bcc/tools/tcpstates SKADDR C-PID C-COMM LADDR LPORT RADDR RPORT OLDSTATE -\u0026gt; NEWSTATE MS ffff9fd7e8192000 22384 curl 100.66.100.185 0 52.33.159.26 80 CLOSE -\u0026gt; SYN_SENT 0.000 ffff9fd7e8192000 0 swapper/5 100.66.100.185 63446 52.33.159.26 80 SYN_SENT -\u0026gt; ESTABLISHED 1.373 ffff9fd7e8192000 22384 curl 100.66.100.185 63446 52.33.159.26 80 ESTABLISHED -\u0026gt; FIN_WAIT1 176.042 同样，我们也可以实时获取到 TCP 连接超时或者重连的网络连接；也可以通过抓取 UDP包相关的连接信息，用于定位诸如 DNS 请求超时或者 DNS 请求的发起进程。\n4. 编写 BPF 程序 对于大多数开发者而言，更多的是基于 BPF 技术之上编写解决我们日常遇到的各种问题，当前 BCC 和 BPFTrace 两个项目在观测和性能分析上已经有了诸多灵活且功能强大的工具箱，完全可以满足我们日常使用。\n BCC 提供了更高阶的抽象，可以让用户采用 Python、C++ 和 Lua 等高级语言快速开发 BPF 程序； BPFTrace 采用类似于 awk 语言快速编写 eBPF 程序；  更早期的工具则是使用 C 语言来编写 BPF 程序，使用 LLVM clang 编译成 BPF 代码，这对于普通使用者上手有不少门槛当前仅限于对于 eBPF 技术更加深入的学习场景。\n4.1 BCC 版本 HelloWorld 图 4-1 BCC 整体架构\n使用 BCC 前端绑定语言 Python 编写的 Hello World 版本：\n#!/usr/bin/python3 from bcc import BPF # This may not work for 4.17 on x64, you need replace kprobe__sys_clone with kprobe____x64_sys_clone prog = \u0026quot;\u0026quot;\u0026quot; int kprobe__sys_clone(void *ctx) { bpf_trace_printk(\u0026quot;Hello, World!\\\\n\u0026quot;); return 0; } \u0026quot;\u0026quot;\u0026quot; b = BPF(text=prog, debug=0x04) b.trace_print() 运行程序前需要安装过 bcc 相关工具包，当运行正常的时候我们发现每当 sys_clone 系统调用时，运行的控制台上就会打印 “Hello, World!”，在打印文字前面还包含了调用程序的进程名称，进程 ID 等信息；\n 如果运行报错，可能是缺少头文件，一般安装 kernel-devel 包即可。\n # python ./hello.py kubelet-8349 [006] d... 33637334.829981: : Hello, World! kubelet-8349 [006] d... 33637334.838594: : Hello, World! kubelet-8349 [006] d... 33637334.843788: : Hello, World! 4.3 BPFTrace BPFTrace 是基于 BPF 和 BCC 的开源项目，与 BCC 不同的是其提供了更高层次的抽象，可以使用类似 AWK 脚本语言来编写基于 BPF 的跟踪或者性能排查工具，更加易于入门和编写，该工具的主要灵感来自于 Solaris 的 D 语言。BPFTrace 更方便与编写单行的程序。BPFTrace 与 BCC 一样也是 IO Visor 组织下的项目，仓库参见 bpftrace。更加深入的学习资料参见：Reference Guide 和 One-Liner Tutorial。\nBPFTrace 使用 LLVM 将脚本编译成 BPF 二进制码，后续使用 BCC 与 Linux 内核进行交互。从功能层面上讲，BPFTrace 的定制性和灵活性不如 BCC，但是比 BCC 工具更加易于理解和使用，降低了 BPF 技术的使用门槛。\n使用样例：\n# 统计进程调用 sys_enter 的次数 #bpftrace -e \u0026#39;tracepoint:raw_syscalls:sys_enter { @[comm] = count(); }\u0026#39; Attaching 1 probe... ^C @[bpftrace]: 6 @[systemd]: 24 @[snmp-pass]: 96 @[sshd]: 125 # 统计内核中函数堆栈的次数 # bpftrace -e \u0026#39;profile:hz:99 { @[kstack] = count(); }\u0026#39; Attaching 1 probe... ^C [...] @[ filemap_map_pages+181 __handle_mm_fault+2905 handle_mm_fault+250 __do_page_fault+599 async_page_fault+69 ]: 12 [...] @[ cpuidle_enter_state+164 do_idle+390 cpu_startup_entry+111 start_secondary+423 secondary_startup_64+165 ]: 22122 4.3 C 语言原生方式 采用 LLVM Clang 的方式编译会涉及到内核编译环境搭建，而且还需要自己编译 Makefile 等操作，属于高级用户使用：\nbpf_program.c\n#include \u0026lt;linux/bpf.h\u0026gt;#define SEC(NAME) __attribute__((section(NAME), used))  static int (*bpf_trace_printk)(const char *fmt, int fmt_size, ...) = (void *)BPF_FUNC_trace_printk; SEC(\u0026#34;tracepoint/syscalls/sys_enter_execve\u0026#34;) int bpf_prog(void *ctx) { char msg[] = \u0026#34;Hello, BPF World!\u0026#34;; bpf_trace_printk(msg, sizeof(msg)); return 0; } char _license[] SEC(\u0026#34;license\u0026#34;) = \u0026#34;GPL\u0026#34;; loader.c\n#include \u0026#34;bpf_load.h\u0026#34;#include \u0026lt;stdio.h\u0026gt; int main(int argc, char **argv) { if (load_bpf_file(\u0026#34;bpf_program.o\u0026#34;) != 0) { printf(\u0026#34;The kernel didn\u0026#39;t load the BPF program\\n\u0026#34;); return -1; } read_trace_pipe(); return 0; } Makefile 文件（部分）\nbuild: ${BPFCODE.c} ${BPFLOADER} $(CLANG) -O2 -target bpf -c $(BPFCODE:=.c) $(CCINCLUDE) -o ${BPFCODE:=.o} 其中 clang 编译中的选型 -target bpf 表明我们将代码编译成 bpf 的字节码。\n完整的程序参见：hello_world；更多的样例代码可以参见对应内核中 kernel-src/samples/bpf/ 下的样例代码。\n 后续会持续进行 BPF 相关的内容总结和分享，Github bpf_study 仓库，欢迎提交 PR 和 Star\n 5. 参考资料   The BSD Packet Filter: A New Architecture for User-level Packet Capture\n  [译] Cilium：BPF 和 XDP 参考指南（2019）  Cillum BPF and XDP Reference Guide\n  Cloudflare架构以及BPF如何占据世界\n  關於 BPF 和 eBPF 的筆記\n  Dive into BPF: a list of reading material 中文\n  eBPF 简史\n  https://www.youtube.com/watch?v=znBGt7oHJyQ\n  BPF Documentation HOWTO interact with BPF subsystem\n  Linux 内核 BPF 文档\n  Linux Extended BPF (eBPF) Tracing Tools Brendan Gregg\n  性能提升40%: 腾讯 TKE 用 eBPF绕过 conntrack 优化K8s Service\n  SDN handbook\n  Linux BPF 帮助文档 bpf(2) bpf-helpers(7) tc-bpf(8)\n  ","permalink":"https://cloudnative.to/blog/bpf-intro/","tags":["BPF"],"title":"eBPF 技术简介"},{"categories":["学习小组"],"contents":"前言 目前在云原生社区的 Kubernetes 源码研习社中和广大学友们共同学习郑东旭大佬的 Kubernetes 源码剖析这本书。当前正在开展第一期学习活动，第五章节 client-go 的学习。之所以从这一章节开始学习，主要是考虑到 client-go 在源码中相对比较独立，可以单独阅读。更主要的是它是 Kubernetes 的核心处理框架，基本上运用在 Kubernetes 各个组件中，因此，如果你学好了这一章节，对于后面 Kubernetes 源码的阅读，将会有很大的帮助。此外随着 Operator 的盛行，一些开源的生成框架也受到广大 Operator 开发者们的青睐。例如 kubebuilder 和 operator-SDK 等。而精通了 client-go，将对你理解这些生成框架及编写 Operator 也是有很好的帮助。\n下面内容是在学习过程中总结的相关笔记及个人见解。\n概括 client-go 是用 Golang 语言编写的官方编程式交互客户端库，提供对 Kubernetes API server 服务的交互访问。\n其源码目录结构如下：\n discovery: 提供 DiscoveryClient 发现客户端。 dynamic: 提供 DynamicClient 动态客户端。 informers: 每种 K8S 资源的 Informer 实现。 kubernetes: 提供 ClientSet 客户端。 listers: 为每一个 K8S 资源提供 Lister 功能，该功能对 Get 和 List 请求提供只读的缓存数据。 plugin: 提供 OpenStack，GCP 和 Azure 等云服务商授权插件。 rest: 提供 RESTClient 客户端，对 K8S API Server 执行 RESTful 操作。 scale: 提供 ScaleClient 客户端，用于扩容或缩容 Deployment, Replicaset, Replication Controller 等资源对象。 tools: 提供常用工具，例如 SharedInformer, Relector, DealtFIFO 及 Indexers。 提供 Client 查询和缓存机制，以减少想 kube-apiserver 发起的请求数等。主要子目录为/tools/cache。 transport: 提供安全的 TCP 连接，支持 HTTP Stream，某些操作需要在客户端和容器之间传输二进制流，例如 exec，attach 等操作。该功能由内部的 SPDY 包提供支持。 util: 提供常用方法。例如 WorkQueue 工作队列，Certificate 证书管理等。  RESTClient 客户端 RESTful Client 是最基础的客户端，它主要是对 HTTP 请求进行了封装，并且支持 JSON 和 Protobuf 格式数据。\nDynamicClient 客户端 DynamicClient 是一种动态客户端，它可以动态的指定资源的组，版本和资源。因此它可以对任意 K8S 资源进行 RESTful 操作，包括 CRD 自定义资源。它封装了 RESTClient。所以同样提供 RESTClient 的各种方法。\n具体使用方法，可参考官方示例：dynamic-create-update-delete-deployment。\n注意: 该官方示例是基于集群外的环境，如果你需要在集群内部使用（例如你需要在 container 中访问），你将需要调用 rest.InClusterConfig() 生成一个 configuration。具体的示例请参考 in-cluster-client-configuration。\nClientSet 客户端 ClientSet 客户端在 RESTClient 的基础上封装了对资源和版本的管理方法。每个资源可以理解为一个客户端，而 ClientSet 则是多个客户端的集合，每一个资源和版本都以函数的方式暴露给开发者。\n具体使用方法，可参考官方示例：create-update-delete-deployment。\nDiscoveryClient 客户端 DiscoveryClient 是一个发现客户端，它主要用于发现 K8S API Server 支持的资源组，资源版本和资源信息。所以开发者可以通过使用 DiscoveryClient 客户端查看所支持的资源组，资源版本和资源信息。\nClientSet VS DynamicClient 类型化 ClientSets 使得使用预先生成的本地 API 对象与 API 服务器通信变得简单，从而获得类似 RPC 的编程体验。类型化客户端使用程序编译来强制执行数据安全性和一些验证。然而，在使用类型化客户端时，程序被迫与所使用的版本和类型紧密耦合。\n而 DynamicClient 则使用 unstructured.Unstructured 表示来自 API Server 的所有对象值。Unstructured 类型是一个嵌套的 map[string]inferface{} 值的集合来创建一个内部结构，该结构和服务端的 REST 负载非常相似。\nDynamicClient 将所有数据绑定推迟到运行时，这意味着程序运行之前，使用 DynamicClient 的的程序将不会获取到类型验证的任何好处。对于某些需要强数据类型检查和验证的应用程序来说，这可能是一个问题。\n然而，松耦合意味着当客户端 API 发生变化时，使用 DynamicClient 的程序不需要重新编译。客户端程序在处理 API 表面更新时具有更大的灵活性，而无需提前知道这些更改是什么。\nInformer 分析 这是一个官方图形表示，展示了client-go 库中的各种组件如何工作，以及它们与将要编写的自定义控制器代码的交互点。\n下面对图中每个组件进行简单介绍：\n  client-go 组件\n  Reflector: 定义在 /tools/cache 包内的 Reflector 类型 中的 reflector 监视 Kubernetes API 以获取指定的资源类型 (Kind)。完成此操作的函数是 ListAndWatch。监视可以用于内建资源，也可以用于自定义资源。当 reflector 通过监视 API 的收到关于新资源实例存在的通知时，它使用相应的 listing API 获取新创建的对象，并将其放入 watchHandler 函数内的 Delta Fifo 队列中。\n  Informer: 在 /tools/cache 包内的基础 controller 中定义的一个 informer 从 Delta FIFO 队列中弹出对象。完成此操作的函数是 processLoop。这个基础 controller 的任务是保存对象以供以后检索，并调用 controller 将对象传递给它。\n  Indexer: indexer 为对象提供索引功能。它定义在 /tools/cache 包内的 Indexer 类型。一个典型的索引用例是基于对象标签创建索引。Indexer 可以基于多个索引函数维护索引。Indexer 使用线程安全的数据存储来存储对象及其键值。在 /tools/cache 包内的 Store 类型 定义了一个名为MetaNamespaceKeyFunc的默认函数，该函数为该对象生成一个名为 \u0026lt;namespace\u0026gt;/\u0026lt;name\u0026gt; 组合的对象键值。\n    Custom Controller 组件\n  Informer reference: 这是一个知道如何使用自定义资源对象的 Informer 实例的引用。您的自定义控制器代码需要创建适当的 Informer。\n  Indexer reference: 这是一个知道如何使用自定义资源对象的 Indexer 实例的引用。您的自定义控制器代码需要创建这个。您将使用此引用检索对象，以便稍后处理。\n  Resource Event Handlers: 当 Informer 想要分发一个对象给你的控制器时，会调用这些回调函数。编写这些函数的典型模式是获取已分配对象的键值，并将该键值放入一个工作队列中进行进一步处理。\n  Work queue: 这是在控制器代码中创建的队列，用于将对象的分发与处理解耦。编写 Resource Event Handler 函数来提取所分发对象的键值并将其添加到工作队列中。\n  Process Item: 这是在代码中创建的处理 work queue 中的 items 的函数。可以有一个或多个其他函数来执行实际的处理。这些函数通常使用 Indexer 引用 或 Listing wrapper 来获取与键值对应的对象。\n    Informer 源码类图 该类图主要描述了 Informer 中主要的接口和类之前的调用关系。大家可以参考这个类图去阅读源码。其中每个类或接口具体功能，请参考 Kubernetes 源码剖析第五章节 client-go。\nIndexer 分析  Store : 是一个通用对象存储和处理接口。 Indexer : Indexer 扩展了多个索引的 Store，并限制每个累加器只保存当前对象（删除后为空）。 cache : 根据 ThreadSafeStore 和关联的 KeyFunc 实现的 Indexer。 ThreadSafeStore : 是一个允许对存储后端进行并发索引访问的接口。它类似于 Indexer，但不（必须）知道如何从给定对象中提取存储键。 threadSafeMap : 实现了 ThreadSafeStore。  下面为具体的类图展示：\nthreadSafeMap 分析 threadSafeMap 类中包含下面三个属性：\n items map[string]interface{} 保存所有数据的 map 结构。 indexers Indexers 通过一个名字映射一个 IndexFunc 索引处理函数。 indices Indices 通过一个名字映射一个 Index。  下面是 threadSafeMap 结构的源码定义：\n// threadSafeMap implements ThreadSafeStore type threadSafeMap struct { lock sync.RWMutex items map[string]interface{} // indexers maps a name to an IndexFunc  indexers Indexers // indices maps a name to an Index  indices Indices } 下面是 Indexers, Indices and Index 的源码定义：\n// IndexFunc knows how to compute the set of indexed values for an object. type IndexFunc func(obj interface{}) ([]string, error) // Index maps the indexed value to a set of keys in the store that match on that value type Index map[string]sets.String // Indexers maps a name to a IndexFunc type Indexers map[string]IndexFunc // Indices maps a name to an Index type Indices map[string]Index 这是一个 threadSafeMap 存储结构的示例图：\n最后以添加一个新的对象到 threadSafeMap 为例，分析具体需要哪些操作。\n首先列出源码以供参考：\nfunc (c *threadSafeMap) Add(key string, obj interface{}) { c.lock.Lock() defer c.lock.Unlock() oldObject := c.items[key] c.items[key] = obj c.updateIndices(oldObject, obj, key) } // updateIndices modifies the objects location in the managed indexes, if this is an update, you must provide an oldObj // updateIndices must be called from a function that already has a lock on the cache func (c *threadSafeMap) updateIndices(oldObj interface{}, newObj interface{}, key string) { // if we got an old object, we need to remove it before we add it again  if oldObj != nil { c.deleteFromIndices(oldObj, key) } for name, indexFunc := range c.indexers { indexValues, err := indexFunc(newObj) if err != nil { panic(fmt.Errorf(\u0026#34;unable to calculate an index entry for key %q on index %q: %v\u0026#34;, key, name, err)) } index := c.indices[name] if index == nil { index = Index{} c.indices[name] = index } for _, indexValue := range indexValues { set := index[indexValue] if set == nil { set = sets.String{} index[indexValue] = set } set.Insert(key) } } } 从上面代码可以总结出下面几个步骤：\n 从 items 中获取旧的对象值，并将新的对象添加到 items 中指定键值的位置。 将新加入对象的键值更新到索引中。  如果旧的对象存在，则将其从索引中删除，否则进行下一步。 迭代 indexers 进行新对象的索引处理。 通过 indexers 中的 indexFunc 处理新对象，找到相应的 indexValues。 使用 indexer 的 name 从 indices 中找到对应的 index。如果对应的 index 是空，则创建一个新的 index。 迭代 indexValues 进行 index 处理。 通过 indexValue 在 index 中找到对应的 set， 如果 set 不存在，则创建一个新的 set。并添加到 index 中。 添加新对象的键值到 set 中。 返回第 5 步，直到迭代完成。 返回第 2 步，直到迭代完成。    WorkQueue 分析 Interface : FIFO 队列接口，并支持去重处理。\nDelayingInterface: 延迟队列接口，基于 Interface 接口封装。\nRateLimitingInterface: 速率限制接口，基于 DelayingInterface 接口封装。\n下面是相关类图：\n示例参考   参考 K8S 官方示例 Kubernetes/sample-controller。\n  参考 client-go 官方示例 workqueue。这是一个典型的使用 client-go informer 的例子，它完全基于 client-go informer 的框架。几乎所有的 K8S 控制器都是基于这个框架实现的。所以个人认为 client-go 的 informer 机制是 k8S controller 实现的基石。\n  总结 可以说 Kubernetes 是当前云原生的基石。所以想要进军云原生领域，kubernetes 的学习必不可少。kubernetes 的设计理念就是通过各种控制器将系统的实际运行状态协调到声明 API 中的期待状态。而这种协调机制就是基于 client-go 实现的。同样，kubernetes 对于 ETCD 存储的缓存处理也使用到了 client-go 中的 Reflector 机制。所以学好 client-go，等于迈入了 Kubernetes 的大门。\n学习 Kubernetes 及更多云原生相关技术是一个漫长的过程。所以需要一个人有极强的意志力和学习动力。如果你觉得自己缺乏这些能力，可以加入我们 云原生社区。大家一起学习，相互督促，相互分享，相互学习，相互成长。\n最后送自己和正在学习及将要学习 Kubernetes 源码的同学们一句话：不积跬步，无以至千里；不积小流，无以成江海！\n参考文章  Source code Kubernetes client-go 库介绍和源码解析 Client-Go informer 机制 informer 之 store 和 index Kubernetes Client-Go Informer 实现源码剖析 client-go package Informer source code analysis kube-controller-manager 源码分析（三）之 Informer 机制 Sample-controller Indexer  ","permalink":"https://cloudnative.to/blog/client-go-study/","tags":["client-go"],"title":"client-go 源码学习总结"},{"categories":["ebpf"],"contents":"TL;DR 声明：下文提到的bpf/BPF字样是泛指，包括cBPF和eBPF。\n通过文章，你能了解Linux内核代码中关于bpf程序的编译运行机制，并能学会如何基于Linux内核bpf示例环境编写你自己的bpf程序。文章涉及的实验环境和代码可以到这个git repo获取： https://github.com/nevermosby/linux-bpf-learning\n最近Kubecon 2020 China上已经有了3个关于bpf的中文分享（来自腾讯和PingCAP），也看到国内第一梯队公司越来越关心bpf这项新技术，欢迎大家都能加入bpf学习队伍。\n内核源码里的BPF示例代码概述 示例代码里基本是kern和user成对出现，也就是对于一个示例来说，分别提供了在内核空间运行的和用户空间运行的程序，绝对是良心之作了。\n下载Linux内核源代码 First thing first，第一步是下载内核代码。\n选择内核版本 目前社区维护的内核版本繁多，你需要确定下载哪个版本的代码。个人建议是下载与你的操作系统运行一致的内核版本，避免后续编译时出现不兼容问题。\n选择下载渠道 代码下载渠道也很多：\n  通过Linux社区官方仓库下载。以下几个网站都是官方维护的：\n https://github.com/torvalds/linux https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git 观察下来，只要有新的commit，基本是实时同步的，下载最新版本的内核代码肯定没问题。如果你跟我一样，需要相对较旧的版本，只要切换相关的目标tag即可。我的内核版本是v4.15.0，下载地址参考如下：  https://github.com/torvalds/linux/tree/v4.15 https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tag/?h=v4.15      通过Ubuntu apt仓库下载。Ubuntu官方自己维护了每个操作系统版本的背后的Linux内核代码，可以通过以下两种apt命令方式获取相关代码：\n# 第一种方式 # 先搜索 \u0026gt; apt-cache search linux-source linux-source - Linux kernel source with Ubuntu patches linux-source-4.15.0 - Linux kernel source for version 4.15.0 with Ubuntu patches linux-source-4.18.0 - Linux kernel source for version 4.18.0 with Ubuntu patches linux-source-5.0.0 - Linux kernel source for version 5.0.0 with Ubuntu patches linux-source-5.3.0 - Linux kernel source for version 5.3.0 with Ubuntu patches # 再安装 \u0026gt; apt install linux-source-4.15.0 # 第二种方式 \u0026gt; apt-get source linux Reading package lists... Done NOTICE: \u0026#39;linux\u0026#39; packaging is maintained in the \u0026#39;Git\u0026#39; version control system at: git://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/bionic Please use: git clone git://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/bionic to retrieve the latest (possibly unreleased) updates to the package. Need to get 167 MB of source archives. Get:2 https://mirrors.ustc.edu.cn/ubuntu bionic-updates/main linux 4.15.0-99.100 (tar) [158 MB] ...... # 以上两种方式，内核源代码均下载至/usr/src/目录下   下载完成后，BPF示例就在源码根目录/samples/bpf目录下，可以到这里看个在线版的，建议大家通读一遍这个目录下的README.rst，了解整体步骤。\n编译BPF示例代码 安装编译所依赖的工具 在真正开始编译工作之前，请确保你的实验环境已经安装clang和llvm：\n clang \u0026gt;= version 3.4.0 llvm \u0026gt;= version 3.7.1  正式编译示例代码 万事俱备了，可以正式开始编译工作。我们说的“编译”其本质就是利用内核目录下不同的Makefile，通过特定的make指令完成特定工作。来，先上命令：\n# 切换到内核源代码根目录 cd linux_sourcecode/ # 生成内核编译时需要的头文件 make headers_install # 可视化选择你想为内核添加的内核模块，最终生成保存了相关模块信息的.config文件，为执行后面的命令做准备 make menuconfig # 使用make命令编译samples/bpf/目录下所有bpf示例代码，注意需要加上最后的/符号 make samples/bpf/ # or make M=samples/bpf 如下截图看结果，生成了一大堆的文件，有.o后缀的目标文件，还有绿色高亮的可执行文件，挑两个执行下，效果符合期待。\n分析samples/bpf/Makefile文件 如果你是个喜欢打破砂锅问到底的同学，可以跟我一起看看最后的make命令到底用了什么魔法？当然你也可以跳过这个章节。本次分析的Makefile是基于内核版本v4.15.0，不同内核版本的Makefile内容会有差异，但总体逻辑是一致的。\n前提条件  如果你对make作为构建工具还不熟悉，可以看看这个教程。 Linux内核中大部分Makefile都是基于Kernel Build System，简称kbuild，它是对Makefile的扩展，使其在编译内核文件时更加高效、简洁。因此你需要对其有所了解，可以到这里看看官方介绍。 上文使用的另外两个make命令，利用的是根目录下的Makefile，完成“生成头文件”和“生成.config文件”，这两步是内核开发的必要步骤，感兴趣的同学移步看README.rst。  分段分析   第一段关于变量hostprogs-y\n# List of programs to build hostprogs-y := test_lru_dist hostprogs-y += sock_example hostprogs-y += fds_example hostprogs-y += sockex1 hostprogs-y += sockex2 hostprogs-y += sockex3 ... Makefile的第一段是初始化变量hostprogs-y，乍一看，好像是把所有示例程序名称都赋值给了hostprogs-y。官方的注释是List of programs to build，直译过来是，“准备构建的程序清单”、，大致能猜出这个变量的意义了，通过查询官方文档，发现一个概念叫Host Program support，意思是在编译阶段就构建出可以在本机直接运行的可执行文件，为了实现这个目的，需要经过两个步骤：\n  第一步告诉 kbuild 需要生成哪些可执行文件，这个就是通过变量hostprogs-y来指定。来看源码中的这一行：\nhostprogs-y := test_lru_dist 程序test_lru_dist就是一个被指定的可执行程序名称，kbuild默认会去同一个目录下查找名为test_lru_dist.c作为构建这个可执行文件的源文件。类似代码也是同样的意义，总计有41个可执行文件赋值给了变量hostprogs-y中。\n  第二步是将显式依赖关系添加到可执行文件中。这可以通过两种方式来完成，一种是为Makefile中某个target添加这个可执行文件，作为prerequisites，形成依赖关系，这样就可以触发这个可执行文件的构建任务，另一种是直接利用变量 always，即无需指定第一种方式中的依赖关系，只要Makefile被执行，变量always中包含的可执行文件都会被构建。来看源码中的相关片段：\n# Tell kbuild to always build the programs always := $(hostprogs-y) 可以看到它使用上文提到的第二种方式，保证这些可执行文件一定会被执行构建任务。\n    第二段关于变量\u0026lt;executeable\u0026gt;-objs\n# Libbpf dependencies LIBBPF := ../../tools/lib/bpf/bpf.o CGROUP_HELPERS := ../../tools/testing/selftests/bpf/cgroup_helpers.o test_lru_dist-objs := test_lru_dist.o $(LIBBPF) sock_example-objs := sock_example.o $(LIBBPF) fds_example-objs := bpf_load.o $(LIBBPF) fds_example.o sockex1-objs := bpf_load.o $(LIBBPF) sockex1_user.o sockex2-objs := bpf_load.o $(LIBBPF) sockex2_user.o sockex3-objs := bpf_load.o $(LIBBPF) sockex3_user.o ... 第一、二行是声明并初始化了两个变量LIBBPF和CGROUP_HELPERS，以便后续复用。后面的几行是有共性的，:=符号左边是个有规律的变量：\u0026lt;executeable\u0026gt;-objs，右边是多个.o文件，看上去的意义像是右边的多个文件会合并成一个指定文件。通过查询文档可知，可执行文件可以由多个其他文件复合组成，通过\u0026lt;executeable\u0026gt;-objs这样的语法，可以列出并指定所有用于生成最终可执行文件（命名为executeable）的文件清单。以如下代码为例，可执行文件sockex1是由bpf_load.o、bpf.o和sockex1_usr.o链接生成的。\nsockex1-objs := bpf_load.o $(LIBBPF) sockex1_user.o   第三段关于变量HOSTCFLAGS和HOSTLOADLIBES\nHOSTCFLAGS += -I$(objtree)/usr/include HOSTCFLAGS += -I$(srctree)/tools/lib/ HOSTCFLAGS += -I$(srctree)/tools/testing/selftests/bpf/ HOSTCFLAGS += -I$(srctree)/tools/lib/ -I$(srctree)/tools/include HOSTCFLAGS += -I$(srctree)/tools/perf HOSTCFLAGS_bpf_load.o += -I$(objtree)/usr/include -Wno-unused-variable HOSTLOADLIBES_fds_example += -lelf HOSTLOADLIBES_sockex1 += -lelf HOSTLOADLIBES_sockex2 += -lelf HOSTLOADLIBES_sockex3 += -lelf ... HOSTLOADLIBES_tracex4 += -lelf -lrt ... 上面的代码中有两个关键变量：\n 变量HOSTCFLAGS顾名思义，它是在编译host program（即可执行文件）时，为编译操作指定的特殊选项，如上面代码中使用-I参数指定依赖的头文件所在目录。默认情况下，这个变量的配置会作用到当前Makefile涉及的所有host program。如果你想为某个host program单独指定一个编译选项，可以像上文的这行代码： HOSTCFLAGS_bpf_load.o += -I$(objtree)/usr/include -Wno-unused-variable 只为bpf_load.o这个object文件指定特殊选项。\n 变量HOSTLOADLIBES是用于链接（link）操作时指定的特殊选项，如上面代码中使用两个library（因为代码中使用了相关的函数），通过选项-l加到最终生成的可执行文件中：  libelf，这个库用来管理elf格式的文件，bpf程序一般都会使用elf作为最终格式，因此需要加载这个library。 librt，这个库其实很常用，一般含有#include\u0026lt;time.h\u0026gt;头文件的代码，都需要加载这个library，用来支持real time相关功能。      第四段关于如何编译BPF程序源文件\n# Trick to allow make to be run from this directory all: $(MAKE) -C ../../ $(CURDIR)/ ... $(obj)/%.o: $(src)/%.c $(CLANG) $(NOSTDINC_FLAGS) $(LINUXINCLUDE) $(EXTRA_CFLAGS) -I$(obj) \\  -I$(srctree)/tools/testing/selftests/bpf/ \\  -D__KERNEL__ -Wno-unused-value -Wno-pointer-sign \\  -D__TARGET_ARCH_$(ARCH) -Wno-compare-distinct-pointer-types \\  -Wno-gnu-variable-sized-type-not-at-end \\  -Wno-address-of-packed-member -Wno-tautological-compare \\  -Wno-unknown-warning-option $(CLANG_ARCH_ARGS) \\  -O2 -emit-llvm -c $\u0026lt; -o -| $(LLC) -march=bpf -filetype=obj -o $@ 其中有两个系统变量：第一个$@代表的是target所指的文件名；第二个$\u0026lt;代表的是第一个prerequisite的文件名。看过本站关于BPF博文的同学可能已经看出如上代码的玄机了，我把它简化下：\nclang -I $(srctree)/tools/testing/selftests/bpf/ \\  -O2 -emit-llvm -c $\u0026lt; -o -| \\  llc -march=bpf -filetype=obj -o $@ 从上面的简化版命令，可以看出最后一行make命令的本质，就是把所有.c源代码文件，通过clang全部编译成.o目标文件。\n  小结 对samples/bpf/Makefile这个文件执行make命令的本质就是：\n 为运行在内核空间的示例源代码（一般文件名称后缀为kern.c），编译生成.o后缀的目标文件，以便加载到对应BPF提供的hook中去。 为运行在用户空间的示例源代码(一般文件文件后缀为user.c)，编译生成可以在本机直接运行的可执行文件，以便用户可以直接运行测试。  我在执行Make命令遇到的问题 我自己的实验环境是Ubuntu 18.04 with 4.15.0内核，在执行上面的make命令时，发生了以下的错误信息：\n... In file included from ./tools/perf/perf-sys.h:9:0, from samples/bpf/bpf_load.c:28: ./tools/perf/perf-sys.h: In function ‘sys_perf_event_open’: ./tools/perf/perf-sys.h:68:15: error: ‘test_attr__enabled’ undeclared (first use in this function) if (unlikely(test_attr__enabled)) ^ ./tools/include/linux/compiler.h:74:43: note: in definition of macro ‘unlikely’ # define unlikely(x) __builtin_expect(!!(x), 0) ^ ./tools/perf/perf-sys.h:68:15: note: each undeclared identifier is reported only once for each function it appears in if (unlikely(test_attr__enabled)) ^ ./tools/include/linux/compiler.h:74:43: note: in definition of macro ‘unlikely’ # define unlikely(x) __builtin_expect(!!(x), 0) ^ In file included from samples/bpf/bpf_load.c:28:0: ./tools/perf/perf-sys.h:69:3: warning: implicit declaration of function ‘test_attr__open’ [-Wimplicit-function-declaration] test_attr__open(attr, pid, cpu, fd, group_fd, flags); ^~~~~~~~~~~~~~~ scripts/Makefile.host:107: recipe for target \u0026#39;samples/bpf/bpf_load.o\u0026#39; failed make[1]: *** [samples/bpf/bpf_load.o] Error 1 Makefile:1823: recipe for target \u0026#39;samples/bpf/\u0026#39; failed make: *** [samples/bpf/] Error 2 根据错误信息，查看发生错误的文件为**./tools/perf/perf-sys.h**，报错的那一行是test开头的。通过Google发现了内核大佬们的邮件来往：https://www.spinics.net/lists/netdev/msg608676.html。大佬们建议由于是测试相关的代码，所以可以skip掉。修改完的文件在这里，请斟酌参考。重新运行make命令，错误不再发生了。\nmake samples/bpf/ # and it works 编译运行自己的BPF程序 如果你想利用Linux内核环境来编译自己的BPF程序，是非常方便的。只要对samples/bpf/目录下的Makefile进行一点点自定义改造即可，如果你仔细阅读了上面的分析，那么改造的原理就显而易见了：\n# 假设你自己BPF程序如下所示： # 内核空间代码：my_bpf_101_kern.c # 用户空间代码：my_bpf_101_user.c # 从上之下，添加新的代码行 # 1. 追加新的一行至hostprogs-y开头的代码块最后，保证自己的BPF程序能够生成可执行文件 hostprogs-y += my_bpf_101 # 2. 一般BPF程序使用以下命令即可，具体取决于你的程序是否依赖其他特殊头文件 my_bpf_101-objs := bpf_load.o $(LIBBPF) my_bpf_101_user.o # 3. 追加新的一行至always开头的代码块最后，保证触发生成可执行文件的任务 always += my_bpf_101_kern.o 一般的BPF程序只需要通过如上3处更新加入到Makefile中，就可以使用make samples/bpf/命令，生成你自己程序的可执行文件了。\n","permalink":"https://cloudnative.to/blog/compile-bpf-examples/","tags":["源码分析","Linux内核"],"title":"编译运行Linux内核源码中的eBPF示例代码"},{"categories":["Kubernetes"],"contents":"Kubernetes 诞生至今已经 5 年了，火爆整个社区，大家对 Kubernetes 越来越熟悉，越来越了解。但现阶段很多人都是熟练使用 Kubernetes，甚至我们会自嘲为 “YAML 工程师”。\n可是随着各类云原生应用的出现、Operator 理念的推广、深入维护 Kubernetes 的需求下，仅仅做一个 \u0026ldquo;YAML 工程师\u0026rdquo; 已经不能满足老板的要求了。需要我们进一步了解 Kubernetes 是如何实现的，该怎么扩展 Kubernetes。\n我在这样的场景下，开始学习 Kubernetes 编程，在这里总结了我学习到的 Kubernetes 编程的基础知识，让大家对 Kubernetes 编程有个大致的了解。\n基于 Kubernetes 编程 什么叫做基于 Kubernentes 编程呢？回想一下，我们以前听过基于 Linux 编程，基于 Windows 编程，可以放在‘基于’后面的都是通用标准的平台。基于 Kubernetes 编程有着相同的概念，Kubernetes 经过 5 年的高速发展，已经成为了容器编排调度框架的标准，直接将之定义为 “云原生操作系统” 也不为过。\n基于 Kubernnetes 编程可以定义为，开发一个 Kubernetes-native 应用，它直接与 K8S API Server（K8S 的一个核心组件，后面会介绍）交互，查询资源的状态或更新状态。\n为什么要基于 Kubernetes 编程呢？大多数基于 Kubernetes 编程的服务都属于 PaaS 层的能力，PaaS 将服务抽象成应用进行分发部署管理，并且对应用屏蔽底下 IaaS 的复杂度。PaaS 层是在 Kubernetes 诞生之前就存在的，在 Kubernetes 环境下以前很多 PaaS 层的应用都需要进行改造迁移，或者被云原生时代的新应用代替，随之诞生了服务网格、Operator 等云原生产物。\n这些需求都是要基于 Kubernetes 编程来实现的，因此掌握 Kubernetes 编程是做云原生开发，PaaS 平台的必备基础。\n学习 Kubernetes 编程后会对 Kubernetens 的各个组件有更加深刻的认知。比如你了解了 controller 架构模式  后就会知道（以下说法并不严谨，只列出组件中的部分功能）:\n kube-proxy 是 Service 资源和服务发现负载之间的协调控制器。 kubelet 是 Pod 资源和容器运行时之间的协调控制器。  了解 API Server 的架构后就知道， kubectl 其实是高级定制版的 curl 工具。\n扩展模式 Kubernetes 是一个强大的并且内聚的可扩展系统。 常用的有如下扩展点：\n 二进制 kubelet 插件，如 网络 (CNI)、设备、存储 (CSI)、容器运行时 (CRI) 二进制 kubectl 插件 API server 中的访问扩展，例如 webhooks 的动态准入控制 自定义资源（CRD）和自定义 controller 自定义 API servers 调度器扩展，例如使用 webhook 来实现自己的调度决策 通过 webhook 进行 身份验证  Kubernetes 提供了很强的扩展能力，其本身的很多组件也是使用了这种扩展能力来实现的。controller 模式是 Kubernetes 编程中通用性最强，使用最多的扩展能力。\nController 实现控制循环，通过 API Server 监听集群的共享状态，根据资源的当前状态做出反应更改真实世界，使将资源更接近期望状态。\n控制循环 The Control Loop 所有的控制器都按照以下逻辑运行:\n 由事件驱动来读取资源 (resources) 的状态 (state)。 更改集群内或集群外对象的状态 (state)。比如，启动一个 Pod，创建 Endpoint。 通过 API server 更新步骤 1 中的资源状态（status），存储到 etcd 中。 重复循环，返回步骤 1。  引用自《Programming Kubernetes》\n控制器组件 从架构的角度来看，Controller 通常使用一下数据结构:\n引用自 “深入剖析 Kubernetes”\n Informers 从 Kubernetes API Server 里监听它所关心的对象状态，Informer 与 API 对象是一一对应的。 Reflector 连接 APIServer，使用 ListAndWatch 方法，获取并监听 API 对象实例的变化。 变化事件及对应的 API 对象，被称为为增量，放进 Delta FIFO Queue。 Delta FIFO Queue 存放事件数据 Store 对象在本地的缓存 Indexer 查询与索引本地缓存的数据结构 ResourceEventHandler 在初始化时将事件类型对应的处理函数注册到 Informer，当事件触发时，由 Informer 调用 Handler Work queues 在执行周期里 (processNextWorkItem)，从工作队列 (workqueue) 中获取一个对象来处理。 event handler 可以通过它来排队或重试状态变化处理任务。 资源在处理中遇到错误时可以被重新入队 (requeued)。  事件 Event Kubernetes 控制平面大量使用事件和松散耦合的组件。 其他分布式系统常使用远程调用（RPC）来触发行为。 但 Kubernetes 并没有这么做。Kubernetes controller 监听 API server 中 Kubernetes 对象的操作：添加，更新和删除。 当发生此类事件时，controller 将执行其业务逻辑。\n例如，为了通过 deployment 来启动 pod，就涉及到许多 controller 和其他控制平面组件协同工作：\n Deployment controller（在 kube-controller-manager 内部）感知到（通过 deployment informer）用户创建了一个 deployment。根据其业务逻辑，它将创建一个 replica set。 Replica set controller（同样在 kube-controller-manager 内部）感知到（通过 replica set informer）新的 replica set 被创建了。并随后运行其业务逻辑，它将创建一个 pod 对象。 Scheduler（在 kube-scheduler 二进制文件内部）——同样是一个 controller，感知到（通过 pod informer）pod 设置了一个空的 spec.nodeName 字段。根据其业务逻辑，它将该 pod 放入其调度队列中。 与此同时，另一个 controller kubelet（通过其 pod informer）感知到有新的 pod 出现，但是新 pod 的 spec.nodeName 字段为空，因此与 kubelet 的 node name 不匹配。它会忽视该 pod 并返回休眠状态（直到下一个事件）。 Scheduler 更新 pod 中的 spec.nodeName 字段，并将该字段写入 API server，由此将 pod 从工作队列中移出，并调度到具有足够可用资源的 node 上。 由于 pod 的更新事件，kubelet 将被再次唤醒，这次再将 pod 的 spec.nodeName 与自己的 node name 进行比较，会发现是匹配的，接着 kubelet 将启动 pod 中的容器，并将容器已启动的信息写入 pod status 中， 由此上报给 API server。 Replica set controller 会感知到已更新的 pod，但并不会做什么。 如果 pod 终止，kubelet 将感知到该事件，进而从 API server 获取 pod 对象，并把 pod status 设置为 “terminated”，然后将其写回到 API server。 Replica set controller 会感知到终止的 pod，并决定必须更换此 pod。它将在 API server 上删除终止了的 pod，然后创建一个新的 pod。 依此类推。  许多独立的控制循环只通过 API server 上对象的变化进行通信，这些变化通过 informer 触发事件。\n书中第一章后面还介绍了事件驱动对应 I/O 模型选择，如何处理并发，Operator 等话题，参考后面给出的 [推荐阅读](# 推荐阅读) 继续阅读。\nI/O 模型的相关知识可以额外阅读《Linux/UNIX 系统编程手册》第 63 章。\nThe API Server Kubernetes 由一堆不同角色的节点（集群中机器）组成，如下图所示：主节点的控制面由 API Server，controller manager 和 scheduler 组成。API Server 是系统的中央管理实体（central management entity），它是系统中唯一个与分布式存储组件 etcd 进行直接交互的组件。\n主要完成以下任务：\n  为 Kubernetes API 提供服务\n 读取状态 (state) 操作状态 (state)    代理转发集群组件\n Kubernetes dashboard 代理 kubectl exec 会话    引用自《Programming Kubernetes》\nAPI Server HTTP 协议接口  API server 使用 RESTful HTTP API 外部请求正常使用 json 格式 内部调用使用 protocol buffer ，为了更高的性能 使用 API 路径参数，如 GET /api/v1/namespaces/{namespace}/pods  使用 kubectl 指令列出当前命名空间下的 pods，kubectl -n *THENAMESPACE* get pods。实际上会发出 GET /api/v1/namespaces/THENAMESPACE/pods 的 HTTP 请求，通过 -v 6 参数能看到 HTTP 请求的 log。\nI0804 10:55:47.463928 23997 loader.go:375] Config loaded from file: /root/.kube/config ... ... I0804 10:55:51.689482 23997 round_trippers.go:443] GET https://172.24.28.3:6443/api/v1/namespaces/default/pods?limit=500 200 OK in 36 milliseconds NAME READY STATUS RESTARTS AGE busybox 1/1 Running 119 4d23h redis-cli 1/1 Running 303 12d API 术语 弄清楚什么是 RESTful 架构 就很容易理解和区分 Kubernetes API Server 里面这些概念。 如果一个架构符合 REST 原则，就称它为 RESTful 架，REST 是 Representational State Transfer 的缩写，可以翻译为 \u0026ldquo;表现层状态转化\u0026rdquo;，这里省略了主语 “资源”（Resources)。 核心在于 “资源”，它是一种信息实体，可以有很多种外在表现形式，我们把 “资源” 具体呈现出来的形式，叫做它的 “表现层”（Representation）。\nRESTful API 是基于 HTTP 协议且符合 REST 原则的软件架构，controller 架构也符合 REST 原则。在 Kubernetes 中同时使用了这两种架构，所以弄出来了一些术语来区分指代实体，其实都是 “资源” 这一信息实体在不同上下文中的不同表示形态。\n    RESTful API controller 架构     实体类型 Resource Kind   实现方式 http controller   资源定位 URL Path GroupVersionKind    Kind 表示实体的类型。每个对象都有一个字段 Kind（JSON 中的小写 kind，Golang 中的首字母大写 Kind），该字段告诉如 kubectl 之类的客户端它表示什么类型。\nAPI group 在逻辑上相关的一组 Kind 集合。 如 Job 和 ScheduledJob 都在 batch API group 里。\nVersion 标示 API group 的版本更新， API group 会有多个版本 (version)。\n v1alpha1: 初次引入 v1beta1: 升级改进 v1: 开发完成毕业  在持续开发中，对象会发生变化，便用 Version 来标示版本变化。 对象会存储所有版本的对象属性的并集。但是在取出时指定版本，即只会取出这个版本所需要的对象定义。\nResource 通常是小写的复数词（例如，pod），用于标识一组 HTTP 端点（路径），来对外暴露 CURD 操作。\nGVR Resource 和 API group、Version 一起称为 GroupVersionResource（GVR），来唯一标示一个 HTTP 路径。\n引用自《Programming Kubernetes》\n声明式状态管理 controller 模式能运作的另一大原因是声明式状态管理，它规定资源必须要有在 spec 中定义的期望状态（desired state）, 和由 controller 补充的当前状态（current status），填写在 status 中。\nspec 定义的期望状态提供了实现 \u0026ldquo;infrastructure-as-code\u0026rdquo; 的基础，让 controller 可以在 event 触发、水平获取、定时同步的时候都可以获取到资源的期望状态。另一方面 status 的设计让 controller 了解到资源当前状态，进而作出操作来调协资源的当前状态与期望状态，再将调协后的当前状态写入 status。这种设计完全可以仍受因网络分区等原因造成的数据短暂不一致问题。\n举个例子，在一个 deployment 里你可能指定想要 20 个应用程序的副本（replicas）持续运行。deployment controller 作为控制面中 controller manager 的一部分，将读取你提供的 deployment spec，并创建一个 replica set 用于管理这些副本，再由 replicat set 来负责创建对应数量的 pods，最终结果是在工作节点上启动容器。如果任何的副本挂了，deployment controller 让你通过 status 可以感知到。这就是我们说的声明式状态管理（declarative state management），简而言之，就是声明期望的状态，剩下的交给 Kubernetes。\n推荐阅读 Programming Kubernetes 本文是阅读《Programming Kubernetes》书籍前两章时做的笔记与总结。\n这本书是由来自 AWS 和 Red Hat 的两位高级工程师写作的，他们自 2015 年以来就一直致力于 Kubernetes 的开发，写作，教学。\n书中主要围绕着 “Kubernetes 扩展编程 “ 主题讲了 Kubernetes 编程基础，client-go，自定义资源（CRD），Opeator，API Servers 扩展等内容。\n对于接触过云原生但不想仅仅停留在使用阶段的朋友，这本书值得一读，通过学习如何在 Kubernetes 基础上做开发，能让你更加了解 Kubernetes，后续可以深入阅读 Kubernetes 源码。\n这本书目前国内还未出版，可以去购买 ACM 会员，在 Oreilly 官网 上阅读。 或者加入 云原生社区，社区内分享了 Programming Kubernetes 中文版（腾讯内部翻译）。在 社区 Github 仓库 Issue 下回复即可。\nKubernetes 源码剖析 对 Kubernetes 编程有了基础的了解后，推荐大家阅读 《Kubernetes 源码剖析》，由来自百度 BFE 团队的郑东旭大佬写的。 前文说了，Kubernetes 本身的很多组件是通过 controller 模式来写的，对于我们编写 Kubernetes 扩展应用来说，是极好的样例代码。 书中第 3 章分析了 Kubernetes 核心数据结构，第 5 章详细的分析了在扩展编程时必不可少的依赖库 client-go，有需求的同学还可以根据第 2 章的说明自己构建 Kuberntes 组件。\n目前（2020-08）云原生社区正在组织 Kubernete 源码剖析精读活动，有兴趣的同学可以加入一起学习，具体信息查看 社区 Issue。\n深入剖析 Kubernetes 这是极客时间的课程，其中的第 23、24、25 节简短的过了一下 Kubernetes 编程。\n参考  理解 RESTful 架构 Kubernetes ApiServer 并发安全机制 深入剖析 Kubernetes  ","permalink":"https://cloudnative.to/blog/kubernetes-programming-base/","tags":["Kubernetes"],"title":"Kubernetes 编程基础知识"},{"categories":["学习小组"],"contents":"IT 技术日新月异，想必每个 IT 人都会有类似的焦虑：我该学习什么？哪些知识学到就是赚到？怎样学习才能最有效提升编程能力？\n阅读优秀的代码是提高编程能力万无一失的办法。诚然，提高编程能力的显著方法是写更多代码，但也需要静下心来品味优秀的代码，大侠行走江湖也需要武功秘籍，而当今优秀的开源项目代码便是程序员的武林秘籍。\n优秀的开源项目浩如烟海，应该如何选择适合自己的项目呢？\n选择方式有很多，比如项目使用到什么开源项目就学习该项目的源码，比如基于 Apache Dubbo 构建微服务，则可以学习 Dubbo 框架源码，理解其底层机制以及原理（比如服务治理），学以致用；阅读那些让你印象深刻或者自己可以掌握的源码，比如从一个小项目或者一个插件开始，也是不错的选择；最重要的是，大多数人时间有限但选择又太多，一定要选择适合自己的，能够融入自己的知识体系。如果你是云原生爱好者，那么阅读 Kubernetes 核心源码就是一个非常好的选择。\n找到一个合适的开源项目后，但在具体实践的时候常常因为一些不正确的看法而误入歧途，中途折戟：\n 缺乏自信，我并未参与该项目开发，因此我很难深入理解其源码 数据结构和算法很重要，所以只需要研究开源项目的数据结构和算法就够了 “Talk is cheap, show me the code”，一头扎进源码，只见树木不见森林  这些看法要么会让人半途而废又或者徒劳无功，那该如何更高效的学习开源项目的源码呢？\n简而言之，纵览全局，按需学习，由上及下，自下而上，避免一开始陷入细节。\n 纵览全局，运筹帷幄。在开始之前需要宏观上了解要学习的项目，了解其背景、功能、业务价值等等，学习方式非常多，比如项目网站、入门教程、官方文档目录等，方便我们快速纵览全局，了解项目主要组成部分。 按需学习，有所取舍。工作后时间有限精力有限，需要在纵览全局后辨别出哪三个功能是对自己最有益处的，摒弃其他模块，全力攻克对自己有价值的功能以及源码。 由上及下，先理解功能、原理以及关键设计后再剖析源码。 自下而上，从一个个实践问题剖析源码。 拓展联系，触类旁通。深度探索（比如 5W2H），横向拓展（比如多种 pod 调度算法横向对比），纵向类比（比如 Kubernetes 与数据库概念上的异同）。  读源码如读书，积累的越多，越熟练，读得越快。\n读书活动介绍 云原生是未来 10 年 IT 发展最重要的趋势，而 Kubernetes 正是云原生的基石。另一方面，《Kubernetes 源码剖析》深入浅出的讲解了 kubernetes 的架构以及核心源码，是进阶 Kubernetes 的不二之选。\n云原生社区 Kubernetes 源码研习社招募志同道合的热爱学习的小伙伴，共同研读《Kubernetes 源码剖析》。\n加入研习社方式 加入知识星球，扫码置顶二维码即可加入云原生社区的 Kubernetes 源码研习社\n欢迎加入 云原生社区\n你能收获什么？  对 Kubernetes 核心源码有更深刻的理解 一群热爱云原生的志同道合的朋友  ","permalink":"https://cloudnative.to/blog/study-groups/","tags":["学习小组"],"title":"如何学习开源项目源码"},{"categories":["Programming"],"contents":" 本文主要分享火焰图使用技巧，介绍 systemtap 的原理机制，如何使用火焰图快速定位性能问题原因，同时加深对 systemtap 的理解。\n 让我们回想一下，曾经作为编程新手的我们是如何调优程序的？通常是在没有数据的情况下依靠主观臆断来瞎蒙，稍微有些经验的同学则会对差异代码进行二分或者逐段调试。这种定位问题的方式不仅耗时耗力，而且还不具有通用性，当遇到其他类似的性能问题时，需要重复踩坑、填坑，那么如何避免这种情况呢？\n俗语有云：“工欲善其事，必先利其器。”个人认为，程序员定位性能问题也需要一件“利器”。 如同医生给病人看病，需要依靠专业的医学工具（比如 X 光片、听诊器等）进行诊断，最后依据医学工具的检验结果快速精准地定位出病因所在。性能调优工具（比如 perf / gprof 等）之于性能调优就像 X 光之于病人一样，它可以一针见血地指出程序的性能瓶颈。\n但是常用的性能调优工具 perf 等，在呈现内容上只能单一地列出调用栈或者非层次化的时间分布，不够直观。这里我推荐大家配合使用火焰图，它将 perf 等工具采集的数据呈现得更为直观。\n初识火焰图 火焰图（Flame Graph）是由 Linux 性能优化大师 Brendan Gregg 发明的，和所有其他的 profiling 方法不同的是，火焰图以一个全局的视野来看待时间分布，它从底部往顶部，列出所有可能导致性能瓶颈的调用栈。\n火焰图整个图形看起来就像一个跳动的火焰，这就是它名字的由来。\n火焰图有以下特征（这里以 on-cpu 火焰图为例）：\n 每一列代表一个调用栈，每一个格子代表一个函数； 纵轴展示了栈的深度，按照调用关系从下到上排列，最顶上格子代表采样时，正在占用 cpu 的函数； 横轴的意义是指：火焰图将采集的多个调用栈信息，通过按字母横向排序的方式将众多信息聚合在一起。需要注意的是它并不代表时间； 横轴格子的宽度代表其在采样中出现频率，所以一个格子的宽度越大，说明它是瓶颈原因的可能性就越大； 火焰图格子的颜色是随机的暖色调，方便区分各个调用信息； 其他的采样方式也可以使用火焰图， on-cpu 火焰图横轴是指 cpu 占用时间，off-cpu 火焰图横轴则代表阻塞时间； 采样可以是单线程、多线程、多进程甚至是多 host，进阶用法可以参考附录进阶阅读；  火焰图类型 常见的火焰图类型有 On-CPU，Off-CPU，还有 Memory，Hot/Cold，Differential 等等。他们分别适合处理什么样的问题呢？\n这里笔者主要使用到的是 On-CPU、Off-CPU 以及 Memory 火焰图，所以这里仅仅对这三种火焰图作比较，也欢迎大家补充和斧正。\n火焰图分析技巧  纵轴代表调用栈的深度（栈桢数），用于表示函数间调用关系：下面的函数是上面函数的父函数； 横轴代表调用频次，一个格子的宽度越大，越说明其可能是瓶颈原因； 不同类型火焰图适合优化的场景不同，比如 on-cpu 火焰图适合分析 cpu 占用高的问题函数，off-cpu 火焰图适合解决阻塞和锁抢占问题； 无意义的事情：横向先后顺序是为了聚合，跟函数间依赖或调用关系无关；火焰图各种颜色是为方便区分，本身不具有特殊含义； 多练习：进行性能优化有意识的使用火焰图的方式进行性能调优（如果时间充裕）；  如何绘制火焰图？ 要生成火焰图，必须要有一个顺手的动态追踪工具，如果操作系统是 Linux 的话，那么通常通常是 perf 或者 systemtap 中的一种。其中 perf 相对更常用，多数 Linux 都包含了 perf 这个工具，可以直接使用；SystemTap 则功能更为强大，监控也更为灵活。网上关于如何使用 perf 绘制火焰图的文章非常多而且丰富，所以本文将以 SystemTap 为例。\nSystemTap 是动态追踪工具，它通过探针机制，来采集内核或者应用程序的运行信息，从而可以不用修改内核和应用程序的代码，就获得丰富的信息，帮你分析、定位想要排查的问题。SystemTap 定义了一种类似的 DSL 脚本语言，方便用户根据需要自由扩展。不过，不同于动态追踪的鼻祖 DTrace ，SystemTap 并没有常驻内核的运行时，它需要先把脚本编译为内核模块，然后再插入到内核中执行。这也导致 SystemTap 启动比较缓慢，并且依赖于完整的调试符号表。\n使用 SystemTap 绘制火焰图的主要流程如下：\n 安装 SystemTap 以及 操作系统符号调试表 根据自己所需绘制的火焰图类型以及进程类型选择合适的脚本 生成内核模块 运行 SystemTap 或者运行生成的内核模块统计数据 将统计数据转换成火焰图  本文演示步骤将会基于操作系统 Tlinux 2.2 ( Linux 内核版本3.10.107)\n安装 SystemTap 以及 操作系统符号调试表 使用 yum 工具安装 systemtap:\nyum install systemtap systemtap-runtime 由于 systemtap 工具依赖于完整的调试符号表，而且生产环境不同机器的内核版本不同（虽然都是Tlinux 2.2版本，但是内核版本后面的小版本不一样，可以通过 uname -a 命令查看）所以我们还需要安装 kernel-debuginfo 包、 kernel-devel 包 我这里是安装了这两个依赖包\nkernel-devel-3.10.107-1-tlinux2-0046.x86_64 kernel-debuginfo-3.10.107-1-tlinux2-0046.x86_64 根据自己所需绘制的火焰图类型以及进程类型选择合适的脚本 使用 SystemTap 统计相关数据往往需要自己依照它的语法，编写脚本，具有一定门槛。幸运的是，github 上春哥（agentzh）开源了两组他常用的 SystemTap 脚本：openresty-systemtap-toolkit 和 stapxx，这两个工具集能够覆盖大部分 C 进程、nginx 进程以及 Openresty 进程的性能问题场景。\n我们这里需要绘制 off-cpu 火焰图，所以使用 sample-bt-off-cpu 脚本即可\n生成内核模块 现在我们有了统计脚本，也安装好了 systemtap，正常来说就可以使用了，但由于 systemtap 是通过生成内核模块的方式统计相关探针的统计数据，而 tlinux 要求所有运行的内核模块需要先到 tlinux 平台签名才可以运行，所以：\n故需要先修改 off-cpu 脚本，让其先生成内核模块；之后对该内核模块作签名；最后使用 systemtap 命令手工运行该脚本，统计监控数据。\nSystemtap 执行流程如下：\n parse：分析脚本语法 elaborate：展开脚本 中定义的探针和连接预定义脚本库，分析内核和内核模块的调试信息 translate：.将脚本编译成c语言内核模块文件放 在$HOME/xxx.c 缓存起来，避免同一脚本多次编译 build：将c语言模块文件编译成.ko的内核模块，也缓存起来。 把模块交给staprun，staprun加载内核模块到内核空间,stapio连接内核模块和用户空间，提供交互IO通道,采集数据。  所以我们这里修改下 off-cpu 的 stap 脚本，让其只运行完第四阶段，只生成一个内核模块\n// 在 stap 命令后增加 -p4 参数，告诉systemtap，当前只需要执行到第四阶段 open my $in, \u0026#34;|stap -p4 --skip-badvars --all-modules -x $pid -d \u0026#39;$exec_path\u0026#39; --ldd $d_so_args $stap_args -\u0026#34; or die \u0026#34;Cannot run stap: $!\\n\u0026#34;; 修改好之后运行脚本，会生成一个内核模块\n// -p 8682 是需要监控的进程的进程号 // -t 30 是指会采样30秒 ./sample-bt-off-cpu -p 8692 -t 30 生成的内核模块名称形如 stap_xxxxx.ko模块名称 由于读者并不需要关心内核模块签名，故章节略过\n运行内核模块统计数据 内核模块签名完成后，便可以使用 staprun 命令手工运行相关内核模块了\n命令：\n// 注意：签名脚本会将生产的内核模块重命名，需要将名字改回去……（脚本bug） staprun -x {进程号} {内核模块名} \u0026gt; demo.bt 值得注意的是，监控的进程要有一定负载 systemtap 才可以采集到相关数据，即在采集时，同时需要要有一定请求量（通常是自己构造请求，压测进程）\n将统计数据转换成火焰图 获得了统计数据 demo.bt 后，便可以使用火焰图工具绘制火焰图了\n下载 FlameGraph，链接：https://github.com/brendangregg/FlameGraph\n命令：\n./stackcollapse-stap.pl demo.bt \u0026gt; demo.folded ./flamegraph.pl demo.folded \u0026gt; demo.svg 这样便获得了 off-cpu 火焰图：\n看图说话 趁热打铁，通过几张火焰图熟悉下如何使用火焰图\n图片源于春哥微博或者本人近期绘制的性能火焰图\non-cpu 火焰图 Apache APISIX QPS急剧下降问题 Apache APISIX 是一个开源国产的高性能 API 网关，之前在进行选型压测时，发现当 Route 匹配不中场景下， QPS 急剧下降，在其 CPU （四十八核）占用率几乎达到100%的情况下只有几千 QPS，通过绘制火焰图发现，其主要耗时在一个 table 插入阶段(lj_cf_table_insert)，分析代码发现是该 table 一直没有释放，每次匹配不中时，路由会向一张用于统计的表中插入一条数据，导致该表越来越大，后续插入耗时过长导致 QPS 下降。\noff-cpu 火焰图 nginx 互斥锁问题 这是一张 nginx 的 off-cpu 火焰图，我们可以很快锁定到 ngx_common_set_cache_fs_size -\u0026gt; ngx_shmtx_lock -\u0026gt; sem_wait 这段逻辑使用到了互斥锁，它让 nginx 进程绝大部分阻塞等待时间花费在获取该锁。\nagent 监控上报断点问题 这是一张 agent 的 off-cpu 火焰图，它是一个多线程异步事件模型，主线程处理各个消息，多个线程分别负责配置下发或者监控上报。当前问题出现在监控上报性能差，无法在周期（一分钟）内完成监控数据上报，导致监控断点，通过 off-cpu 火焰图我们可以分析出，该上报线程花费了大量的时间使用 curl_easy_perform 接口收发 http 监控数据消息。\n依据火焰图将发送 http 消息的逻辑改为异步非阻塞后，该问题解决。\n附录 进阶阅读  谷歌搜索演讲：Blazing Performance with Flame Graphs 演讲 ppt：https://www.slideshare.net/brendangregg/blazing-performance-with-flame-graphs 《SystemTap新手指南》：https://spacewander.gitbooks.io/systemtapbeginnersguide_zh/content/index.html 极客时间《Linux性能优化实战》\u0026ndash;倪朋飞  FAQ 使用 perf 或者 systemtap 的方式采集数据，会对后台服务有性能影响吗？\n有，但是很小，可以基本忽略不计。\n它们使用系统的探针或者使用一些自定义的动态探针进行数据采集，第一对代码无侵入性，它既不需要停止服务，也不需要修改应用程序的代码；第二，它们是以内核模块/内核原生的方式跟踪用户态和内核态的所有事件，并通过一系列优化措施，进行采样统计，对目标服务性能影响极小，大概在5%左右或者更低的性能损耗。相较于将进程运行在沙箱的 valgrind 工具或静态调试工具 gdb 来说，动态追踪 perf 或者 systemtap 或者 ebpf 的性能损耗基本可以忽略不计。\n目标进程重启后，systemtap 是否需要重新生成内核模块？\n不需要。甚至同一个 linux 内核版本下的同一个二进制进程（md5值一致），在安装 kernel 调试符号表后，便可以在生成采集指标的内核模块，并且可以多次使用。\n当 linux 内核版本不一致，符号表有变化，需要重新生成内核模块；当目标进程二进制文件重新编译后，也需要重新生成统计用的 systemtap 内核模块。\n","permalink":"https://cloudnative.to/blog/flame-graph/","tags":["profile","flamegraph"],"title":"性能调优利器--火焰图"},{"categories":["Istio"],"contents":"背景 Istio 从发布开始就使用 Envoy 作为自己的数据平面，充分利用了 Envoy 提供的服务发现、路由、熔断、负载均衡等功能。与此同时，Istio 项目也一直致力于提供一个便于灵活扩展的平台，以满足用户多样化的需求。在过去的一年半中， Google 的团队一直在努力用 WebAssembly 技术为 Envoy 代理添加动态扩展，并推出了针对 Envoy 代理的 WebAssembly (以下简称为WASM) 扩展机制，包括标准化的 ABI，SDK，以及该扩展机制的第一个重点实现：全新的、低延迟的 Istio 遥测系统。\n本文主要对 Envoy 和 WebAssembly 技术进行介绍，并使用 solo.io 团队推出的 wasme 工具完成 WASM filter 的构建、发布和部署，方便读者了解 Envoy WASM Filter 的扩展方式及其实现原理。\nEnvoy 的过滤器机制 Envoy 是 Istio 中的 Sidecar 官方标配，是一个面向服务架构的高性能网络代理，由 C++ 语言实现，拥有强大的定制化能力。Envoy 提供了进程外架构、支持L3/L4 filter、HTTP L7 filter、服务发现和动态配置、健康检查等高级功能。这里我们重点介绍一下 Envoy 流量处理过程中的 filter 机制。\n过滤器机制 Envoy 是面向服务架构设计的L7代理和通信总线，核心是一个 L3/L4 网络代理。可插入 filter 链机制允许开发人员编写 filter 来执行不同的 TCP 代理任务并将其插入到主体服务中。Envoy 还支持额外的 HTTP L7 filter 层。可以将 HTTP filter 插入执行不同任务的 HTTP 连接管理子系统。\n目前，Envoy 提供的过滤器包括侦听器过滤器（Listener Filters）、网络过滤器（Network Filters）、HTTP过滤器（HTTP Filters）三种类型，它们共同组成了一个层次化的过滤器链。\n1、侦听器过滤器\n侦听器过滤器在初始连接阶段访问原始数据并操作 L4 连接的元数据。例如，TLS 检查器过滤器（TLS Inspector Filter）标识连接是否经过 TLS 加密，并解析与该连接关联的 TLS 元数据（SNI或ALPN协商的协议类型）；HTTP Inspector Filter 检测应用协议是否是 HTTP，如果是的话，再进一步检测 HTTP 协议类型 (HTTP/1.x or HTTP/2) ，这两种过滤器解析到的元数据都可以和 FilterChainMatch 结合使用。\n2、网络过滤器\n网络过滤器访问和操作 L4 连接上的原始数据，即TCP数据包。例如，TCP代理过滤器（TCP Proxy Filter）将客户端连接数据路由到上游主机，它还可以生成连接统计数据。此外，MySQL proxy、Redis proxy、Dubbo proxy、Thrift proxy等都属于网络过滤器。\n3、HTTP过滤器\nHTTP 过滤器在 L7 上运行，由网络过滤器（即 HTTP 连接管理器，HTTP Connection Manager）创建。这些过滤器用于访问、操作 HTTP 请求和响应，例如，gRPC-JSON 转码器过滤器（gRPC-JSON Transcoder Filter）可以为 gRPC 后端提供一个 REST API，并将请求和响应转换为相应的格式。此外，还包括 JWT、Router、RBAC 等多种过滤器。\n整体来看，Envoy 的过滤器机制为用户提供了很多好处，比如：用户可以创建一个中间层，以便在与不兼容的服务器通信时优雅地处理客户端请求；代理可以执行协议转换，允许不同的协议互操作；代理可以通过过滤器做出智能路由决策等。\n扩展方式 现有的 Filter 可能无法满足用户的使用需求，这时候就需要对 Envoy 进行功能扩展，通过在现有的过滤链基础上自定义新的 filter，实现定制化需求。用户可以通过以下三种方式对 Envoy 进行扩展。\n1、编写 C++ 代码扩展 Envoy\n这种方式直接在 Envoy 基础上编写 C++ 代码进行功能增强，实现自定义的 filter 之后，重新编译新的二进制可执行文件，完成现有业务的升级替换。这种方式有以下两方面问题：\n受语言限制，只能使用 C++ 进行扩展，不利于生态发展； 提高了部署、运维、升级的复杂性，Envoy将会变得越来越重，并且每次更改都需要重新编译二进制文件，不利于技术迭代和管理。\n2、使用 lua 脚本扩展 filter\nLua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。HTTP Lua Filter 允许在请求和响应流程中运行 Lua 脚本，在运行时使用 LuaJIT。该过滤器仅支持在配置中直接加载 Lua 代码。\n目前支持的主要功能包括：对传输的请求或响应流，提供头部、正文和尾部的检查；对头部和尾部进行修改；对上游主机执行异步HTTP调用；直接执行响应并跳过后续的过滤器等。\n然而，HTTP Lua Filter 是实验性的，在生产中使用需要自担风险。若存在非常复杂或更高性能的场景，建议使用本地 C++ 过滤器。\n3、使用 WASM 扩展 envoy\n为了提供更加方便、更加灵活的扩展方式，Google 团队计划用 WebAssembly 为 Envoy 代理添加动态扩展。用户可以使用自己擅长的编程语言编写 filter，并使用工具编译成 wasm 格式，嵌入到 Envoy 中运行即可。目前，Google 也与社区紧密合作，以确保为用户提供良好的开发者体验，帮助用户快速上手。Google 团队也一直与 Solo.io 团队紧密合作，Solo 团队已经建立了 WebAssembly Hub 服务，用于构建，共享，发现和部署 WASM 扩展。有了 WebAssembly Hub，WASM 扩展就会像容器一样易于管理，安装和运行。\nWASM 概述 介绍 WebAssembly（WASM）是一种由多种语言编写的，可移植的字节码格式，它能以接近本机的速度执行。作为一种可移植、体积小、加载快并且兼容 Web 的全新格式，wasm具有以下特点：\n 高效：WASM 有一套完整的语义，实际上 WASM 是体积小且加载快的二进制格式， 其目标就是充分发挥硬件能力以达到原生执行效率。 安全：WASM 运行在一个沙箱化的执行环境中，甚至可以在现有的 JavaScript 虚拟机中实现。 开放：WASM 设计了一个非常规整的文本格式，用于调试、测试、实验、优化、学习、教学或者编写程序。 标准：WASM 在 web 中被设计成无版本、特性可测试、向后兼容的特点。WASM 不仅可以运行在浏览器上，也可以运行在非web环境下。  需要注意的是，WASM 是一个编译目标，不是一种编程语言。WebAssembly 是经过编译器编译之后的目标格式，体积小、起步快。在语法上完全脱离 JavaScript，同时具有沙盒化的执行环境。\n尽管 WASM 最初是作为客户端技术诞生的，但它应用于服务器端时也有很多优势。比如运行时是内存安全的，并且以沙盒方式运行以确保其安全性。\n工具链 这里简单介绍一下 WASM 编译相关的工具链。传统的编译器设计都是三步式的：Frontend(前端)，Optimizer（优化器），Backend(后端)。\n Frontend ：源代码解析，错误检查，然后构建一个语言相关的抽象语法树(AST)来表示输入的代码。 Optimizer：优化器会做很多的转换来减少代码的运行时间，比如说减少冗余的计算。 Backend：将优化后的代码映射到目标指令集，也可以被称为代码生成器。  而在一个基于 LLVM 的编译器中，一个 Frontend 的任务是对源代码进行解析、错误诊断，然后将解析后的的代码转换为 LLVM IR（Intermediate Representation），IR 会经过一系列的分析和优化以便提高代码性能，最后基于优化后的代码生成相应的机器代码。这种方式十分灵活，当扩展编程语言或硬件类型时，添加对应的前端或后端即可，优化阶段则成为了一个通用的阶段。\nEmscripten 的底层就是 LLVM 编译器，可以将 LLVM 字节码编译成 JavaScript，还支持 WebAssembly 这一更加先进的 Web 技术，可以生成 WASM 字节码文件。\nWASM与Envoy和Istio Istio 引入 WebAssembly 该特性在 Istio 1.5 自带的 Envoy 中以 Alpha 版本推出，其源代码在 envoy-wasm 开发分支中，并且正在努力将其合并到 Envoy 主干上。该实现使用了 Google 高性能 V8 引擎 中内置的 WebAssembly 运行时。\n除了构建底层的运行时，Google 团队还开展了以下关键工作：\n 制定 Wasm 嵌入代理的通用应用程序二进制接口（ABI），这意味着编译后的扩展将可以在不同版本的 Envoy 中工作，甚至其它代理也可以，前提是其它代理实现了 ABI 用 C++, Rust 和 AssemblyScript 可以方便进行扩展开发的 SDK，后续还会支持更多类型的编程语言 全面的示例和说明，介绍如何在 Istio 和独立的 Envoy 中部署 允许使用其它 WASM 运行时的抽象，包括把扩展直接编译进 Envoy 中 “null” 运行时，这对于测试和调试非常有用  使用 WASM 扩展 Envoy 带来了很多好处：\n 敏捷性：可以用 Istio 控制平面在运行时下发和重载扩展，这就可以快速的进行开发、测试、发布，而无需重启 Envoy。 可靠性和隔离性：扩展模块部署在具有资源限制的沙箱中，这意味着虽然该模块可能崩溃或泄漏内存，但不会让整个 Envoy 挂掉。 灵活性：可以将多种编程语言编译为 WASM，让各种技术背景的开发人员都可以选择自己的语言来编写 Envoy 扩展，比如：C++，Go，Rust，Java，TypeScript 等。  WASME 实践 Solo.io 团队发布了 WebAssembly Hub，这是一套为 Envoy 和 Istio 准备的，用于构建、部署、共享和发现 Envoy Proxy WASM 扩展的工具和仓库。\nWebAssembly Hub 将开发和部署 Wasm 扩展所需的许多步骤都自动化了。使用 WebAssembly Hub 提供的工具，用户可以轻松地把任何受支持语言开发的代码编译为 WASM 扩展，并将这些扩展上传到 Hub 仓库，使用单个命令就将其在 Istio 中部署和删除。\nWebAssembly Hub 工具提供了功能强大的 CLI 和优雅且易于使用的图形用户界面，该产品的一个重要目标是简化构建 WASM 模块的体验。下面介绍一下使用 wasme 工具开发、构建和部署 filter 的整体流程。\n1、安装 wasme cli\nwasme 命令行工具用于构建、管理 wasm filter，作用和流程有点像 docker 构建和管理容器。\n# 安装wasme curl -sL https://run.solo.io/wasme/install | sh export PATH=$HOME/.wasme/bin:$PATH # 查看版本号 wasme --version 2、初始化filter项目\n创建一个新的filter项目：\nwasme init ./new-filter 根据命令行的提示可以知道，现在只支持cpp、assemblyscript两种语言；可以选择部署到 Istio 或 Gloo 平台。这里我们选择cpp、istio选项，完成项目创建。\n我们可以看一下生成的项目包括哪些文件：\n# tree . |-- bazel | `-- external | |-- BUILD | |-- emscripten-toolchain.BUILD | `-- envoy-wasm-api.BUILD |-- BUILD |-- filter.cc |-- filter.proto |-- README.md |-- runtime-config.json |-- toolchain | |-- BUILD | |-- cc_toolchain_config.bzl | |-- common.sh | |-- emar.sh | `-- emcc.sh `-- WORKSPACE 3 directories, 14 files 这些文件的作用分别为：\n BUILD：用于编译 filter 的 bazel 编译文件 WORKSPACE：用于编译 filter 的 bazel WORKSPACE 文件 bazel/：bazel 外部依赖 toolchain/：编译 WASM 模块的 bazel 工具链 filter.cc：filter 源代码，这里是C++语言 filter.proto：filter配置的 protobuf schema runtime-config.json：和 filter 镜像共同存储的 config 文件，用于在运行时加载 filter  这里重点关注 filter.cc 文件即可，里面定义了一组接口和实现，只需要对相关的方法进行修改，就可以实现自定义的filter。其他文件主要用于编译，可以看到这里也引入了 emscripten 工具链，用于编译成 wasm 字节码格式。\n3、修改和编译\n这里我们在响应头添加一组 header 信息，以验证 filter 功能是否符合预期。\nFilterHeadersStatus AddHeaderContext::onResponseHeaders(uint32_t) { LOG_DEBUG(std::string(\u0026#34;onResponseHeaders \u0026#34;) + std::to_string(id())); addResponseHeader(root_-\u0026gt;header_name_, root_-\u0026gt;header_value_); replaceResponseHeader(\u0026#34;location\u0026#34;, \u0026#34;envoy-wasm\u0026#34;); addResponseHeader(\u0026#34;hello\u0026#34;, \u0026#34;world!\u0026#34;); return FilterHeadersStatus::Continue; } 接下来使用 wasme 命令编译 filter，这里会自动拉取quay.io/solo-io/ee-builder镜像完成编译过程，构建完成的filter镜像将会存储在本地的 registry中。\nwasme build cpp -t webassemblyhub.io/sunboy0213/add-header:v0.1 . 查看本地编译完成的filter镜像：\nwasme list NAME TAG SIZE SHA UPDATED webassemblyhub.io/sunboy0213/add-header v0.1 1.0 MB 72ad74e2 15 Apr 20 11:03 CST 这里可以看一下我们最终编译生成的文件如下，目标文件 filter.wasm 只有 1021K，可以很方便的集成到 envoy 中。\nls store/41aabc92e1f91207d4b4e12385fd5bca/ -alh total 1.1M drwxr-xr-x 2 root root 4.0K Apr 15 12:19 . drwxr-xr-x 4 root root 4.0K Apr 15 12:19 .. -rw-r--r-- 1 root root 226 Apr 15 20:58 descriptor.json -rw-r--r-- 1 root root 1021K Apr 15 20:58 filter.wasm -rw-r--r-- 1 root root 44 Apr 15 20:58 image_ref -rw-r--r-- 1 root root 128 Apr 15 20:58 runtime-config.json 4、推送到 WebAssembly hub\n这里需要首先注册https://webassemblyhub.io账号，然后将本地编译完成的镜像推送到远程仓库。\n# 登录账号 wasme login -u $YOUR_USERNAME -p $YOUR_PASSWORD # 推送镜像 wasme push webassemblyhub.io/sunboy0213/add-header:v0.1 # 查找我的远程镜像 wasme list --search $YOUR_USERNAME 5、部署到istio集群\n这一步的前提是已经搭建了 Istio 运行环境，并部署好了 bookinfo 示例应用。测试服务间的访问连通性如下：\n# kubectl exec -ti deploy/productpage-v1 -c istio-proxy -- curl -v http://details:9080/details/123 * Trying 172.18.233.86... * TCP_NODELAY set * Connected to details (172.18.233.86) port 9080 (#0) \u0026gt; GET /details/123 HTTP/1.1 \u0026gt; Host: details:9080 \u0026gt; User-Agent: curl/7.58.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; content-type: application/json \u0026lt; server: istio-envoy \u0026lt; date: Thu, 23 Apr 2020 09:16:53 GMT \u0026lt; content-length: 180 \u0026lt; x-envoy-upstream-service-time: 1 \u0026lt; x-envoy-peer-metadata: Ch4KDElOU1RBTkNFX0lQUxIOGgwxNzIuMTYuMC4yMDYK1QEKBkxBQkVMUxLKASrHAQoQCgNhcHASCRoHZGV0YWlscwohChFwb2QtdGVtcGxhdGUtaGFzaBIMGgo3NWQ5NGM0OGY1CiQKGXNlY3VyaXR5LmlzdGlvLmlvL3Rsc01vZGUSBxoFaXN0aW8KLAofc2VydmljZS5pc3Rpby5pby9jYW5vbmljYWwtbmFtZRIJGgdkZXRhaWxzCisKI3NlcnZpY2UuaXN0aW8uaW8vY2Fub25pY2FsLXJldmlzaW9uEgQaAnYxCg8KB3ZlcnNpb24SBBoCdjEKGgoHTUVTSF9JRBIPGg1jbHVzdGVyLmxvY2FsCiUKBE5BTUUSHRobZGV0YWlscy12MS03NWQ5NGM0OGY1LTdibHhtChYKCU5BTUVTUEFDRRIJGgdkZWZhdWx0Ck4KBU9XTkVSEkUaQ2t1YmVybmV0ZXM6Ly9hcGlzL2FwcHMvdjEvbmFtZXNwYWNlcy9kZWZhdWx0L2RlcGxveW1lbnRzL2RldGFpbHMtdjEKJQoPU0VSVklDRV9BQ0NPVU5UEhIaEGJvb2tpbmZvLWRldGFpbHMKHQoNV09SS0xPQURfTkFNRRIMGgpkZXRhaWxzLXYx \u0026lt; x-envoy-peer-metadata-id: sidecar~172.16.0.206~details-v1-75d94c48f5-7blxm.default~default.svc.cluster.local \u0026lt; x-envoy-decorator-operation: details.default.svc.cluster.local:9080/* \u0026lt; * Connection #0 to host details left intact {\u0026#34;id\u0026#34;:123,\u0026#34;author\u0026#34;:\u0026#34;William Shakespeare\u0026#34;,\u0026#34;year\u0026#34;:1595,\u0026#34;type\u0026#34;:\u0026#34;paperback\u0026#34;,\u0026#34;pages\u0026#34;:200,\u0026#34;publisher\u0026#34;:\u0026#34;PublisherA\u0026#34;,\u0026#34;language\u0026#34;:\u0026#34;English\u0026#34;,\u0026#34;ISBN-10\u0026#34;:\u0026#34;1234567890\u0026#34;,\u0026#34;ISBN-13\u0026#34;:\u0026#34;123-1234567890\u0026#34;} 部署我们刚才定制开发的filter：\nwasme deploy istio webassemblyhub.io/sunboy0213/add-header:v0.1 --id=myfilter 再次访问，可以发现响应头已经增加了 \u0026ldquo;hello: world!\u0026rdquo; 键值对。注意：该部署过程会触发pod重建操作。\nkubectl exec -ti deploy/productpage-v1 -c istio-proxy -- curl -v http://details:9080/details/123 * Trying 172.18.233.86... * TCP_NODELAY set * Connected to details (172.18.233.86) port 9080 (#0) \u0026gt; GET /details/123 HTTP/1.1 \u0026gt; Host: details:9080 \u0026gt; User-Agent: curl/7.58.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; content-type: application/json \u0026lt; server: istio-envoy \u0026lt; date: Thu, 23 Apr 2020 09:20:12 GMT \u0026lt; content-length: 180 \u0026lt; x-envoy-upstream-service-time: 2 \u0026lt; : \u0026lt; location: envoy-wasm \u0026lt; hello: world! \u0026lt; x-envoy-peer-metadata: Ch4KDElOU1RBTkNFX0lQUxIOGgwxNzIuMTYuMC4yMDgK1QEKBkxBQkVMUxLKASrHAQoQCgNhcHASCRoHZGV0YWlscwohChFwb2QtdGVtcGxhdGUtaGFzaBIMGgo3NzdkOGY1NDc1CiQKGXNlY3VyaXR5LmlzdGlvLmlvL3Rsc01vZGUSBxoFaXN0aW8KLAofc2VydmljZS5pc3Rpby5pby9jYW5vbmljYWwtbmFtZRIJGgdkZXRhaWxzCisKI3NlcnZpY2UuaXN0aW8uaW8vY2Fub25pY2FsLXJldmlzaW9uEgQaAnYxCg8KB3ZlcnNpb24SBBoCdjEKGgoHTUVTSF9JRBIPGg1jbHVzdGVyLmxvY2FsCiUKBE5BTUUSHRobZGV0YWlscy12MS03NzdkOGY1NDc1LWY0Z3c0ChYKCU5BTUVTUEFDRRIJGgdkZWZhdWx0Ck4KBU9XTkVSEkUaQ2t1YmVybmV0ZXM6Ly9hcGlzL2FwcHMvdjEvbmFtZXNwYWNlcy9kZWZhdWx0L2RlcGxveW1lbnRzL2RldGFpbHMtdjEKJQoPU0VSVklDRV9BQ0NPVU5UEhIaEGJvb2tpbmZvLWRldGFpbHMKHQoNV09SS0xPQURfTkFNRRIMGgpkZXRhaWxzLXYx \u0026lt; x-envoy-peer-metadata-id: sidecar~172.16.0.208~details-v1-777d8f5475-f4gw4.default~default.svc.cluster.local \u0026lt; x-envoy-decorator-operation: details.default.svc.cluster.local:9080/* \u0026lt; * Connection #0 to host details left intact {\u0026#34;id\u0026#34;:123,\u0026#34;author\u0026#34;:\u0026#34;William Shakespeare\u0026#34;,\u0026#34;year\u0026#34;:1595,\u0026#34;type\u0026#34;:\u0026#34;paperback\u0026#34;,\u0026#34;pages\u0026#34;:200,\u0026#34;publisher\u0026#34;:\u0026#34;PublisherA\u0026#34;,\u0026#34;language\u0026#34;:\u0026#34;English\u0026#34;,\u0026#34;ISBN-10\u0026#34;:\u0026#34;1234567890\u0026#34;,\u0026#34;ISBN-13\u0026#34;:\u0026#34;123-1234567890\u0026#34;} 6、生产环境的部署\n前面我们使用的 wasme 命令行提供了一种编译、部署 wasm filter 的简单方式，可以方便的在开发和测试环境中使用，但该方式显然无法用于声明式、无状态的k8s生产环境中。\n为此，官方推荐使用 Wasme Operator 管理 Service Mesh 集群中的 wasm filter。主要包括两个组件：\n 镜像缓存：从 filter registry 拉取 filter 镜像，并缓存到本地，该组件以 DaemonSet 的形式进行部署； operator：安装、配置 wasm filter 到数据面代理，以 Kubernetes Deployment 的形式部署。  用户提交的 FilterDeployment 示例如下：\napiVersion: wasme.io/v1 kind: FilterDeployment metadata: name: bookinfo-custom-filter namespace: bookinfo spec: deployment: istio: kind: Deployment filter: config: \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;world\u0026#34;}\u0026#39; image: webassemblyhub.io/ilackarms/istio-test:1.5.0-0 工作原理分析 刚才我们使用 wasme 命令行工具完成了 wasm filter 的构建、部署过程，其背后的工作原理简单描述如下：\n 由 Wasme Operator 设置 wasm filter 的本地缓存信息，同时生成 EnvoyFilter 资源提交给k8s； 镜像缓存模块拉取需要的 wasm filter 到本地缓存中，该模块以 DaemonSet 的形式部署在集群节点中； 缓存模块拉取完成后，将 wasm 文件挂载到目标的workload中； 同时，Istiod 监测到 EnvoyFilter 变更，通过 xDS API 将 wasm 文件的信息下发到 envoy 代理。  目前，WASM 扩展是通过 mount 机制来分发给对应的 workload，这种方式显然不够灵活，理想的方案是通过网络拉取 WASM 文件，完成实时加载。针对该问题，社区也正在积极优化。\n结合前面的实践内容和原理分析，这里我们可以查看已经添加的 EnvoyFilter 资源。\n[root@c-wfodwhfz-aaxyxwyz ~]# kubectl get envoyfilters.networking.istio.io NAME AGE details-v1-myfilter 50m productpage-v1-myfilter 50m ratings-v1-myfilter 50m reviews-v1-myfilter 50m reviews-v2-myfilter 50m reviews-v3-myfilter 50m 这里的 EnvoyFilter 是 Istio 提供的一种资源对象，用来更新配置 Envoy 中的 filter，为服务网格控制面提供了强大的扩展能力。可以详细看一下 productpage-v1-myfilter 的具体描述。\napiVersion: networking.istio.io/v1alpha3 kind: EnvoyFilter metadata: creationTimestamp: \u0026#34;2020-04-23T09:19:34Z\u0026#34; generation: 1 name: productpage-v1-myfilter namespace: default resourceVersion: \u0026#34;9071122\u0026#34; selfLink: /apis/networking.istio.io/v1alpha3/namespaces/default/envoyfilters/productpage-v1-myfilter uid: b528b175-5e08-4b08-85ed-a324a2418a64 spec: configPatches: - applyTo: HTTP_FILTER match: context: SIDECAR_INBOUND listener: filterChain: filter: name: envoy.http_connection_manager subFilter: name: envoy.router patch: operation: INSERT_BEFORE value: config: config: name: myfilter rootId: add_header_root_id vmConfig: code: local: filename: /var/local/lib/wasme-cache/72ad74e260c99fd77bbfd62f5dfab16af666dbdee8bacca39d97eafe60c69584 runtime: envoy.wasm.runtime.v8 vmId: myfilter name: envoy.filters.http.wasm workloadSelector: labels: app: productpage version: v1 该配置内容通过 xDS API 下发到 Envoy 代理之后，envoy 的运行时配置就会出现如下类型的 http filter，可以看到该 filter 指定了wasm文件的位置，并将wasm的运行时设置为v8引擎，从而实现了 wasm filter 的加载和运行。\n{ \u0026#34;name\u0026#34;: \u0026#34;envoy.filters.http.wasm\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;config\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;myfilter\u0026#34;, \u0026#34;rootId\u0026#34;: \u0026#34;add_header_root_id\u0026#34;, \u0026#34;vmConfig\u0026#34;: { \u0026#34;code\u0026#34;: { \u0026#34;local\u0026#34;: { \u0026#34;filename\u0026#34;: \u0026#34;/var/local/lib/wasme-cache/72ad74e260c99fd77bbfd62f5dfab16af666dbdee8bacca39d97eafe60c69584\u0026#34; } }, \u0026#34;runtime\u0026#34;: \u0026#34;envoy.wasm.runtime.v8\u0026#34;, \u0026#34;vmId\u0026#34;: \u0026#34;myfilter\u0026#34; } } } }, 小结 本文首先介绍了 Envoy 的过滤器模型和 WASM 扩展技术，并结合 Solo 团队提供的 wasme 工具完成了 WASM 扩展的构建、部署过程，最后对背后的工作原理进行了分析。可以看到，使用 WASM 可以很方便的将自定义 filter 集成到 Envoy 中，实现 Envoy 代理的功能增强，同时我们也发现 envoy-wasm 仍然处于初步阶段，在支持的语言类型、运行性能、部署运维等方面仍然有待完善，相信在社区的不断努力下，WASM 技术能够走向成熟并应用于更多的使用场景中。\n参考 重新定义代理的扩展性：Envoy 和 Istio 引入 WebAssembly\n如何高效地编写Envoy过滤器！第1部分\nWebAssembly for Proxies (ABI specification)\nDeclarative WebAssembly deployment for Istio\n","permalink":"https://cloudnative.to/blog/envoy-wasm/","tags":["Istio","Envoy","WASM"],"title":"Istio 进阶学习系列 - 基于 WebAssembly 实现 Envoy 与 Istio 的功能扩展"},{"categories":["Etcd"],"contents":" 作者介绍：aoho，一线码农，对云原生、微服务、Go 语言、容器化感兴趣，并做了深入研究。闲暇时间会分享一些技术思考和实践，与大家讨论交流，共同进步。\n 0 专辑概述 etcd 是云原生架构中重要的基础组件，由 CNCF 孵化托管。etcd 在微服务和 Kubernates 集群中不仅可以作为服务注册于发现，还可以作为 key-value 存储的中间件。\n《彻底搞懂 etcd 系列文章》将会从 etcd 的基本功能实践、API 接口、实现原理、源码分析，以及实现中的踩坑经验等几方面具体展开介绍 etcd。预计会有 20 篇左右的文章，笔者将会每周持续更新，欢迎关注。\n1 etcd 介绍 etcd 是 CoreOS 团队于 2013 年 6 月发起的开源项目，它的目标是构建一个高可用的分布式键值(key-value)数据库。具有以下特点：\n 简单：安装配置简单，而且提供了 HTTP API 进行交互，使用也很简单 键值对存储：将数据存储在分层组织的目录中，如同在标准文件系统中 监测变更：监测特定的键或目录以进行更改，并对值的更改做出反应 安全：支持 SSL 证书验证 快速：根据官方提供的 benchmark 数据，单实例支持每秒 2k+ 读操作 可靠：采用 raft 算法，实现分布式系统数据的可用性和一致性  etcd 采用 Go 语言编写，它具有出色的跨平台支持，很小的二进制文件和强大的社区。 etcd 机器之间的通信通过 Raft 算法处理。\netcd 是一个高度一致的分布式键值存储，它提供了一种可靠的方式来存储需要由分布式系统或机器集群访问的数据。它可以优雅地处理网络分区期间的 leader 选举，以应对机器的故障，即使是在 leader 节点发生故障时。\n从简单的 Web 应用程序到 Kubernetes 集群，任何复杂的应用程序都可以从 etcd 中读取数据或将数据写入 etcd。\netcd 于 2018 年 12 月正式加入云原生计算基金会(CNCF，全称 Cloud Native Computing Foundation)，并由 CNCF 支持。CNCF 是一个厂商中立的基金会、云原生技术推广和普及的领导者。\n2 使用场景 etcd 比较多的应用场景是用于服务注册与发现，除此之外，也可以用于键值对存储，应用程序可以读取和写入 etcd 中的数据。\n一个简单的用例是将数据库连接详细信息或功能标志存储在 etcd 中作为键值对。 可以观察这些值，使我们的应用在更改时可以重新配置自己。高级用法是利用 etcd 的一致性保证来实施数据库 leader 选举或在一组 follower 之间执行分布式锁定。\n2.1 键值对存储  A highly-available key value store for shared configuration and service discovery.\n一个用于配置共享和服务发现的键值存储系统。\n 归根结底，etcd 是一个键值存储的组件，其他的应用都是基于其键值存储的功能展开。etcd 的存储有如下特点：\n 采用kv型数据存储，一般情况下比关系型数据库快。 支持动态存储(内存)以及静态存储(磁盘)。 分布式存储，可集成为多节点集群。 存储方式，采用类似目录结构。  只有叶子节点才能真正存储数据，相当于文件。 叶子节点的父节点一定是目录，目录不能存储数据。    etcd leader 的延迟是要跟踪的最重要的指标，并且内置仪表板具有专用于此的视图。在我们的测试中，严重的延迟会在群集内造成不稳定，因为 Raft 的速度仅与大多数机器中最慢的机器一样快。我们可以通过适当地调整群集来缓解此问题。etcd 已在具有高度可变网络的云提供商上进行了预调。\n2.2 服务注册与发现 服务注册与发现(Service Discovery)要解决的是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务如何才能找到对方并建立连接。从本质上说，服务发现就是要了解集群中是否有进程在监听 UDP 或者 TCP 端口，并且通过名字就可以进行查找和链接。\n要解决服务发现的问题，需要下面三大支柱，缺一不可。\n  强一致性、高可用的服务存储目录。 基于 Raft 算法的 etcd 天生就是这样一个强一致性、高可用的服务存储目录。\n  一种注册服务和服务健康状况的机制。 用户可以在 etcd 中注册服务，并且对注册的服务配置 key TTL，定时保持服务的心跳以达到监控健康状态的效果。\n  一种查找和连接服务的机制。通过在 etcd 指定的主题下注册的服务业能在对应的主题下查找到。为了确保连接，我们可以在每个服务机器上都部署一个 Proxy 模式的 etcd，这样就可以确保访问 etcd 集群的服务都能够互相连接。\n  etcd2 中引入的 etcd/raft 库，是目前最稳定、功能丰富的开源一致性协议之一。作为 etcd、TiKV、CockcorachDB、Dgraph 等知名分布式数据库的核心数据复制引擎，etcd/raft 驱动了超过十万个集群，是被最为广泛采用一致性协议实现之一。etcd3 中引入的多版本控制、事务等功能，大大的简化了分布式应用的开发流程，提高了效率和稳定性。经过 5 年的演进，etcd 也已经成为了各种容器编排系统的默认存储选项。Kubernetes 是流行的容器平台，运行在任何环境的 Kubernetes 集群都依赖 etcd 来提供稳定而可靠的存储服务。\n2.3 消息发布与订阅 在分布式系统中，最适用的一种组件间通信方式就是消息发布与订阅。即构建一个配置共享中心，数据提供者在这个配置中心发布消息，而消息使用者则订阅他们关心的主题，一旦主题有消息发布，就会实时通知订阅者。通过这种方式可以做到分布式系统配置的集中式管理与动态更新。\n应用中用到的一些配置信息放到 etcd 上进行集中管理。这类场景的使用方式通常是这样：应用在启动的时候主动从 etcd 获取一次配置信息，同时，在 etcd 节点上注册一个Watcher并等待，以后每次配置有更新的时候，etcd 都会实时通知订阅者，以此达到获取最新配置信息的目的。\n分布式搜索服务中，索引的元信息和服务器集群机器的节点状态存放在etcd中，供各个客户端订阅使用。使用etcd的key TTL功能可以确保机器状态是实时更新的。\n分布式日志收集系统。这个系统的核心工作是收集分布在不同机器的日志。收集器通常是按照应用（或主题）来分配收集任务单元，因此可以在 etcd 上创建一个以应用（主题）命名的目录P，并将这个应用（主题相关）的所有机器ip，以子目录的形式存储到目录P上，然后设置一个 etcd 递归的Watcher，递归式的监控应用（主题）目录下所有信息的变动。这样就实现了机器IP（消息）变动的时候，能够实时通知到收集器调整任务分配。\n系统中信息需要动态自动获取与人工干预修改信息请求内容的情况。通常是暴露出接口，例如 JMX 接口，来获取一些运行时的信息。引入 etcd 之后，就不用自己实现一套方案了，只要将这些信息存放到指定的 etcd 目录中即可，etcd 的这些目录就可以通过 HTTP 的接口在外部访问。\n2.4 分布式通知与协调 这里说到的分布式通知与协调，与消息发布和订阅有些相似。在分布式系统中，最适用的一种组件间通信方式就是消息发布与订阅。即构建一个配置共享中心，数据提供者在这个配置中心发布消息，而消息使用者则订阅他们关心的主题，一旦主题有消息发布，就会实时通知订阅者。通过这种方式可以做到分布式系统配置的集中式管理与动态更新。\n这里用到了 etcd 中的 Watcher 机制，通过注册与异步通知机制，实现分布式环境下不同系统之间的通知与协调，从而对数据变更做到实时处理。实现方式通常是这样：不同系统都在 etcd 上对同一个目录进行注册，同时设置 Watcher 观测该目录的变化（如果对子目录的变化也有需要，可以设置递归模式），当某个系统更新了 etcd 的目录，那么设置了 Watcher 的系统就会收到通知，并作出相应处理。\n通过 etcd 进行低耦合的心跳检测。检测系统和被检测系统通过 etcd 上某个目录关联而非直接关联起来，这样可以大大减少系统的耦合性。\n通过 etcd 完成系统调度。某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改了 etcd 上某些目录节点的状态，而 etcd 就把这些变化通知给注册了Watcher的推送系统客户端，推送系统再作出相应的推送任务。\n通过 etcd 完成工作汇报。大部分类似的任务分发系统，子任务启动后，到 etcd 来注册一个临时工作目录，并且定时将自己的进度进行汇报（将进度写入到这个临时目录），这样任务管理者就能够实时知道任务进度。\n2.5 分布式锁 当在分布式系统中，数据只有一份（或有限制），此时需要利用锁的技术控制某一时刻修改数据的进程数。与单机模式下的锁不仅需要保证进程可见，分布式环境下还需要考虑进程与锁之间的网络问题。\n分布式锁可以将标记存在内存，只是该内存不是某个进程分配的内存而是公共内存如 Redis、Memcache。至于利用数据库、文件等做锁与单机的实现是一样的，只要保证标记能互斥就行。\n因为etcd使用Raft算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。\n保持独占即所有获取锁的用户最终只有一个可以得到。etcd 为此提供了一套实现分布式锁原子操作 CAS （CompareAndSwap）的 API。通过设置 prevExist 值，可以保证在多个节点同时去创建某个目录时，只有一个成功。而创建成功的用户就可以认为是获得了锁。\n控制时序，即所有想要获得锁的用户都会被安排执行，但是获得锁的顺序也是全局唯一的，同时决定了执行顺序。etcd 为此也提供了一套 API（自动创建有序键），对一个目录建值时指定为 POST 动作，这样 etcd 会自动在目录下生成一个当前最大的值为键，存储这个新的值（客户端编号）。同时还可以使用API按顺序列出所有当前目录下的键值。此时这些键的值就是客户端的时序，而这些键中存储的值可以是代表客户端的编号。\n3. 小结 本章主要介绍了 etcd 的相关概念，以及 etcd 主要的使用场景。etcd 在分布式环境中是一个利器，在一致性存储方面有广泛的应用。下一篇将会具体介绍 etcd 的安装以及使用的实践。\n参考 etcd\n","permalink":"https://cloudnative.to/blog/etcd-1/","tags":["etcd"],"title":"彻底搞懂 etcd 系列文章（一）：初识 etcd"},{"categories":["Operator"],"contents":"导言 2018年 kubecon 大会上，阿里的陈俊大佬分享 Node-operator 的主题让我印象深刻，回来之后开始着手研究 Operator。正好当时老板希望能够将公司正在使用的 Nosql 组件容器化，顺势给老板安利一波 Operator 的思想。随后以 opentsdb 的容器为开端，后续完成一系列组件容器化，一路走来不断学习和借鉴其他 operator 的先进经验。Zookeeper作为最新完成 operator 化的组件，除了可以快速部署以外，还实现了 Operator 对 scale up/down 的进度干预，控制 rolling 的重启顺序，感知组件实际运行状态等，具体实现请阅读对于相关章节。\n功能需求 目前 operator 主要实现如下功能：\n 快速部署 安全伸缩容 自动化监控 故障自愈 可视化操作  CRD Operator 设计第一步是定义声明式接口的 Item，spec 主要包含节点资源、监控组件、副本数、持久化存储。\napiVersion: database.ymm-inc.com/v1beta1 kind: ZooKeeper metadata: name: zookeeper-sample spec: version: v3.5.6 cluster: name: test resources: requests: cpu: 1000m memory: 2Gi limits: cpu: 2000m memory: 2Gi exporter: exporter: true exporterImage: harbor.ymmoa.com/monitoring/zookeeper_exporter exporterVersion: v3.5.6 disableExporterProbes: false nodeCount: 3 storage: size: 100Gi 架构图 Operator 主要包含：Deploy、Monitor、Scale 三个大模块。\n Deploy：主要用于生成和创建 Statefulset、Service、ConfigMap、PV 等原生资源，用于快速部署 zookeeper 集群。 Monitor：主要用于生成和创建 ServiceMonitor、PrometheusRule 资源，用于自动化注册 target、添加告警策略，实现对集群的监控和告警。 Scale：主要用于把控扩缩容以及滚动升级的进度，确保以最少的主从切换完成重启。  具体方案 快速部署 基本知识   Kubernetes Labels\n Labels：是一对 key/value，被关联到特定对象上，标签一般用来表示同一类资源，用来划分特定的对象，一个对象可以有多个标签，但是，key 值必须是唯一的。这里我们将在 list-watch 的时候用这个 labels 进行过滤，从所有的 Kubernetes event 中过滤出符合特定 label 的 event，用来触发 operator 的主流程。    Kubernetes Informer\n  watch：可以是 Kubernetes 内建的资源或者是自定义的资源。当 reflector 通过 watch API 接收到有关新资源实例存在的通知时，它使用相应的列表 API 获取新创建的对象，并将其放入 watchHandler 函数内的 Delta Fifo 队列中。\n  Informer：informer 从 Delta Fifo 队列中弹出对象。执行此操作的功能是 processLoop。Base controller 的作用是保存对象以供以后检索，并调用我们的控制器将对象传递给它。\n  Indexer：索引器提供对象的索引功能。典型的索引用例是基于对象标签创建索引。 Indexer 可以根据多个索引函数维护索引。Indexer 使用线程安全的数据存储来存储对象及其键。 在 Store 中定义了一个名为 MetaNamespaceKeyFunc 的默认函数，该函数生成对象的键作为该对象的 / 组合。\n    Labels labels: app: zookeeper app.kubernetes.io/instance: zookeeper-sample app.kubernetes.io/managed-by: zookeeper-operator app.kubernetes.io/name: zookeeper app.kubernetes.io/part-of: zookeeper component: zookeeper zookeeper: zookeeper-sample 节点部署 容器分类  InitContainer  配置文件初始化容器，主要用于 zk config 文件复制到工作区域。   Container  主进程容器 监控容器 Agent    初始化容器  zoo.cfg.dynamic，这个文件同样以 configmap 方式挂入主容器，主要用于zk节点发现和注册，下面将详细介绍下这个zk 3.5之后的特性。\n  具体可以参考 ZooKeeper 动态重新配置  server.1=zookeeper-sample-0.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181 server.2=zookeeper-sample-1.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181 server.3=zookeeper-sample-2.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181 server.4=zookeeper-sample-3.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181 server.5=zookeeper-sample-4.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181  更新目录权限   设置 data 和 logs 目录的权限，确保 zk 能够正常启动。\n echo \u0026#34;chowning /data to zookeeper:zookeeper\u0026#34; chown -v zookeeper:zookeeper /data echo \u0026#34;chowning /logs to zookeeper:zookeeper\u0026#34; chown -v zookeeper:zookeeper /logs 主进程容器  环境变量   POD_IP、POD_NAME，主要将 node 的 pod ip 和名称传到 pod 内部，方便容器内部调用。\nZK_SERVER_HEAP，这变量为限制 zk 启动 heapsize 大小，由 operator 根据 request 内部大小设置，zk启动会读取这个变量。\n - name: POD_IP valueFrom: fieldRef: apiVersion: v1 fieldPath: status.podIP - name: POD_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name - name: ZK_SERVER_HEAP value: \u0026#34;2048\u0026#34; - name: ZK_CLIENT_HEAP value: \u0026#34;512\u0026#34;  Readiness探针   主要通过 zk 客户端端口传入 ruok 命令，检查返回码，返回 imok 认为 zk node 已经准备完毕，zk node 将会被更新到上面说到的 zoo.cfg.dynamic 文件，zk cluster 将会自动发现该节点。\n ZK_CLIENT_PORT=${ZK_CLIENT_PORT:-2181} OK=$(echo ruok | nc 127.0.0.1 $ZK_CLIENT_PORT) if [ \u0026#34;$OK\u0026#34; == \u0026#34;imok\u0026#34; ]; then exit 0 else exit 1 fi 监控容器  github 项目（https://github.com/dabealu/zookeeper-exporter） exporter 跟随主进程一同启动，后续会介绍如何注册到 prometheus target 以及告警策略。\n 访问控制  暴露端口   9114：该端口为 exporter 服务端口，通过 servicemonitor 注册 prometheus target 时将通过 labels 匹配该端口。\n1988：该端口为 zk-agent 服务端口，通过该接口 operator 可以查询到当前节点运行状态，后面会详解介绍。\n2181：该端口为 zk 客户端端口，该端口创建 Kubernetes headless 模式 svc，方便客户端一次获取所有节点 ip。\n3888：选举 leader 使用\n2888：集群内机器通讯使用（ Leader 监听此端口）\n ports: - name: client port: 2181 protocol: TCP targetPort: 2181 - name: server port: 2888 protocol: TCP targetPort: 2888 - name: leader-election port: 3888 protocol: TCP targetPort: 3888 - name: http-metrics port: 9114 protocol: TCP targetPort: 9114 - name: http-agent port: 1988 protocol: TCP targetPort: 1988  暴露方式   这里主要 kubernetes service 的两种模式：Headless 和 Cluster\n Headless Services：简单而言就是，每次访问 headless service，kube-dns 将返回后端一组 ip，在我们这种场景下，即会返回 es 所有节点 ip 给客户端，再由客户端自己判断通过哪个 ip 访问 es 集群。\nCluster：这种模式是默认配置，创建此类 service 之后，将分配一个 cluster ip，这个 ip 类似 vip，每次访问这个 service name，kube-dns 将会随机返回一个节点 ip。\n operator 在创建 service 的时候，上面两种都会创建，headless 类型主要给 kubernetes 内部应用访问，cluster 类型主要通过 NodePort 暴露给外部应用访问。\n 配置信息  配置文件  autopurge.purgeInterval=24 autopurge.snapRetainCount=20 initLimit=10 syncLimit=5 skipACL=yes maxClientCnxns=300 4lw.commands.whitelist=cons, envi, conf, crst, srvr, stat, mntr, ruok tickTime=2000 dataDir=/data dataLogDir=/logs reconfigEnabled=true standaloneEnabled=false dynamicConfigFile=/conf/zoo.cfg.dynamic.c00000002 数据存储  PersistentVolume   StorageClass PROVISIONER: diskplugin.csi.alibabacloud.com，阿里云CSI插件实现了 Kubernetes 平台使用阿里云云存储卷的生命周期管理，支持动态创建、挂载、使用云数据卷。 当前的 CSI 实现基于kubernetes 1.14以上的版本。\n云盘 CSI 插件支持动态创建云盘数据卷、挂载数据卷。云盘是一种块存储类型，只能同时被一个负载使用(ReadWriteOnce)。\noperator 会将 CRD 中配置的 pvc 信息，透传到 sts 中去，并挂载到 zk data 目录下 。\n 自动化监控 监控注册 ServiceMonitor selector.matchLabels：这里通过 zookeeper: zookeeper-sample 来匹配 service。\nport: http-metrics：这里通过匹配 service 中到 port name 来注册到 prometheus target。\noperator 调用 prometheus-operator client 完成 ServiceMonitor 资源的创建，实现新建zk集群自动注册到prometheus的功能。\napiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: labels: app: zookeeper app.kubernetes.io/instance: zookeeper-sample app.kubernetes.io/managed-by: zookeeper-operator app.kubernetes.io/name: zookeeper app.kubernetes.io/part-of: zookeeper component: zookeeper zookeeper: zookeeper-sample name: zookeeper-sample namespace: default spec: endpoints: - interval: 30s port: http-metrics namespaceSelector: {} selector: matchLabels: zookeeper: zookeeper-sample PrometheusRule operator 调用 prometheus-operator client 完成 PrometheusRule 资源的创建，实现将告警策略自动注册到 prometheus。\n告警策略中的 dingtalkRobot 标签，主要用来重定向告警信息到指定钉钉群中，这里可以添加多个钉钉群机器人。\n安全伸缩容 扩缩节点   更新 Zookeeper CR 中 spec.cluster.nodeCount 配置。\n  触发 operator 主流程，判断期望副本数大于实际副本数继续流程，否则退出主流程。\n  更新 zk 集群 records，提交两种 record：\n  Zookeeper upscale from 3 to 4.\n  Zookeeper Statefulset %s already update.\n    更新 zk 集群 StatefulSet 资源，StatefulSet 控制器将会新建节点，zk 将新建节点加入集群中，数据将会自动做同步。\n  Reconfig 模块将从集群中添加或者剔除节点\n  扩资源   更新 Zookeeper CR 中 spec.node.resources 配置。\n  如果zk节点数与期望节点数不一致，退出主流程，直到节点数一致，所有 pod 全部 ready。\n  通过节点数量检查之后，更新 StatefulSet 资源，由于我们这边 StatefulSet 设置的 RollingUpdate 策略为 OnDelete，即更新 StatefulSet 配置之后，StatefulSet 将不会主动重启节点以完成升级，需要我们自己手动去重启节点。\n  获取当前集群中节点角色，将 leader 节点放到最后重启，尽量减少集群不可用时间。\n  operator 比对 StatefulSet 和 pod resourceVersion值，如果不一致将节点加入到需要重启节点列表中。\n  operator 执行对节点如下检查项：\n  当前重启中对节点是否超过 MaxUnavailable 值，目前 MaxUnavailable 值默认为1.\n  跳过节点状态为 Terminating 的节点。\n    从重启节点中取一个节点，调用 kubernetes 接口，执行重启操作。\n  第一个节点重启完成之后，将 requeue 主流程，继续其他节点重启。\n  所有节点全部重启完成，滚动升级成功。\n  故障自愈 Observer   operator 会为每一个创建的 zk 集群启动一个 observer，每个 observer 将会启动两个 goroutine：\n  GetClusterStatus，获取 zk-agent /status 接口数据。\n  GetClusterUp，获取 /runok 接口数据。\n    operator 将每10秒获取集群最新状态，包括集群状态、node 节点数、leader 节点等。\n  operator 获取到最新集群状态之后，将更新CR的 status 中，达到实时更新 CR 中 zk 集群状态的功能，效果如下图。\n  status: availableNodes: 3 leaderNode: zookeeper-sample-1.zookeeper-sample.default.svc.cluster.local  如果zk集群被销毁, operator 将调用 finalizers 方法停止 observer 协程。  触发主流程   operator 控制器在初始化的时候，将 watch 一个自定义的 event channel，等待 event 通过 channel 传递过来，触发主控流程执行。\n  observer 初始化的时候，创建一个 listeners 函数数组，用于 observer 状态刷新时候调用，每新建一个 zk 集群将加入一个 listener。\n  observer 执行一次，listeners 数组中的函数将会执行一次，获取最新各个 zk 集群的 health 状态。\n  listeners 数组的函数将判断，集群新状态与老状态是否一致，一致则返回 nil，否则进一步处理。\n  如果状态不一致将传值到 event channel，由 watch 消费以触发 operator 主控流程执行。\n  可视化操作 可视化操作，主要实现一下功能：\n zk 集群的查询、创建、伸缩、资源调整 支持多 kubernetes 环境 支持集群监控展示  多kubernetes环境 对于多 kubernetes 环境的支持，主要通过在每个环境部署 agent 组件，组件通过 rbac 进行授权，确保agent组件只能操作指定资源。将 agent 注册到管理平台，管理平台按照环境请求不同环境接口即可。\n接口列表    模式 接口 说明 备注     GET /zookeeper/list 查询所有zookeeper集群信息    POST /zookeeper/info 查询单个zookeeper集群信息    POST /zookeeper/create 创建单个zookeeper集群    POST /zookeeper/update 更新单个zookeeper集群    POST /zookeeper/delete 销毁单个zookeeper集群     参数校验 Admission Webhooks  ValidatingWebhook：主要实现验证检测，即检查通过 kubernetes API client 提交到CR参数是否合法，如果不符合要求直接拒绝资源创建。检查项如下：  检查节点资源，request CPU/mem 是否小于 limit CPU/mem   MutatingWebhook：主要实现注入默认参数，即检查到提交参数缺少一些关键性参数，将由 webhook 补齐并注入到创建资源中。补全项如下：  节点资源限制，比如request cpu/mem和limit cpu/mem。 exporter配置，默认开启exporter，    Exporter: true, ExporterImage: \u0026#34;harbor.ymmoa.com/monitoring/zookeeper_exporter\u0026#34;, ExporterVersion: \u0026#34;1.1.0\u0026#34;, DisableExporterProbes: false, 升级策略 StatefulSets 提供了多种升级策略：OnDelete，RollingUpdate，RollingUpdate with partition。\nOnDelete的一般方法 使用 OnDelete，除非 Pod 的数量高于预期的副本数，否则 StatefulSet 控制器不会从 StatefulSet 中删除 Pod。\nOperator 决定何时要删除 Pod。一旦删除，便会由 StatefulSet 控制器自动重新创建一个 Pod，该 Pod 具有相同的名称，但是最新的规范。\n我们的操作员永远不会创建 Pod，但是当我们决定准备删除 Pod 时，它将负责 Pod 的删除。\n当对 StatefulSet 进行修改时（例如，更改 Pod 资源限制），我们最终得到一个新的 revision（基于模板规范的哈希值）。\n查看 StatefulSet 状态，我们可以获得当前的修订版（currentRevision: zookeeper-sample-7b889dd5b4），使用该修订版的容器的数量以及仍在使用旧修订版的容器的数量（updateRevision: zookeeper-sample-74597f9b9d）。\n通过列出该 StatefulSet 中的 Pod，我们可以检查每个 Pod（metadata.labels[\u0026ldquo;controller-revision-hash\u0026rdquo;]: \u0026ldquo;zookeeper-sample-7b889dd5b4\u0026rdquo;）的当前版本。\nRollingUpdate.Partition 方法 使用此策略，我们定义了一个 partition 索引：这允许使用 StatefulSet 控制器替换序数高于此索引的 Pod。\n例如，如果我们有一个带有5个副本的 StatefulSet：\n zookeeper-sample-0 zookeeper-sample-1 zookeeper-sample-2 zookeeper-sample-3 zookeeper-sample-4  如果分区索引为3，则允许 StatefulSet 控制器自动删除然后重新创建 Pod zookeeper-sample-3 和 zookeeper-sample-4。\n在此模式下，操作员永远不会删除 Pod。它所做的就是：\n 当应添加新容器或应除去容器时，更新 StatefulSets 副本 当应更换某些 Pod 时更新分区索引  要对上面的 StatefulSet 进行滚动升级，我们将从索引开始5，确保4可以安全地替换 Pod ，然后将索引更新为4。这将触发更换 Pod。\nOnDelete 除了不显式删除 Pod 而是管理索引外，其他逻辑与适用相同。\nAgent zk agent 作为 sidecar 伴随主容器一并启动，提供如下接口：\n status：返回宿主 zk 节点当前运行状态，参考 zk srvr 命令。 runok：返回宿主 zk 节点是否正常运行且无错误，参考 zk ruok 命令。 health：返回 agent 运行状态，用于 agent 的心跳检测。 get：返回 zk 集群节点列表，查询 /zookeeper/config 文件。 add：增加节点到 zk 集群中，主要依赖 zk reconfigure 特性，集群扩容时使用。 del：从现有 zk 集群中删除某个节点，如果删除节点是主节点，会先做主节点切换，之后才会移除节点，集群缩容时使用。  接口列表    模式 接口 说明 备注     GET /status getZkStatus    GET /runok getZkRunok    GET /health Health    GET /get getMember    POST /add addMember    POST /del delMember     GET /status, 获取当前 zk 节点运行状态，字段含义对照 mntr 查看信息，包括如下字段：\n{ \u0026#34;Sent\u0026#34;: 1617, \u0026#34;Received\u0026#34;: 1618, \u0026#34;NodeCount\u0026#34;: 5, \u0026#34;MinLatency\u0026#34;: 0, \u0026#34;AvgLatency\u0026#34;: 2, \u0026#34;MaxLatency\u0026#34;: 5, \u0026#34;Connections\u0026#34;: 1, \u0026#34;Outstanding\u0026#34;: 0, \u0026#34;Epoch\u0026#34;: 14, \u0026#34;Counter\u0026#34;: 82, \u0026#34;BuildTime\u0026#34;: \u0026#34;2019-10-08T20:18:00Z\u0026#34;, \u0026#34;Mode\u0026#34;: 2, //0表示Unknown，1代表Leader，2代表follower \u0026#34;Version\u0026#34;: \u0026#34;3.5.6-c11b7e26bc554b8523dc929761dd28808913f091\u0026#34;, \u0026#34;Error\u0026#34;: null } /runok，获取当前节点是否正常启动。\n/health，获取 zk-agent 是否正常启动。\n/get，获取当前 Reconfig 动态配置节点信息。\n{ \u0026#34;record\u0026#34;: \u0026#34;server.1=zookeeper-sample-0.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181\\nserver.2=zookeeper-sample-1.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181\\nserver.3=zookeeper-sample-2.zookeeper-sample.default.svc.cluster.local:2888:3888:participant;0.0.0.0:2181\\nversion=c00000002\u0026#34; } POST /add，获取客户端传入需要新增的节点信息，并更新到动态节点配置中。\n/del，获取客户端传入需要删除到节点信息，并更新到动态节点配置中。传入值参考 add 接口格式。\nOAM对接  OAM 是一个专注于描述应用的标准规范。有了这个规范，应用描述就可以彻底与基础设施部署和管理应用的细节分开。这种关注点分离（Seperation of Conerns）的设计好处是非常明显的。\n 应用组件（Components）  组件（Components）：概念让平台架构师等能够将应用分解成成一个个可被复用的模块，这种模块化封装应用组成部分的思想，代表了一种构建安全、高可扩展性应用的最佳实践：通过一个完全分布式的架构模型，实现了应用组件描述和实现的解耦。\n 按照应用组件的定义，对应到目前zk operator的快速部署模块上，部署模块主要生成和创建原生资源，完成容器化zk集群搭建，并持续维持声明式定义的集群终态。部署模块可以单独定义CRD, 比如 workload.zookeeper.example.com。\n应用运维特征（Traits）  运维特征（Traits）：它们描述了应用在具体部署环境中的运维特征，比如应用的水平扩展的策略和 Ingress 规则，这些特征对于应用的运维来说非常重要，但它们在不同的部署环境里却往往有着截然不同的实现方式。\n Traits则对应 zk operator 模块中的 伸缩、滚动升级两个模块，这两个模块可以抽出来定义为单独CRD，比如 scale.zookeeper.example.com 和 rolling.zookeeper.example.com。\n小结 目前 zk operator 的实现能力也仅仅实现 部署、伸缩、滚动升级、监控等能力，还有很多模块可以做，比如：备份、重置、迁移、调度策略、暂停等等。\n参考文档   阿里云携手微软与 Crossplane 社区发布 OAM Kubernetes 标准实现与核心依赖库 OAM 正式开源：全球首个云原生应用标准定义与架构模型  ","permalink":"https://cloudnative.to/blog/zookeeper-operator/","tags":["zookeeper","operator","OAM"],"title":"Zookeeper operator 实战"},{"categories":["开源"],"contents":"前言 开源已经无处不在，当下已经很难找到一款软件是完全和开源没有任何关系的了。开源软件，正在成为现代社会的基础设施。\n“Open up your phone. Your social media, your news, your medical records, your bank: they are all using free and public code.” - Nadia Eghbal 《Roads and Bridges: The Unseen Labor Behind Our Digital Infrastructure》\n开源，并非与你不相关，并非离你很遥远，开源就在你身边！\n而谈到开源软件的开发模式，不得不提及 Eric S.Raymond 在其著名的论文《大教堂与集市》中论证了开源的软件工程理论。如他所定义的 Linus 定律：众目睽睽之下，Bug 将无处藏身，模块化、去中心化、快速发布快速反馈等等是可行的，Kernel 就是成功的案例。\n随着 Linux、Apache、Perl/Python/PHP、MySQL/PostgreSQL 等开源技术的崛起，以及技术的更新迭代，开源已经不再是稀缺，而是一种过剩，架构师在最初构建业务系统的时候，面临的不是创造，而是选择。于是开源项目又有了新的优势：\n可以让业务快速的搭建原型 几乎以零成本的方式来进行 让产品迅速进入市场，获得及时反馈\n开源社区 开源的理论知识或许太过深奥、晦涩。接下来我就接地气地讨论下面几个实际问题：\n 为什么要加入开源社区？ 加入社区的门槛有哪些？ 加入社区你能做什么？ 加入社区如何正确互动提问？ 加入社区有哪些收益？  为什么要加入开源社区？ 本文开篇说到过，开源已经无处不在，不管你是从事架构、开发、运维、算法还是产品、运营，只要你从事计算机与互联网相关工作，总有“一款”开源社区适合你，你可以从该社区中获益。\n加入社区的门槛有哪些？ 最近在邀请身边的朋友加入社区时，偶尔发现有人这样回答：我现在水平还不够，等以后知识水平提升了再加入吧。如果这位是在诚实地回答，我想告诉你的是，加入开源社区原则上并没有门槛。不限于其经验水平、性别、性别认同和表达、性取向、残疾、个人外貌、体型、人种、种族、年龄、宗教或国籍等。如果一定要在加上一个门槛的话，我希望你能有参与社区建设的热情、你懂得社交的基本礼仪、你有一定责任心与荣辱感，你能遵守社区的行为准则与国家地区的法律法规！\n加入社区你能做什么？ 很重要的一点，加入社区的个体可以做什么，可以在其中扮演怎样的角色！这个可能需要看社区本身的性质。如果是开源项目官方社区，加入社区后，你可以参与讨论如何贡献代码，参与技术方案的决策，当然也可以参与“疑难杂症”的讨论或者提问。如果社区的性质是终端用户社区，比如某个技术领域或者某个开源项目在中国的本地社区，那么加入社区你有很多事可以做，包括但不限于：\n 参与技术话题讨论与交流 参与官方文档汉化活动（翻译） 参与或协办线上线下活动 技术文章（原创/翻译）投稿 在社区内进行技术分享 参与社区组织的电子书的写作 参与社区网站的构建和维护 宣传自己热爱的开源项目 其它  正如第二点所说，加入社区本身没有门槛，但是加入社区后具体能做些什么取决于个体本身的水平和能力。社区是由个体组成，社区伴随个体共同成长。\n值得一提的是，很多人加入社区长期处于潜水状态，我这里强烈建议这部分群体浮出水面。被动接受地知识不易于真正吸纳，参与讨论，最终将知识产出反馈给社区，这样才能形成良性循环。另外有一部分人加入社区后，只有工作中遇到问题时才活跃起来，在社区中提问，其它社区活动也不参与，也没有任何反馈，这样单方面索取的行为不利于社区的发展，久而久之，社区就不再有知识产出了，自己也很难从社区中获得提升。\n加入社区如何正确互动提问？ 紧接上面的话题，大部分参与开源社区主要的活动就是参与互动或者提问。\n参与社区互动其实也是一个社交活动，需要个人把握社交分寸，遵守基本的社交礼仪。不可接受的参与者行为包括但不限于：讨论问题上升到人身攻击，挑衅、侮辱或贬低性评论、公开或私下骚扰、未经允许发布他人私人信息、未经允许发布广告或者其它不良信息、无故刷屏刷帖从而占用公共资源等。\n另外，在社区里提问或者发起相关技术话题讨论是被鼓励的，但是提问也是一门艺术，需要提问着好好把握。有一个知名 Github 项目 How-To-Ask-Questions-The-Smart-Way对提问的智慧进行完整的整理，我这里简单整理几点如下：\n 提问之前先尝试自己通过各种手段搜索答案，包括但不限于百度、谷歌、相关技术论坛、技术手册等。当你提出问题的时候，请先表明你已经做了上述的努力；这将有助于树立你并不是一个不劳而获且浪费别人的时间的提问者。 提问时，使用清晰、正确、精准的语句描述问题，话不在多而在精。无效的问题，往往浪费大家的时间去阅读和理解，并且可能没有人去给你解答，因此清楚明确地表达你的问题以及需求至关重要。 提问时要有一定的礼貌，尤其通过社区向个人提问时至关重要。虽然同为社区成员，但往往素不相识，别人没有义务一定要给你解决问题，尤其当该问题需要花费不少时间去梳理和解答。向个人提问时，一般需要首先做个自我介绍，然后礼貌地请教问题，不管问题最终是否得到解答，都能够表示感谢。尤其当你有一串的问题待解决，客气一点肯定会增加你得到有用回应的机会。  加入社区有哪些收益？ 简单来说，加入社区，肯定是有利可图的，你能够收获知识与成长、收获人脉、以及其它长期收益。\n 收获知识与成长。长期参与社区技术话题讨论，阅读社区提供的学习资源，参与社区活动，甚至直接给开源项目提交 PR，久而久之，在该领域的知识水平与解决问题的能力就会得到提升。以社区里面的技术达人为目标或者榜样，往往能督促个人朝着正确的方向快速前进。 收获人脉。有一句俗话，参与开源社区就是混技术圈子的。在这个圈子里，你能找到志同道合的人，结交更多的朋友。三人行，必有我师焉。圈子里面技术大牛如云，结交和认识社区里面的技术达人，除了向强者学习之外，还有利于扩展自己的人脉资源，人脉多了，路就越走越宽了。 收获影响力与认同感。一旦积极参与了社区活动，包括技术博客投稿，参与社区技术文档撰写，个人的技术影响力也会逐步提升，同时也会有更多人对你表示赞同与尊敬。替人解疑答惑，不仅自己的知识得到巩固和传播，也能收获别人的感激之情。 其它长期收益。加入社区的收益往往很难在短期之内显现，而且即使你投入很多，也很难获得物质上的回报。如果你把目光放长远，你会发现，加入社区的长期收益有很多，包括个人技术影响力的提升、自身技术视野的提升、社交水平的提升，对于一些公司和部门来说，长期活跃在开源社区也能有助于职业的晋升。 更多的收益取决于你愿意贡献多少精力在开源上。  写在最后 对于广大中国开发者而言，终端用户开源社区是最容易接触的，也是最容易从中受益的。终端用户，这里指开源项目的最终收益者/使用者。而终端用户社区即由一群终端用户成立的社区。对于这样的社区，一般的宗旨为：拥抱开源、反馈开源。终端用户开源社区不仅仅是对开源项目与技术的传播、布道、交流，也会引导社区成员在力所能及的前提之下对开源项目进行反馈，包括提 bug，提交 PR，参与项目重要决策或设计等等。\n在开发者真正拥抱开源的同时，一个开放、多样且极具成长空间的开源社区不该被错过，它将为开发者回馈更大的价值。无论是社区本身，还是参与其中的众多开发者，相信都能在良性的互动中，相互促进，获得快速且长足的发展。\n","permalink":"https://cloudnative.to/blog/opensource-and-community/","tags":["开源","社区"],"title":"解秘开源与社区"},{"categories":["Cloud Native"],"contents":"今天我们不讲行业和商业，讲讲2019年最热的概念——云原生（Cloud Native）。\n我认为云原生是未来10年IT发展最重要的趋势，但是它涵盖的概念非常多，需要花很多时间研究，同时浩如烟海的资料分散在网络上各个地方，缺乏系统性的梳理。今年2月我在基金内部做过一个分享，今日成文，希望让更多的人有所了解。\n本文试图解答：\n 为什么云原生概念具有革命性？ 什么是微服务？ 微服务和中台的关系 容器和微服务为什么是最佳搭档？ 容器化与虚拟化的区别 API管理与API集成的区别 Kubernetes是做什么用的？ 开源软件商业化遇到的典型问题是什么？  涉及到的概念包括云原生、DevOps、持续集成、持续交付、持续部署、微服务、API管理、iPaaS、Service Mesh、Serverless、容器、Docker、Kubernetes等等，我争取用比较形象和通俗的方式把这些技术概念讲清楚。\n本文内容较多，共分为六个章节。\n 第一部分：云原生及CNCF基金会 第二部分：DevOps与CI/CD 第三部分：微服务、API管理与集成 第四部分：容器与Docker 第五部分：Kubernetes与容器编排之战 第六部分：思考与机会  第一部分：云原生及CNCF基金会 从集装箱革命说起\n有一本非常有名的书，叫《集装箱改变世界》，说的是看起来平淡无奇的铁箱子，如何从二十世纪起永久性的改变了这个世界，并促进了全球化和全球分工。集装箱的出现和发展是实体货物包装、运输、交付方式的一次革命。\n《经济学家》杂志曾经评价说“没有集装箱，不可能有全球化”。集装箱为什么具有革命性？\n经济全球化的基础就是现代运输体系,而一个高度自动化、低成本和低复杂性的货物运输系统的核心就是集装箱。集装箱最大的成功在于其产品的标准化及由此建立的一整套运输体系。能够让一个载重几十吨的庞然大物实现标准化，并且以此为基础逐步实现全球范围内的船舶、港口、航线、公路、中转站、桥梁、隧道、多试联运相配套的物流系统，这的确堪称人类有史以来创造的伟大奇迹之一，而撬动这个系统的理念就是标准化和系统化。\n改变世界的不仅仅是集装箱本身，还有一整套货物处理的新方法，包括港口、货船、起重机、卡车，还有发货人的自身操作方式等。\n云原生在IT领域的意义非常类似于集装箱，只是里面装载的不再是实体货物，而是虚拟世界的二进制代码和软件。我们将在介绍完众多概念之后再来对应解释。\n云原生的诞生\n随着虚拟化技术的成熟和分布式框架的普及，在容器技术、可持续交付、编排系统等开源社区的推动下，以及微服务等开发理念的带动下，应用上云已经是不可逆转的趋势。\n云原生的发展史，来自CNCF基金会执行董事Dan Kohn\n云计算的3层划分，即基础设施即服务(IaaS)、平台即服务(PaaS)、软件即服务(SaaS)为云原生提供了技术基础和方向指引，真正的云化不仅仅是基础设施和平台的变化，应用也需要做出改变，摈弃传统的土方法，在架构设计、开发方式、部署维护等各个阶段和方面都基于云的特点，重新设计，从而建设全新的云化的应用，即云原生应用。\n云原生（Cloud Native）这个概念，是由Pivotal的Matt Stine于2013年首次提出，他还在2015年出版了《Migrating to Cloud-Native Application Architectures（迁移到云原生应用架构）》一书。\nGartner提到云原生的定义尚不明确，但含义丰富。云原生对于不同的人和组织来讲，有着不同的理解。众多顶级技术的铸造者、Matt Stine的东家Pivotal如此定义云原生。\n“Cloud native is an approach to building and running applications that fully exploit the advantages of the cloud computing model.”——云原生是一种构建和运行充分利用云计算模型优势的应用程序的方法。\nCNCF云原生计算基金会如此定义云原生：\n“云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格（Service Mesh）、微服务、不可变基础设施和声明式API。这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。”\n其中服务网格和声明式API是新加入的内容，而不可变基础设施指的是应用的基础设施应是不可变的，是一个自包含、自描述可以完全在不同环境中迁移的东西，容器技术正是这一理念实现的基石。\n而CNCF同时把云原生计算定义为：\n“Cloud native computing uses an open source software stack to be:\nContainerized. Each part (applications, processes, etc) is packaged in its own container. This facilitates reproducibility, transparency, and resource isolation.\nDynamically orchestrated. Containers are actively scheduled and managed to optimize resource utilization.\nMicroservices-oriented. Applications are segmented into microservices. This significantly increases the overall agility and maintainability of applications.”\n——云原生计算使用的开源技术栈包括：\n 容器化。每个部分（应用、流程等等）都打包在自己的容器中，这有助于提升复用性、透明度以及改善资源隔离。 动态编排。容器受到有效的调度和管理，以便优化资源利用。 以微服务为导向。应用被分割到不同的微服务中，这种分割可以显著的提高应用的整体敏捷性和可维护性。  我个人理解，云原生是指从云的原生应用角度出发，一整套设计、开发、部署、运行、维护的流程、技术栈以及背后文化理念的统称。\n下表列举了云原生应用和传统应用的有哪些主要区别。\n要转向云原生应用需要以新的云原生方法开展工作，云原生有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。\n云原生的发展脉络\n云原生背后的价值主张有哪些？\n 隔离性：把应用程序打包在容器中加快了代码和组件的重用，并且简化了操作； 无锁定：开源软件栈支持在任何公共或私有云上或以组合方式进行部署； 无限扩展：为能够扩展到数万个自修复多租户节点的现代分布式系统环境而优化； 灵活性和可维护性：将应用程序拆分为具有明确描述的依赖关系的微服务； 提高效率和资源利用率：动态管理和调度微服务的中央编排流程降低了与维护和操作相关的成本； 应用的弹性：以应对单个容器甚至数据中心的故障，以及不同级别的需求  2019年，Gartner曾经发布报告表示云原生时代已经到来，在未来三年中将有75%的全球化企业将在生产中使用容器化的应用。\n请注意，云原生相关技术不仅仅能用于云计算，即便是和云计算即对立又协同的边缘计算，微服务、容器、Kubernetes依然是事实上的杀手应用和标准。如由著名的Kubernetes管理平台创业公司Rancher所贡献的K3s项目，就是Kubernetes（K8s）的最轻量级版本，以满足边缘计算和IOT环境中，在x86、ARM64和ARMv7处理器上运行小型、易于管理的Kubernetes集群日益增长的需求。\n云原生计算基金会CNCF\n提到云原生，就不能不介绍云原生计算基金会CNCF（Cloud Native Computing Foundation）（https://www.cncf.io）。CNCF于2015 年7月由Google 牵头成立，隶属于 Linux 基金会，初衷是围绕云原生服务云计算，致力于培育和维护一个厂商中立的开源生态系统，维护和集成开源技术，支持编排容器化微服务架构应用，通过将最前沿的模式民主化，让这些创新为大众所用。\nCNCF的使命包括以下三点：\n 容器化包装 通过中心编排系统的动态资源管理 面向微服务  全球主流的科技企业和云计算厂商绝大部分都是CNCF会员，其中不乏多家来自中国的科技巨头。\nCNCF黄金、白金会员\n截止2020年4月，CNCF 基金会共托管49个云原生项目，每个CNCF项目都对应一个成熟度等级，申请成为CNCF项目的时候需要确定项目的成熟度级别，Kubernetes和 Envoy等项目基于生产可用和高稳定性首先成为毕业项目（9个），其他项目则根据其成熟度分别位于孵化（17个）和沙箱（23个）阶段。CNCF目前托管的项目共同构成了云原生生态的基石。\n值得注意的是其中有三个来自中国的项目：VMware中国团队为企业用户设计的 Registry Server开源项目Harbor，PingCap贡献的分布式事务键值数据库TiKV以及阿里自研的P2P文件分发系统Dragonfly。\nCNCF项目成熟度等级划分\n对于企业在复杂的基础架构之上如何推动云原生应用的更好落地，从而更好地适应环境与业务的发展，CNCF给出了路线图（Trail Map）用于对用户在整体上给出指导建议，共分成十个步骤（容器化；CI/CD；应用定义及编排；监控及分析；服务代理、发现和网格；网络、策略及安全；分布式数据库及存储；流与消息；镜像库与运行时；软件分发）进行实施，而在不同的步骤都可以结合CNCF全景图（Landscape）中列出的产品或服务进行选择。\nCNCF全景图则列举了和云原生相关的产品及服务的完整名单，这1381个项目共同构成了恢弘庞大的云原生世界。整个全景图按照功能分为29个模块，分别归属于9种大的类别（应用定义与开发、编排与管理、运行时、配置、平台、可观察性与分析、Serverless、会员和其它）。值得注意的是其中专门有一种分类是Cards from China，列举了来自中国的145个项目，其中不乏许多大家耳熟能详的知名项目，可惜的是数据并不完整。感兴趣的朋友可以自行研究。\n从CNCF的理念及野心来看，基于云原生的基础设施正在壮大和蚕食非云的市场，未来极有可能成为整个IT生态事实上的意见领袖和领导者。\n云原生涵盖的主要概念\n上面提到云原生的代表技术包括容器、服务网格（Service Mesh）、微服务、不可变基础设施和声明式API。另外一种比较主流的说法是云原生=微服务+DevOps+持续交付+容器化，广泛的见诸于各种文章和资料。\n在接下来的《云原生时代》系列报告中，我们将依照这些概念，分成DevOps与CI/CD；微服务、API管理与集成；容器与Docker；Kubernetes与容器编排之战四个部分全面介绍云原生各个组成部分。\n第二部分：DevOps与CI/CD DevOps\nDevOps（Development \u0026amp; Operations，开发和运维）是09年提出来的概念，但一直没有太火。直到14年，容器与微服务架构的提出，DevOps才得到了快速的发展。DevOps不单是一个实现自动化的工具链，而是组织、流程与技术的结合。组织上强调全栈团队、团队特性专一、团队自治；技术上打通开发与运维；流程上强调端到端、可视化、灰度升级、A/B测试等。\n对于DevOps，微服务不是必须的，但微服务为DevOps提供了最好的架构支撑，对于组织和流程的要求也是一致的。所以，也有人称微服务是DevOps架构。\nDevOps流程示意图\nDevOps与下面提到的CI、CD不同，DevOps更偏向于一种对于文化氛围的构建。DevOps也即是促使开发人员与运维人员之间相互协作的文化。DevOps的概念似乎与持续交付的概念有些类似，两者均旨在促进开发与运维之间的协作，但是实际上两者差别很大：DevOps 更偏向于一种文化的构建，在DevOps文化指导下，团队中将包含了具有不同技能的人员（开发、测试等），并通过自动化测试与发布的手段，更快、更高质量的生产软件。\n持续集成\n持续集成（CONTINUOUS INTEGRATION，CI）指的是开发人员频繁的（一天多次的）将所有开发者的工作合并到主干上。这些新提交在最终合并到主线之前，都需要通过编译和自动化测试流进行验证，以保障所有的提交在合并主干之后的质量问题，对可能出现的一些问题进行预警。持续集成的核心在于确保新增的代码能够与原先代码正确的集成。\n持续集成流程示意图\n持续集成带来的好处是：\n 易于定位错误 易于控制开发流程 易于Code Review 易于减少不必要的工作  持续交付\n与持续集成相比，持续交付（CONTINUOUS DELIVERY，CD）的侧重点在于交付，其核心对象不在于代码，而在于可交付的产物。由于持续集成仅仅针对于新旧代码的集成过程执行了一定的测试，其变动到持续交付后还需要一些额外的流程。与持续集成相比较，持续交付添加了测试Test-\u0026gt;模拟Staging-\u0026gt;生产Production的流程，也就是为新增的代码添加了一个保证：确保新增的代码在生产环境中是可用的。\n持续交付流程示意图\n持续交付带来的好处是：\n 繁琐的部署工作没有了。团队不再需要花费几天的时间去准备一个发布 可以更快的进行交付，这样就加快了与客户之间的反馈环 轻松应对小变更，加速迭代  持续部署\n持续部署（CONTINUOUS DEPLOYMENT）指的是通过自动化部署的手段将软件功能频繁的进行交付。与持续交付以及持续集成相比，持续部署强调了通过自动部署的手段，对新的软件功能进行集成。同持续交付相比持续集成的区别体现在对生产的自动化。从开发人员提交代码到编译、测试、部署的全流程不需要人工的干预，完全通过自动化的方式执行。这一策略加快了代码提交到功能上线的速度，保证新的功能能够第一时间部署到生产环境并被使用。\n持续部署流程示意图\n持续部署带来的好处是：\n 发布频率更快，因为不需要停下来等待发布。每一处提交都会自动触发发布流 在小批量发布的时候，风险降低了，发现问题可以很轻松的修复 客户每天都可以看到持续改进和提升，而不是每个月或者每季度，或者每年  自动实时的部署上线，是最优的解决办法，但持续部署的要求是团队非常成熟，并且上线前是需要经过QA测试的，所以实际情况下很难实现，一般的团队也很难接受，挑战和风险都很大。\n我们总结下，DevOps、持续集成、持续交付、持续部署并不是某种技术栈或者框架，而是开发文化、流程、理念和操作方式。下一部分，我们将介绍云原生最重要的概念之一：微服务。\n第三部分：微服务、API管理与集成 什么是微服务\n微服务（Microservice）概念最早出现于2012年，2015年以后受到越来越多的关注，并且逐渐开始流行开来。其中著名技术大神Martin Fowler功不可没，他于2014年发表的一篇博客《Microservices: a definition of this new architectural term》（微服务：新技术架构的定义）清晰的定义和阐述了微服务概念。\n“要开始解释什么是微服务之前，先了解单体（Monolithic）应用是很有用的：作为一整个单元构建的应用程序。企业应用由三个重要部分组成：客户端界面（由HTML、Javascript组成，使用浏览器访问）、数据库、服务端程序。服务端程序处理HTTP请求、执行业务逻辑、检索并更新数据库中的数据、选择和填充HTML视图发送给客户端。这个服务端程序是一个单一结构也即一个整体，系统中的任何修改都将导致服务端重新编译和布署一个新版本。\n这样一个单体应用很自然的被构建成为一个系统，虽然可以使用开发语言的基本特性把应用封装成类、函数、命名空间，但是业务中所有请求都要在单一的进程中处理完成，在某些场景中，你可以在开发人员的笔记本电脑中运行和测试，并且通过布署通道将测试通过的程序布署到生产环境中，你还可以水平扩展，利用负载均衡将实例布署到多台服务器中。\n的确，单体应用也非常成功，但是越来越多的人感觉到了不妥，特别是应用程序被发布到云的时候，变更周期被捆绑在一起-对应用程序一小部分所做的变更，都需要重新编译和部署整个应用。随着时间的推移，软件开发者很难保持一个好的模块架构，使得单个模块的变更不会影响到其它模块，而且扩展时也只能进行整体扩展，而不能根据需求进行部分扩展。”\u0026ndash; Martin Fowler\n下图是传统单体应用的技术及对应的组织架构，Martin Fowler称之为大家已熟知的Siloed Architectures-烟囱式（也称为谷仓）架构。\n传统单体应用的架构及对应的职能型组织架构\n综上，传统的单体应用有很大的局限性，应用程序随着业务需求的迭代、功能的追加扩展，最终成为一个庞然大物。单体应用的局限性大体包括以下几方面：\n 复杂性高：业务规模和团队规模发展的一定阶段，模块耦合严重，代码难以理解，质量变差 交付效率低：构建和部署耗时长，难以定位问题，开发效率低，全量部署耗时长、影响范围广、风险大，发布频次低 伸缩性差：单体只能按整体横向扩展，无法分模块垂直扩展 可靠性差：一个bug有可能引起整个应用的崩溃 阻碍技术创新：受技术栈限制，团队成员使用同一框架和语言  解决这一问题的银弹就是微服务。\n“微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间相互协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务和服务之间采用轻量级的通信机制相互沟通（通常是基于HTTP的Restful API)。这些服务要基于业务场景，并使用自动化布署工具进行独立的发布。可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。”\u0026ndash; Martin Fowler\n微服务架构将单体应用，按照业务领域拆分为多个高内聚低耦合的小型服务，每个服务运行在独立进程，由不同的团队开发和维护，服务间采用轻量级通信机制，如HTTP RESTful API，独立自动部署，可以采用不同的语言及存储方式。微服务体现去中心化、天然分布式，是中台战略落地到IT系统的具体实现方式的技术架构，用来解决企业业务快速发展与创新时面临的系统弹性可扩展、敏捷迭代、技术驱动业务创新等难题。\n下图左边是传统的单体应用，右边是微服务模式，图中每种颜色代表一种可拆分的微服务应用。\n单体应用和微服务\n一个比较形象的例子是装配式建筑。传统建筑（单体应用）的施工周期（开发时间）很长，往往依赖于建筑公司（开发团队）的能力和水平，修建完成后难以搬迁和复用，而装配式建筑（微服务）的梁、板、柱、墙等构件（单个服务）可以事先批量化的在工厂（容器）生产，而在建造过程中，我们可以把构件想象成一块块乐高积木，在施工现场只需把它们拼合在一起，大大提升了施工进度和建筑质量。\n装配式建筑：乐高积木\n微服务的特征包括：\n 小：粒度小，专注于一件事 独：单独的进程。微服务不等于组件，服务是可以直接使用的商品，组件是待加工的原材料 轻：轻量级通信机制，通常是HTTP Restful的接口。此处区别于传统的SOA（面向服务的架构） 松：松耦合，可以独立部署。每个微服务可以独立编译、独立部署、独立运行  微服务采用独立的数据库服务，数据去中心化\n微服务运行在独立的进程中，部署去中心化\n微服务架构的好处是：\n 易于开发与维护：微服务相对小，易于理解 独立部署：一个微服务的修改不需要协调其它服务 伸缩性强：每个服务都可按硬件资源的需求进行独立扩容 与组织结构相匹配：微服务架构可以更好将架构和组织相匹配，每个团队独立负责某些服务，获得更高的生产力 技术异构性：使用最适合该服务的技术，降低尝试新技术的成本 企业环境下的特殊要求：去中心化和集中管控/治理的平衡，分布式数据库和企业闭环数据模型的平衡  微服务的实践有两个重要问题：什么时候选择微服务架构，以及颗粒度如何拆分，与经验和实际情况息息相关。\n上图来自Martin Fowler另一篇叫《微服务进阶》的文章，揭示了生产率和复杂度的一个关系。在复杂度较小时采用单体应用的生产率更高，复杂度到了一定规模时，单体应用的生产率开始急剧下降，这时对其进行微服务化的拆分才是合算的。\n我个人建议是除非在可见的将来，复杂度都不会显著提高的情况下，才选择单体应用，否则其它时候都应提前为微服务架构做好设计和准备。\n微服务基础设施及案例\n下图是一个典型的微服务技术架构图。\n微服务架构最常见、最广泛使用的框架是基于Java的Spring Cloud（集成了上图里的Netflix OSS技术栈），提供了服务发现、负载均衡、故障转移、动态扩展和数据分区等功能，已经成为微服务的最佳实践。\n但是Spring Cloud构建在Java虚拟机之上，不能满足高并发下的性能要求，所以许多开源产品层出不穷，其中也包括中国互联网企业所贡献的微服务框架，例如华为的ServiceComb、阿里的Dubbo等等。\n下面我们举一个例子。传统的电商的技术架构如下图所示，这是一个单体应用。\n所带来的常见问题包括：\n 不同客户端产品之间，例如小程序、App、网站端有许多相同业务逻辑的重复代码，每个产品都要各自维护一份代码，修改的时候所有地方要一起修改。 单个应用经常需要给其他应用提供接口，渐渐地越来越复杂，包含了很多本来不属于它的逻辑，代码变得臃肿，功能边界模糊。 系统代码耦合性高，相互之间逻辑复杂，一旦出现开发离职的情况，继任者需要花很长时间review代码，才有可能搞清楚整体架构和逻辑关系。 多个应用使用一个数据库，依赖性严重，很难重构和优化。所有应用都在一个数据库上操作，数据库很容易出现性能瓶颈。同时数据库成为单点，出现意外整个系统都会受到影响。 即使只改动一个小功能，也需要整个应用一起发布，发布流程繁琐、上线时间长。并且很容易出现一个小bug影响整个系统，每次发布都是胆战心惊，很容易出现开发、运维和测试之间的矛盾。  下面我们用微服务重构整个系统：\n改造之后，去除了大量冗余代码，系统复用性得到提升；不同的团队专注于不同的微服务，代码和工程质量得到保证；数据库不再存在单点问题，系统健壮性得以提升；前后端分离，业务逻辑更加清晰；降低了系统耦合性，不同的微服务可以分开部署上线，相互之间并不影响。\n组织挑战、康威定律与蜂群理论\n请注意，微服务理念不仅反映了技术架构的变化，也反映了组织内部沟通结构为了应对更加灵活、快速、碎片化的需求和环境而变化的结果。例如液态组织就是组织形态应对当前市场环境快速变化的一种输出形式，但实际应该如何构建？\n曾经有一张非常有名的组织架构图，如下图所示。\n对一家企业来说，能一步步不断发展壮大，进入一个领域就能迅速突破，这其中的根本核心必然是组织模式。在粗放发展的年代，很少有企业强调内部效率，组织模式绝大部分都类似单体应用，按照职能划分的方式进行管理，从而创造了无数的烟囱/谷仓。\n单体架构和职能型组织模式相似\n一张著名的图：技术组织造就了难以逾越的谷仓\n我在我的知识星球里提出过企业级产品设计所面临的重要挑战，其中一个问题是：\n 版本。企业级产品现在经常涉及多个平台和不同的版本，例如Web、PC、App、钉钉、企业微信、微信小程序、飞书的版本等等，第一会面临重复开发的问题，第二业务逻辑非常复杂，很容易造成产品逻辑和体验的不统一，以及不同版本产品之间逻辑的缺失。例如登录和注册微信小程序可能用的是手机号，而通过邮件注册需要使用的却是邮箱。如何设计一套比较好的产品流程和组织架构，来保证统一完善的产品逻辑及用户体验？  是的，这不仅仅是产品和技术问题，还是组织问题。现在越来越多的企业意识到了最大的挑战在于组织内部，无论是增长黑客还是MVP的理念都需要快速灵活的机制来配合。为什么有的组织效率高、能力强，能及时响应客户的需求和环境变化？\n新的组织设计理念认为传统的烟囱形式会成为创建有效增长和盈利途径的障碍，需要解构组织孤岛，采用跨职能组织的形式以支持增长。企业组织设计是非常专业的领域，有许多文章讨论，例如《战胜组织孤岛的战略之路》，本文不延伸讨论。\n职能组织与跨职能组织\n我们可以看到单体应用和职能组织，微服务与跨职能组织，在形式上是高度相似的，这引申出微服务背后的理论基础。\n“当希望把一个大型应用拆分成多个部分时，管理层通常将重点放在技术层面。而如果组织架构还按UI团队、服务端逻辑团队和数据库团队的标准设立，甚至一个非常简单的变更都将导致跨团队间的项目协作，从而耗费时间和预算审批。一个高效的团队会针对这种情况进行优化，关注它们所涉及的应用逻辑，并从中做出更好的选择。换句话说，逻辑无处不在。这是康威定律的一个实例。”\u0026ndash; Martin Fowler\n 设计系统的架构受制于产生这些设计的组织的沟通结构（Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations）\u0026ndash; Melvyn Conway, 1967\n 康威定律可谓软件架构设计中的第一定律，本质是对商业世界的规律总结，但是因为投稿到编程相关的杂志，后经过《人月神话》这本软件界圣经的引用，并命名为康威定律（Conway\u0026rsquo;s law），因此得以推广。\n只通过简单的描述可能无法理解康威定律的精髓所在，原文中康威定律可总结为四项：\n 第一定律 组织沟通方式会通过系统设计表达出来（Communication dictates design） 第二定律 时间再多一件事情也不可能做的完美，但总有时间做完一件事情（There is never enough time to do something right, but there is always enough time to do it over） 第三定律 线型系统和线型组织架构间有潜在的异质同态特性（There is a homomorphism from the linear graph of a system to the linear graph of its design organization） 第四定律 大的系统组织总是比小系统更倾向于分解（The structures of large systems tend to disintegrate during development, qualitatively more so than with small systems）  例如微服务的团队间应该是inter-operate，not integrate（互操作、不集成）。inter-operate是定义好系统的边界和接口，在一个团队内全栈，让团队自治，原因就是因为如果团队按照这样的方式组建，将沟通的成本维持在系统内部，每个子系统就会更加内聚，彼此的依赖耦合变弱，跨系统的沟通成本也就能减低。\n康威定律可以上升到哲学的高度进行讨论，但是过于复杂。简言之，微服务架构与组织模式互相决定和影响，协同才能发挥出最大价值。\n跨职能组织-微服务架构/团队边界强化服务边界\n凯文·凯利在《失控》中提出了著名的“蜂群理论”，利用蜂巢思维比喻人类的协作带来的群体智慧：依靠成千上万个发条一起驱动一个并行的系统，进行生产，进行自维持。蜂巢思维就是“群体思维”（Collective consciousness）。作为“超级有机体”的蜂群，被称为“分布式系统”，是以生物逻辑建立起来的群集模型。由此形成的蜂巢思维这四个理念至关重要：\n 去中心化。几乎所有的团队都直接接触用户与市场，因此所有的团队都将围绕市场格局而变，充分重视第一线的敏感度与直觉，从而做到真正的应时而动； 分布式。与垂直型集团组织不同，这个形态打破单一的行业垂直细分格局。在这种多维度矩阵式结构中，拥有更加专注的功能型团队，可建立起一个紧密围绕具体客户与市场的服务体系； 强化合作。从控制权、所有权的角度来说，这些组织单元是分离的，因而要建立起一种横向合作的文化，打破物理团队，提倡交流、合作，整体核心竞争力的提升； 适应变化。市场在不断变化，但因所有的团队都直接接触用户与市场，因此无论个人还是团队，都将不断的学习和进化。  微服务理念对应的组织模式包括蜂巢型组织，它具有突出的稳定性和抗弯曲能力，特点是：\n 跨组织：它不一定是一个独立的法人实体，而是为了特定目标或项目形成的联盟 相对统一：蜂巢组织不是一成不变的，当市场需求或组织目标发生变化时立即变化 分享性：它改变了传统的等级分明的金字塔结构，允许信息横向传递与交流，使信息利用更为充分及时  在这样一个以蜂巢为理念搭建的企业圈层里面，各个独立团队能够得到更好的协助与支撑，不断扩大视野，提高眼界，掌握话语权，团队成员也会更有归属感。这样的团队乃至蜂巢本身，也一定会更有活力和变革力，更加能适应市场的变化。蜂巢型组织有四个突出特点，所谓活系统的特质也正是由此而来：没有强制性的中心控制；次级单位具有自治的特质；次级单位之间彼此高度连接；点对点间的影响通过网络形成了非线性因果关系。\n微服务：筑巢\n蜂巢型组织的典型案例之一是华为。除了组织架构去中心化的管理模式之外，华为的著名的轮值CEO制度正是由此而来，华为有三位轮值CEO，每六个月轮换一次，这体现了依靠集体民主决策而非一人独裁的理念。\n再例如国美蜂巢式组织变革的实践是将由四个大区管辖54个分公司，调整为七个大区直接管辖200家分公司的结构，即将原来二级市场里的146家分公司独立出来，直接划归大区管辖，而原来四个大区变成七个大区。实践证明，组织扁平化是国美提升供应链效率，提升消费者消费体验的重要战略。\n国外著名的代表案例是微服务先驱Netflix。Netflix是一家技术强大的互联网公司，但是它却没有CTO职位，产品团队和技术团队(包括UI前端工程团队、Discovery搜索工程团队和Platform平台团队等)全部汇报首席产品CPO，产品驱动是该公司的核心文化要素之一，Netflix称其为BusDevOps组织架构。\nNetflix：BusDevOps组织\n在整个系列第二部分中，我们介绍了DevOps，现在我们可以理解，DevOps是配合微服务的理念组织构建团队协作的方式，各团队可以独立开发，测试、发布和迭代各自的微服务，互不干扰，沟通协调成本小。全部业务、研发和运维围绕产品开展工作，统一目标，大家都是产品驱动，分别服务于内外不同客户，避免技术驱动 vs 业务驱动的陷阱。\n传统水平组织 vs DevOps驱动的垂直组织\n在某些文章中，认为微服务的切割应该按照组织架构来划分，我反而觉得应该按微服务的分割方式来划分组织架构，因为归根结底，组织架构应该为业务服务，而不是业务为组织服务，组织需要贯彻执行微服务的理念，就必须由微服务驱动组织业务的不断迭代演进。\n微服务与中台\n可能有人会问，中台的目标不也是为了解决企业内部业务系统烟囱林立，数据孤岛严重，各自为战，缺乏复用性，所以要充分提取业务共性，从而及时应对需求变化，听起来和微服务的目标和理念非常相似，那它们之间有什么异同呢？\n阿里巴巴中台战略架构图\n来自阿里官方的定义，“企业中台就是，将企业的核心能力随着业务不断发展以数字化形式沉淀到平台，形成以服务为中心，由业务中台和数据中台构建起数据闭环运转的运营体系，供企业更高效的进行业务探索和创新，实现以数字化资产的形态构建企业核心差异化竞争力。”\n中台架构，简单地说，就是企业级能力的复用，一种方法论，企业治理思想。\n微服务，是可独立开发、维护、部署的小型业务单元，是一种技术架构方式。\n所以中台并不是微服务，中台是一种企业治理思想和方法论，偏向于宏观，微服务是技术架构方式，偏向于微观。而中台化的落地，离不开使用微服务架构。\n中台强调核心基础能力的建设，基础能力以原子服务的形式来建设，并通过将原子服务产品化，支撑业务端各种场景的快速迭代和创新；原子服务和微服务所倡导的服务自闭环思想不谋而合，使得微服务成为实现原子服务的合适架构。\n支撑业务场景的应用也是通过服务来实现，其生命周期随业务变化需要非常灵活的调整，这也和微服务强调的快速迭代高度一致，所以业务应用服务也适合通过微服务来实现。\nAPI管理与API集成\n下面我们讲讲微服务相关的两个具体领域，API管理与API集成。\n1、全生命周期API管理\n上文提到微服务各个服务对外都是以Restful API形式提供服务。再加上企业越来越多地使用云服务，各种云服务也提供了众多API。\n这就导致企业拥有的API越来越多，那就当然需要有一个系统把这些API统一管理起来。同时，如果能够顺便把这些API的权限认证、安全审计等等机制也一并统一了，那就更好了，这样其它系统调用起来就方便多了。能管了以后，当然又会冒出来更多的想法。比如，能不能改一下原有API的格式内容？能不能把两个API合成一个API？能不能让一个API直接调用另一个API？能不能把这些API的调用自动化串起来？\n简单来说，API管理就是解决以上这些问题的。我们来看看Gartner全生命周期API管理领域魔力象限，许多巨头都在里面。值得注意的是，Google之所以排名第一，是因为它在2016年用6.5亿美元收购了刚上市一年左右的Apigee。\n2019年全生命周期API管理魔力象限\n2、API网关：微服务基础设施\n全生命周期API管理里一个细分的领域是API网关（API Gateway），它是微服务1.0时代最重要的基础设施。\nAPI网关顾名思义，是出现在系统边界上的一个面向API的、串行集中式的强管控服务，这里的边界是企业IT系统的边界，主要起到隔离外部访问与内部系统的作用，并处理常见的南北向流量。在微服务概念的流行之前，API网关的实体就已经诞生了，例如银行、证券等领域常见的前置机系统，它也是解决访问认证、报文转换、访问统计等问题的。\nAPI网关的流行，源于近几年来，移动应用与企业间互联需求的兴起。移动应用、企业互联，使得后台服务支持的对象，从以前单一的Web应用，扩展到多种使用场景，且每种使用场景对后台服务的要求都不尽相同。这不仅增加了后台服务的响应量，还增加了后台服务的复杂性。随着微服务架构概念的提出，API网关成为了微服务架构的标配组件。\nAPI网关作为企业能力开放的一个门户，除了具备基本的请求转发、协议转换、路由等功能，以及高性能和高稳定性外，还需具备良好的扩展性，已便于网关能力的不断增强。在网关实施过程中，要规划好网关层与服务层的交互方式，尽量使得网关层与服务层解耦，便于各个团队工作的独立性。另外，在API的管理上，需要提供API全生命周期的发布、配置、鉴权、流控、监控等配套的管理功能。\nAPI网关：微服务基础设施\n例如Uber，在传统的单体架构遇到越来越大挑战的时候，决定改变自己的架构，效仿亚马逊、Netflix、Twitter等其他超级增长公司，将其整体架构拆分为多个代码库，以形成一个微服务架构。其主要变化是引入了API网关，所有的司机和乘客都是通过这个网关连接的。从API网关，所有的内部点都连接在一起，如乘客管理、司机管理、行程管理等。每个单元是单独的可部署单元，执行单独的功能。例如：如果你想在账单微服务中更改任何内容，那么只需部署账单微服务，而不必部署其他服务。所有的功能都是单独扩展的，即每个特征之间的相互依赖被移除。\nUber的微服务架构\nAPI网关带来的的好处包括：\n 网关层对外部和内部进行了隔离，保障了后台服务的安全性 对外访问控制由网络层面转换成了运维层面，减少变更的流程和错误成本 减少客户端与服务的耦合，服务可以独立发展。通过网关层来做映射 通过网关层聚合，减少外部访问的频次，提升访问效率 节约后端服务开发成本，减少上线风险 为服务熔断，灰度发布，线上测试提供简单方案。 便于扩展  API网关常见的解决方案包括Spring Cloud Gateway、Zuul、Tyk以及下文要介绍的Kong。\nCNCF Landscape：API Gateway\n3、Kong：API网关独角兽\nKong是我去年起就在关注的一家公司，它的创业历程非常有意思。“Kong的创始人Augusto Marietti（简称Aghi）出生在罗马，因为意大利创业环境很弱，在2009年飞来了旧金山。Aghi刚来就参加了一个早期创业者的小聚会，聚会上参加的人不多，但现在都是如雷贯耳的名字：Uber的创始人Travis，Airbnb的CEO Brian，Dropbox的CEO Drew和Box的CEO Aaron。Aghi当时为了省钱，借住在Uber创始人Travis家，每天睡沙发。\n后来Travis搬了家，Aghi又去了当时只有十多个人的Airbnb办公室里借住，当时的Airbnb虽然Bug很多，但订单量一天天疯涨。在Travis的帮助下拿到天使投资后，Aghi做了一个把云端的组件连接起来的PaaS公司，一做就是五六年。由于时机不对，公司濒临破产，Aghi告诉团队，这么多年公司写了很多小功能，现在可以把代码开放出去，放在网上看看有没有人用，给社区做点贡献。没想到这看似濒死的挣扎，却给公司带来了巨大的转机。\n后来，公司关于API管理的代码模块，在GitHub上被疯狂下载，Kong也接到客户要求，希望购买相应的付费企业版。Kong敏锐地发现了这个大机会，迅速转型成了一个开源软件公司。”如果在CSDN博客上搜索，关于Kong开源版本的教程比比皆是。这是一个成功的开源软件商业化的案例，听起来经历和Docker非常相似。\nKong开源版本Github主页\nKong成长的大背景是软件开发技术正在经历革命性变化，全球5000强公司都在转向新的分布式软件架构，因为现代应用程序需要有高度可扩展性、跨平台支持以及处理实时数据流的能力。IDC预计，到2022年90%的应用程序将采用微服务架构和第三方代码，35%的生产应用程序将诞生于云端。由于容器和敏捷方法的采用，预计2018-2023年间将诞生5亿个新应用程序。\n同时开源软件初期具有的优势也在逐渐显现。Kong本身基于开源的Openresty（Nginx+lua），但比Nginx提供了更简单的配置方式，数据采用了Apache Cassandra/PostgreSQL存储，由于底层使用Nginx，所以性能比基于Java的Spring Cloud Gateway及Zuul更为出色。Kong另外一个非常诱人的地方就是提供了大量的插件来扩展应用，通过设置不同的插件可以为服务提供各种增强的功能。Kong默认插件包括：身份认证、安全、流量控制、分析监控、转换等等。\nKong的插件功能\nKong提供开源的Kong Gateway和商业版Kong Enterprise两个产品。例如在插件功能上，商业版本提供更多的选择。\nKong的部分插件功能\nKong通过云原生、混合和本地部署无缝连接API和微服务，便于程序员开发可扩展的微服务应用，推动业务增长。凭借高性能的开源内核和AI技术以及机器学习，Kong将实现全方位的服务生命周期管理，覆盖前期到后期全过程，帮助客户搭建和管理创新产品及服务。它服务于全球5000强企业，帮助程序员更方便地开发和管理高性能、可扩展的微服务应用，推动业务增长。\n从业务和融资上来讲，2018年，Kong订单大幅增加，公司员工数翻倍，已服务超过100家企业客户，包括雅虎日本、法拉利、SoulCycle、WeWork等，开源软件下载量超过5400万次，收入为500万美元。2019年，Kong完成了Index Ventures领投，GGV纪源资本、World InnovationLab跟投，老股东Andreessen Horowitz、Charles Rivers Ventures追加的4300万美元C轮融资，至此Kong累计融资共计7100万美元。\n4、RapidAPI：全球最大API市场\n和Kong紧密相关的另外一家企业是RapidAPI，2017年，Kong的母公司Mashape将其API市场业务与RapidAPI合并，从而组成了世界上最大的API市场。\n市场研究机构Ovum Research曾经表示，API经济在迅迅猛发展，到2018年将成为产值高达2.2万亿美元的市场。合并后，RapidAPI成为了这个市场的主要提供商之一。\nRapidAPI的首席执行官吉纳在宣布合并的博文中表示，“软件相互连接起来后，其功效就要大得多。不妨想一想。你使用Facebook登录到某个游戏应用程序，就能看到玩游戏的所有朋友。当亚马逊的购买门户网站与仓库存货连接起来后，你就能实时获得发货估计日期。如果你在订购机票呢？已经在你的谷歌日历中预定了航班。”吉诺补充道，API正是让那些连接成为可能的秘诀。“它们让不同的软件得以彼此联系，共享信息，并且简化我们的生活。”\n吉纳在博文中表示这只是开了个头。API正在迅速发展，打开之前紧闭的许多大门。使用API，开发人员就有可能从任何地方来访问服务，比如IBM公司的超级计算机和谷歌的机器学习模型，这就意味着他们能够充分利用比以前处理的任何资源丰富得多的资源。\n吉纳说：“我们想要让广大开发人员更容易寻找、测试和连接API。我们的计划始终未变，那就是将世界上的所有API统统集中到一个地方。将Mashape API市场合并到RapidAPI让我们离实现这个目标比以往更近了一步。现在我们每月总共有370000名开发人员在调用3000亿次API。也就是说，每秒的API调用超过100000次。”\nRapidAPI的市场里包括各种各样类型的API，例如天气、体育、科技、通讯、图像处理等等，例如获取新闻信息、实时体育比赛比分、天气信息，甚至还包括新冠病毒API分类。\n开发商可以自由的为自己的API接口定价，下图是Twilio SMS接口的报价方案。\n2019年，RapidAPI完成了由微软领投、A16Z等跟投的2500万美元B轮融资，历史累计融资达到3750万美元。RapidAPI表示，它将利用这笔新筹集的资金扩大其API市场规模，并推动其新发布的RapidAPI for Teams产品。它是一个自助服务平台，使开发人员能够发布，管理和协调API和微服务，这些是用于构建现代应用程序的常用组件。\n5、Mulesoft：API集成/iPaaS/API管理领头羊\n1）从SOA讲起\n讲API管理之前，我们得先来说说前文提到过的SOA（Service-Oriented Architecture，面向服务的架构）。\n简单地说，一个企业建设了许多业务系统，每个系统都拥有自己的数据，那么如何将这些分散各处的数据打通，从而可以进一步加以利用呢？\n这就涉及到企业应用集成（EAI，Enterprise Application Integration）这个领域了。\n传统上，企业应用集成很多是利用ETL（Extract-Transform-Load，抽取转换加载）工具，把不同系统里的数据经过抽取、过滤、转换，最终导入到一个集中的数据仓库里，然后再做整合应用。但是这种做法也存在很多问题。\n一是只认数据，没有脑子。在数据汇集的过程中，只能针对数据格式本身进行一些处理，很难利用业务系统原有的业务逻辑。\n二是随着各个系统数据体量越来越大，把所有系统的数据都汇到一个数据仓库里就变得越来越困难。\n为了解决这样的问题，SOA应运而生，就是企业中每个系统都对外发布自己的服务，那么系统之间的集成，就可以通过调用对应系统的服务来解决了。\n但是，随着企业拥有的系统越来越多，这种系统之间相互调用服务接口的集成方式又遇到了新麻烦。\n可能每两个系统之间都需要相互调用服务，这最终就会演变成一个复杂的蜘蛛网结构，使得整个集成变得越来越脆弱，难以维护。\n为了解决这个新问题，ESB（Enterprise Service Bus，企业服务总线）的概念被提出来了，就是把每个系统的服务接口都对接到ESB上，这样在系统集成的时候，只需要跟总线打交道，而不再需要直接跟所有其它系统打交道了，从而大大简化了集成的复杂度。\n使用ESB前后\n2）Mulesoft\n2018年3月，美国SaaS巨头Salesforce花费65亿美元收购iPaaS代表企业Mulesoft，Mulesoft于2017年在纽交所上市，市值约30亿美元。Mulesoft的核心产品是企业软件集成平台Anypoint Platform（旧称Mule ESB），客户可以在Anypoint上集成所有业务系统的服务，实现本地系统与云、以及云与云服务的集成。Anypoint Platform/Mule ESB是世界上使用最广泛的开源ESB产品，已拥有超过数百万的下载量，以及来自世界各地数十万个开发人员，财富500强中35%的企业、全球10大银行中的5家均使用了该平台。\nMule ESB\n尽管只有一个产品，但从Gartner的划分标准来看，Mulesoft同时踩在了两个领域里：全生命周期API管理和企业集成平台即服务（iPaaS，Enterprise Integration Platform as a Service）。\nGartner魔力象限：全生命周期API管理\nGartner魔力象限：企业集成平台即服务\nMule ESB同时包括开源和商业版本，在各个技术论坛上遍布其技术教程。\nMule开源版讨论文章\nMulesoft的成长历程非常具有参考意义，他们瞄准了一个有7000亿美元空间的市场，目标是解决一个十分困难的IT问题-集成。在摸索过程中Mulesoft不断优化其产品形态和销售方式，例如针对大客户需要的不仅是平台提供的通用功能，还需要更复杂的综合服务。于是MuleSoft把他们的销售方式从出售可靠的集成功能，变成了向高级管理人员出售提升企业连接能力的愿景和相应的解决方案，客单价也从10-30000美元提升到了500万美元。\n3）应用场景与案例\nMule ESB的常见应用场景例如：\n 旧系统改造，开放系统的服务能力。举个例子，企业有一个电商系统，需要调用SAP ERP的订单接口来创建订单，这个时候需要将SAP的订单服务暴露成流行的Restful API，以方便电商系统调用。使用Mule ESB可以轻松实现。 系统集成。企业之间的数据交换，竟然有一半以上是文件的形态进行的，这在互联网思维普及的今天，是不容易想象的。在10年前，企业间交换数据采用文件形态的比重占60%，当时普遍认为这个比重会迅速下降，最终以接口服务形态进行交换的比重会占绝大多数。然而10年后直至今天，采用文件形态的依然占51%的比重。其实仔细想想，也不无合理。两个对等企业之间，行业上下游多个企业之间，不同系统之间的进行数据交换，采用文件的形式，可能是最简单便捷的方式。举个例子，很多系统之间数据交互可能还是用FTP目录。尤其是企业跟企业之间的数据交互，比如，A企业丢一个EDI文件到B企业的FTP目录，然后B企业会从FTP目录下载解析并放置到数据库。这个场景用Mule ESB实现也很方便。  4）Salesforce为什么收购Mulesoft\nSalesforce最初为中小企业提供SaaS的CRM，而随着大客户越来越多，定制化、个性化的需求也越来强烈，所以就需要提供PaaS平台解决个性化、定制化的问题。\n而这个定制化，最开始只是以Salesforce为核心的功能延伸及简单扩展，而随着个性化需求的不断深入，这种定制已经逐步演变为更大规模的多个骨干数据源之间的数据集成与交换，Salesforce可能只是多个数据源之一。\n所以也可以说，数据集成是PaaS平台的上层建筑，Salesforce需要帮助客户解决整合不同数据源所带来的挑战。\n收购之后，Salesforce会将MuleSoft植入进Salesforce Integration Cloud，从而帮助客户连接多个数据源，并计划在之后推出集成云。\n所以，可以看出Salesforce其实更在乎的是集成（Integration）这个词。\n5）iPaaS、API管理与API集成\niPaaS的集成不光是针对云服务，也包括本地系统，这样就解决了混合云模式下的集成问题。iPaaS集成的范畴，除了API接口之外，一般还会包括更多种类的协议（比如FTP、数据库），也包括对于文件数据的集成。\n从这个角度来理解，API管理更关注API的治理与整合，iPaaS关注更大范畴的集成，包含API集成的概念。\n6）SOA、ESB与微服务的关系\n微服务架构和SOA架构非常类似，微服务是SOA的升华，只不过微服务架构强调的是“业务需要彻底的组件化及服务化”，原单个业务系统会被拆分为多个可以独立开发、设计、部署运行的小应用，这些小应用间通过服务化完成交互和集成。\nESB是一种集中式服务治理的架构，看上去微服务中不需要ESB，Martin Fowler也不赞同在微服务架构中继续用ESB。\n我们下面要介绍到的下一代微服务架构核心-服务网格*，则可以视为分布式的ESB。*\n微服务2.0：服务网格与Serverless\n1、服务网格\n微服务当前遇到的挑战包括：\n 技术门槛高：开发团队在实施微服务的过程中，除了基础的服务发现、配置中心和鉴权管理之外，团队在服务治理层面面临了诸多的挑战，包括负载均衡、熔断降级、灰度发布、故障切换、分布式跟踪等，这对开发团队提出了非常高的技术要求。 代码侵入性强：Spring Cloud、Dubbo等主流的微服务框架都对业务代码有一定的侵入性，技术升级替换成本高，导致开发团队配合意愿低，微服务落地困难。  为了解决上述问题，号称微服务2.0的服务网格（Service Mesh）应运而生。服务网格这个词最早由著名开源服务网格项目Linkerd所在的Buoyant公司CEO William Morgan所提出。按照他的定义，服务网格是一个软件基础设施层，用于控制和监视微服务应用程序中的内部、服务到服务的流量。\n服务网格架构\nSidecar是服务网格中的核心组成部分，可以看到，上图中每一个微服务都配备了一个Sidecar。此时用户只需要关心业务逻辑，而不用关心服务治理等非业务功能，非业务功能都由Sidecar负责，接管对应服务的入流量和出流量，并将微服务架构中的服务订阅、服务发现、熔断、限流等功能从服务中抽离到Sidecar中。\n服务网格和API网关是两个联系非常紧密的概念，它们的用途既不同，但是在某些方面又相互重叠。在某种程度上，我们可以认为服务网格是一个分布式的、微观层面的API网关，解决微服务服务发现、负债均衡、流量控制等需求。在具体用途上，API网关处理的是所谓南北向流量即内外部请求；而服务网格处理的是东西向流量即内部服务相互间的访问。想深入了解两者区别的读者可以仔细阅读《Service Mesh和API Gateway关系深度探讨》这篇文章。\n南北向流量 vs 东西向流量\n服务网格相关的著名项目包括Linkerd、Envoy和最受欢迎的服务网格框架Istio。Kong也于2019年发布了基于Envoy的开源服务网格产品Kuma。\nKong的服务网格产品：Kuma\n下图是CNCF Landscape里服务网格分类所罗列的项目，其中Linkerd正由CNCF进行孵化。\n2、Serverless\nServerless（无服务器架构）这个概念在2012年时便已经存在，比微服务和服务网格的概念出现都要早，但是直到微服务概念大红大紫之后，Serverless才重新又被人们所关注。\nServerless是一种构建和管理基于微服务架构的完整流程，它与传统架构的不同之处在于，完全由第三方管理，由事件触发，存在于无状态、暂存的计算容器内。Serverless相关的重要概念包括FaaS（Functions as a Service，函数即服务）。开发者把函数上传到云厂商的FaaS平台，函数只在被请求时才实例化运行，然后被销毁，其它时候不占用任何服务器资源，完全实现按需使用，大幅度降低了服务器占用和成本。\nServerless通常适用于实时性要求不高、无状态的场景，例如突发事件处理、数据统计分析、视频解码、离线批量计算等等，像AWS FaaS平台Lambda限制用户功能必须在15分钟内完成。\n相较服务网格，Serverless概念更为超前，虽然AWS Lambda、阿里云等许多平台都已经提供对其的支持，但是目前仍处于发展早期，无论是成熟项目数量和企业应用程度都相对有限。\nFaaS Landscape\nCNCF Serverless Landscape\n微服务 vs 宏服务：新的抉择\n最近，Uber支付体验平台的工程经理Gergely Orosz发布推文表示他们的架构方向已经发生了变化。\n “声明一下，在Uber，我们正将许多微服务转移到@copyconstruct所称的Macroservices宏服务（大小适中的服务）。 确切地说，B/C测试和维护成千上万的微服务不仅很难——它可能会带来更多的长期麻烦，而不是解决短期问题。 微服务确实可以帮助团队在早期快速推进。 等你意识到服务越少越好时，已为时已晚。你需要解决很多服务的“困难”部分。 我们在不断增加更多的服务，但也在停止使用服务，并且会更慎重的思考新的服务。“\n 全部的上下文可以在这里阅读。有一篇英文文献中这样描述Macroservices宏服务：宏服务应该定义为运行2-20个单独服务的应用程序体系结构，每个服务代表一个中等大小的代码库，可处理业务中定义明确的部分。宏服务的关键是拆分服务，最大程度地从拆分中获得收益，同时最大程度地降低运行多个服务的开销。通俗点讲，宏服务介于单体服务到微服务之间，关注的不再是某一个细节点，而是一个业务点。\n实际上，宏服务目前的定义并不清晰，影响和实践相当有限，也并非比微服务更优的解决方案，本质还是不同企业和团队在架构演进中对于系统复杂性的不同度量。\n总结\n微服务的理念不同的团队有不同的实践，例如微服务如何拆分、组织架构如何搭建、技术栈如何选择。\n我们理解，微服务是云原生的核心，后面要介绍到的容器（及Docker）和Kubernetes是实现的技术方法和手段，DevOps是配合的文化和研发流程，但是微服务带来的启发，更多是思维方式上的转变。\n第四部分：容器和Docker 虚拟化与容器\n在容器技术之前，业界的网红是虚拟机。虚拟机技术的代表是VMware和OpenStack，我在虚拟化与超融合系列里做过介绍。很多人都用过虚拟机，就是在操作系统里安装一个软件，然后通过这个软件，再模拟一台甚至多台“子电脑”出来。在“子电脑”里，可以和正常电脑一样运行程序，例如微信、Word。“子电脑”和“子电脑”之间，相互隔离互不影响。\n虚拟机虽然可以隔离出很多“子电脑”，但占用空间大，启动慢，虚拟机软件可能还要花钱（例如VMware）。而容器技术恰好没有这些缺点，它不需要虚拟出整个操作系统，只需要虚拟一个小规模的环境（类似“沙箱”），启动时间很快，几秒钟就能完成。而且，它对资源的利用率很高（一台主机可以同时运行几千个Docker容器）。此外它占的空间很小，虚拟机一般要几GB到几十GB的空间，而容器只需要MB级甚至KB级。虚拟机和以Docker为代表的容器都是虚拟化技术，不过容器属于轻量级的虚拟化。下面是两者的主要对比。\nDocker的源起\n我们再来看看Docker，Docker本身并不是容器，它是创建容器的工具，是应用容器引擎。虽然Docker 把容器技术推向了巅峰，但容器技术却不是Docker发明的。实际上，容器技术连新技术都算不上，因为它的诞生和使用有些年头了，像最早的容器LXC发布于2008年。\nDocker本来是做PaaS的公司，原来叫做DotCloud，成立于2010年。但比起Pivotal、Red Hat等著名企业，DotCloud运营并不成功。眼看就要失败的时候，2013年DotCloud决定开源自己的容器项目Docker。但是短短几个月，Docker迅速崛起，吸引大量的开发者使用。随着Docker在开发者中越来越流行，2013年10月，DotCloud公司正式更名为Docker，2014年8月，Docker 宣布把PaaS业务出售，开始专心致志做Docker。\nDocker一词意为码头工人，而它的logo则是一个托着许多集装箱的鲸鱼，非常形象：Docker是鲸鱼，而集装箱则是一个个的容器。在Docker的官网上，对于容器有一个一句话的解释“A standardized unit of software”，即“软件的一个标准化单元”。\n下面的图片比较了Docker和传统虚拟化的不同之处，容器是在操作系统层面上实现虚拟化，而传统方式是在硬件层面实现，所以导致两者的特性有很大区别，Docker更小更轻。\nDocker vs 虚拟化\n而Docker与传统的Linux容器也并不完全一致。Docker技术最初是建立在LXC技术之上的，大多数人都把LXC技术与传统的Linux容器联系在一起，尽管后来它已经摆脱了这种依赖性。LXC作为轻量级虚拟化很有用，但它没有很好的开发人员或用户体验。Docker技术带来的不仅仅是运行容器的能力，它还简化了创建和构建容器、加载镜像和镜像版本控制等过程。传统的Linux容器使用可以管理多个进程的init系统，这意味着整个应用可以作为一个整体运行。Docker鼓励将应用程序分解为它们各自的进程，并提供了实现这一点的工具，这种粒度有不少优点。\n传统Linux容器 vs Docker\nDocker解决的问题\n众所周知，Linux上我们不愉快的经历之一就是安装软件。因为系统硬件、操作系统环境不一样，软件包有不同的依赖性，所以必须要安装完软件依赖路径上的所有包，这个链条之长，往往要耗费几小时甚至几天的时间。例如下面的案例，我要安装Docker，系统提示我必须要先安装selinux-policy、selinux-policy-base、selinux-policy-targeted三个相关模块。而我安装selinux-policy的时候，又提示要先安装python；安装python的时候，又提示我要先安装_bz2、_curses、_curses_panel等等模块…\n这就是由于环境不统一带来的巨大问题，每天在世界各地的数千万台机器上都会重复上演无数次。那么，如果服务器环境能够标准化，那我们安装任何软件只需要一个版本就可以解决问题。\n同时，如果所有服务器环境统一、标准化，还能保留上面的配置、安装的软件和应用，对于我们来讲就更加有用。Docker正是在操作系统之上实现了这个标准化、统一化的运行环境，并且把各种不同的配置和应用存储成镜像，供未来使用。这有点类似于我们熟悉的Ghost或者虚拟光驱，把需要的环境和状态保留为镜像，随时恢复、随时使用。不过Ghost基于操作系统，镜像是一个大文件，管理起来并不方便，恢复速度也很慢，同时不支持跨平台的镜像恢复；而虚拟光驱则是基于软件层面，使用范围有限；而Docker正处于两者之间，能完成更多功能的同时，还实现了镜像的快速加载和运行。\nGhost软件\n虚拟光驱软件\n我们在上一部分讲微服务的时候，将其比喻成装配式建筑。把这个比喻用在Docker上的话，我们只要提前设计好模板（配置环境、部署软件或服务），就能在工厂（Docker）里批量化生产（说复制可能更加合适）出楼板、墙板、楼梯、阳台等构件和配件（容器所装载的、不同的微服务），这些构件在建筑施工现场经过组装拼合（API访问），就能成为各种各样的建筑（各种类型的产品和应用）。\n装配式建筑由各种构件组成\nDocker与各种概念的关系\n所以，Docker曾经有一句Slogan叫做“Build once，Run anywhere（搭建一次，随处可用）”。\nDocker的核心概念\nDocker技术的三大核心概念，分别是：\n 镜像（Image） 容器（Container） 仓库（Repository）  上面的例子里，设计出来的模板就是Docker镜像，生产（复制）出来的构件就是Docker容器，而Docker仓库则是集中放置管理Docker镜像的地方。\nDocker镜像是一个特殊的文件系统。它除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的配置参数（例如环境变量）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。\n每一种模板（镜像）能够创建出一种构件，但是模板可以由不同的设计师来设计，提供不同用途、不同风格，例如斜顶式阳台、嵌入式阳台、包豪斯风格、蒙德里安风格等等，所有人相互之间可以共享，这就形成了大的公共仓库。\nDocker官方提供了Docker Hub来维护管理所有的镜像，只是对于免费用户而言,只能创建一个私有仓库。Docker Hub里提供了大量高质量的官方镜像，例如Oracle、MySQL、redis、Ubuntu、Nginx、python、Docker（Docker in Docker！）等等，开发人员需要一个环境的时候，可以直接到Docker镜像仓库去查找，减少了大量无谓的环境安装工作。\nDocker Hub\nDocker创始人曾经公布过一个相关数据，Docker Hub里镜像的下载数量从2014年的100万次，3年内猛增到了120亿次。\n下面是我从Docker Hub上拉取一个hello world演示镜像，并且运行的示例。\nDocker的好处\nDocker给我们带来的好处非常多，下面简单列举几点：\n 更高效的利用系统资源  有了Docker，我们可以在一台服务器上运行很多应用，充分利用硬件资源。例如现在我们有一台Linux服务器，可以构建不同版本的Ubuntu镜像启动，并且为不同的用户分配不同的容器。这样用一台服务器就能虚拟出许多运行不同操作系统的虚拟服务器，而对于用户来说，这些都是透明的。许多公有云采用了容器技术为用户提供服务，所以虚拟化与容器共同成为了现代云计算的基石。\n 更快速的启动时间  传统的虚拟机技术启动应用服务往往需要数分钟，而Docker容器应用，由于直接运行于宿主内核，无须启动完整的操作系统，因此可以做到秒级甚至毫秒级的启动时间，大大的节约了开发、测试、部署的时间。\n 保证环境一致性  开发过程中常见的问题之一是环境一致性问题，由于开发环境、测试环境、生产环境不一致，导致有些bug并未在开发过程中被发现，而Docker的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，再也不会有在线下开发环境中运行正常，而部署到线上有各种错误的情况了。\n 持续交付和部署  对于开发和运维人员来说，最希望的是一次创建或配置，可以在任意地方正常运行。开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码，无论在多少台服务器中部署都是如此。Docker可以快速创建容器，快速迭代应用程序，并让整个过程全程可见。\n 更轻松的迁移  由于Docker确保了执行环境的一致性，使得应用的迁移更加容易，Docker可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，其运行结果是一致的，因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。\n 提升复用性，降低耦合性，维护和扩展更轻松  Docker使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。安装Docker后，我们可以从Docker Hub上获取各种各样的操作系统镜像，这个操作很简单，只需要拉取相应的镜像到本地然后运行即可。另外我们可以将数据库、Web服务器、缓存服务器运行在不同的容器中，降低了各个服务之间的耦合性、便于扩展，Docker Hub上有各种各样的优秀镜像，我们可以直接拿来使用，不需要自己搭建，应用的部署就像搭积木一样简单。\n 实现沙盒机制，提高了安全性  由于应用运行在容器中，与操作系统隔离开，从而使操作系统基本不可能受到破坏。另外如果应用因为攻击而瘫痪，并不需要重启服务器，直接重启容器或者再启动一个镜像就可以了。\n容器与微服务\n容器是微服务和云原生架构的最佳实现载体。微服务与容器几乎是完美的搭配。单体式架构（Monolithic）变成微服务架构（Microservices），相当于一个全能型变成N个专能型，每个专能型分配一个隔离的容器，赋予了最大程度的灵活。\n服务器势必会走上虚拟化的道路，因为虚拟化有太多的优势，例如前文所说的低成本、高利用率、充分灵活、动态调度等等。而采用容器之后，只需要一台服务器，创建十几个容器，用不同的容器，来分别运行不同用途的服务程序。这些容器，随时可以创建，也可以随时销毁。还能够在不停机的情况下，随意变大，随意变小，随意变强，随意变弱，在性能和功耗之间动态平衡。所以容器化是云计算的终极形态。\n如果把传统IT架构比作传统工厂，容器化比作现代化工厂，那么下一部分我们要讲到的Kubernetes则会将现代化工厂进一步提升为智能化无人工厂。那么当Docker遇到Kubernetes之后将会发生什么有趣的事情？让我们拭目以待。\n第五部分：Kubernetes与容器编排之战 容器编排与Kubernetes\n在单机上运行容器，无法发挥它的最大效能，只有形成集群，才能最大程度发挥容器的良好隔离、资源分配与编排管理的优势。所以企业需要一套管理系统，对Docker及容器进行更高级更灵活的管理，按照用户的意愿和整个系统的规则，完全自动化的处理好容器之间的各种关系，这叫做编排（Orchestration）。\nOrchestration这个词来自于音乐领域，是指一种将不同乐器、音色加以合理的编排等手法营造出一个听感交融、平衡的艺术，它完美地描述了容器编排的含义：为单个应用程序（乐队中的每种乐器）提供协同工作的模式。\n在IT领域编排可以理解为一种工作流，它能把整个IT系统都串接起来，然后自动化运作。在云原生时代，整体式的应用早已成为过去时，应用一般由单独容器化的组件即微服务组成，而这些组件需要通过相互间的协同合作，才能使既定的应用按照设计运作。\n2014年6月，IT基础设施领域的领先者Google发布了Kubernetes（简写为K8S）。编排概念并不是由Kubernetes第一个提出的，Kubernetes这个单词来自于希腊语，含义是舵手或领航员。\nKubernetes是基于Docker的开源容器集群管理系统，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能，因为容器本身可移植，所以Kubernetes容器集群能跑在私有云、公有云或者混合云上。\nKubernetes属于主从的分布式集群架构，包含Master和Nodes。Master作为控制节点，调度管理整个系统；Nodes是运行节点，负责运行应用。Pod是Kubernetes创建或部署的最小单位。一个Pod封装一个或多个容器（Container）、存储资源（Volume）、一个独立的网络IP以及管理控制容器运行方式的策略选项。\nKubernetes的主要功能包括：\n 资源调度：资源调度是一套分布式系统最基本的核心指标 资源管理：控制Pod对计算资源、网络资源、存储资源的使用 服务发现：管理外在的程序或者内部的程序如何访问Kubernetes里面的某个Pod 健康检查：监控检测服务是否正常运行非常重要 自动伸缩：因为涉及到环境的快速迁移和复制，虚拟机时代之前都非常难实现。容器化时代很自然的解决了这个问题，Kubernetes保证了资源的按需扩容 更新升级：Kubernetes为服务的滚动和平滑升级提供了很好的机制  Kubernetes使用案例：滚动发布\n下面我们举一个Kubernetes的应用场景，帮助大家更好的理解Kubernetes的用途。\n应用程序升级面临最大挑战是新旧业务切换，将软件从测试的最后阶段带到生产环境，同时要保证系统不间断提供服务。长期以来，业务升级渐渐形成了几个发布策略：蓝绿发布、灰度发布（金丝雀发布）和滚动发布，目的是尽可能避免因发布导致的流量丢失或服务不可用问题。\n在微服务架构盛行的时代，用户希望应用程序时时刻刻可用，为了满足不断变化的新业务，需要不断升级更新应用程序，有时可能需要频繁的发布版本。实现\u0026quot;零停机\u0026rdquo;、“零感知”的持续集成和持续交付/部署应用程序，一直都是软件升级换代必须面对的难题和追求的理想方式，也是DevOps诞生的目的。\n滚动发布/滚动更新（Rolling Update Deployment）是指每次只升级一个或多个服务，升级完成后加入生产环境，不断执行这个过程，直到集群中的全部旧版本升级成为新版本。在整个滚动发布期间，保证始终有可用的副本在运行，从而平滑的发布新版本，实现零停机、用户零感知，是云原生时代非常主流的发布方式。\n下图是滚动发布的流程示意图，Load Balance是前端的负载均衡器，橙色是正在运行旧版本服务的节点，紫色是正在更新及更新完毕新版本服务的节点。\n滚动发布流程示意图\n可以看到，滚动发布开始后（Step 2），负载均衡器将服务器A从集群里摘除，服务器A进行新版本的发布，由服务器B和服务器C对外提供版本1.0的服务；Step 3，服务器A更新完毕，部署验证成功，负载均衡器将其加入集群，开始和服务器C一起对外提供不同版本的服务，同时服务器B开始发布；直至服务器ABC全部发布完成（Step 5），服务都更新到最新的2.0版本。\n滚动发布的优点是用户无感知，平滑过渡，同时不需要冗余服务器，节省资源。不足是部署时间慢，取决于每阶段的更新时间；发布策略较复杂；同时涉及自动化的更新策略、部署验证、回滚机制等等，自动化程度比较高，通常需要复杂的发布工具支撑，而Kubernetes正好可以完美的支持这个任务。\nKubernetes通用的编排模式是控制循环，用伪代码表示如下：\n解释一下，Kubernetes集群本身状态就是实际状态，而期望状态来自于用户提交的配置文件。滚动发布的时候，Kubernetes将会根据这个控制循环，使用一个叫做Deployment的控制器，通过创建新的集群（下图中的v2版本ReplicaSet复制集）将其控制的Pod副本从0个逐渐变成3个，与此同时旧的集群（下图中v1版本的ReplicaSet）管理的Pod副本数则从3个逐渐变成0个，以此将一个集群中正在运行的多个Pod交替的逐一升级，实现滚动发布的效果。\n如果在发布刚开始的时候，集群里只有1个新版本的Pod，这个Pod有问题启动不起来，那么滚动发布就会停止，开发和运维可以及时介入解决问题。而应用本身还有旧版本的集群和Pod在线，所以服务不会受到任何影响。关于滚动发布的详细介绍和互动教程可以阅读这里。\n下面这张图展示了使用Kubernetes，配合代码仓库GitLab、Docker镜像仓库Harbor、构建工具Jenkins，实现自动化的CI/CD流程。\n上一部分结束时我们提到，传统IT架构好比传统工厂，容器化好比现代化工厂，而Kubernetes则是智能化的无人工厂，让容器和应用能够高效自动、井然有序的被控制和管理；Kubernetes还实现了服务的抽象、解耦、高扩展、统一调度与集中化管理，例如用户可以专注用同样的方式在不同硬件上的应用，比如GPU节点池和低优先级的CPU节点池。Kubernetes不仅解决了容器的编排问题，让容器应用进入大规模工业生产，更进一步对云原生应用提供了定义规范，CNCF整个技术栈都是围绕Kubernetes建立，所以Kubernetes是云原生生态最重要的基石，可以说“Kubernetes是云原生时代的Linux”，即云原生应用的操作系统。\n高扩展的Kubernetes：兼容不同的硬件节点\nKubernetes：云原生应用的大规模工业生产\n回到本文第一部分，我们曾经用集装箱革命比喻云原生。现在大家已经理解，货船可以类比操作系统，集装箱类比容器，里面装的货物则是一个个的微服务，吊臂、吊桥、起重机等自动化操作设备是Kubernetes，而一整套集装箱的操作方法和流程则是DevOps。所有这些加起来构成了现代PaaS所具备的能力：操作系统、集群管理、应用编排、应用发布、持续集成等等。\n容器编排之战\n意识到容器编排的重要性，Docker在2014年发布了Docker Swarm（Swarm是蜂群的意思），以一个整体来对外提供集群管理功能，最大的亮点就是全部使用Docker项目原来的容器管理API来完成集群管理。\n同时从2014年底开始，Docker收购了最先提出容器编排概念的Fig项目，并改名为Compose（Compose是作曲的意思），它可以用来组装多容器的应用，并在Swarm集群中部署分布式应用。\n2014年Kubernetes发布之后，为了与Swarm竞争，在容器编排地位取得绝对的优势，Google、RedHat等开源基础设施公司共同发起了CNCF基金会，希望以Kubernetes为基础，建立一个由开源基础设施领域厂商主导、按照独立基金会方式运营的平台社区，来对抗以Docker公司为核心的容器商业生态。\n一方面Kubernetes脱胎于Google内部久负盛名的大规模集群管理系统Borg，是Google在容器化基础设施领域十余年实践经验的沉淀和升华，Google利用Kubernetes的架构和设计思想成功将其所有应用（搜索、地图、视频、金融、社交、人工智能）运行在超过100万台服务器、超过80个数据中心，每周的20亿个容器上，所以Kubernetes是唯一具有超过10年以上大规模容器生产使用的技术经验和积淀的开源项目。并且Kubernetes采用了非常优雅的软件工程设计和开源开放的态度，使得用户可以根据自己的使用场景、通过灵活插拔的方式，采用自定义的网络、存储、调度、监控、日志等模块，所以在Github上的各项指标一路飙升，将较为简单、并且生态自闭的Swarm项目远远地甩在了后边。CNCF社区也迅速增加了一系列容器生态的知名工具和项目，大量的公司和初创团队将注意力投向CNCF社区而不再是Docker，CNCF本质上成为了以Kubernetes为核心的生态系统。\n企业服务大厂也纷纷加入Kubernetes平台战局，在公有云或者私有PaaS平台上来发展自己的Kubernetes产品。像微软直接找来Kubernetes联合创始人Brendan Burns负责领导Azure容器服务团队，自身的混合云产品Azure Stack也大力支持Kubernetes。IBM同样也靠以Kubernetes为核心的PaaS软件IBM Cloud Private来抢占企业私有云容器平台市场，尤其是微服务的管理需求。很早就支持Kubernetes的Redhat，在2015年推出的OpenShift 3.0版中，不惜放弃自己的容器调度工具，开始支持Kubernetes，现在更成为了支持跨多云、混合云架构，以及裸机、容器和虚拟机的企业级通用应用管理平台。而虚拟化龙头VMware也改为力推主打通吃多家IaaS和Kubernetes集群管理的容器服务软件，甲骨文也在旗下云端服务支持Kubernetes。\n在用户、社区和大厂的支持中，Kubernetes逐步成为企业基础架构的部署标准和新一代的应用服务层。\n2016年，面对CNCF的竞争优势，Docker公司宣布放弃现有的Swarm项目，将容器编排和集群管理功能转到Docker项目当中。然而这种改变带来的技术复杂度和维护难度，给Docker项目造成了非常不利的局面。不同于Docker，Kubernetes推进的民主化架构从API到容器运行的每一层，都给开发者暴露出了可扩展的插件机制，鼓励用户通过代码的方式介入每一个阶段。Kubernetes的变革非常有效，很快在整个容器社区中催生出了大量的、基于Kubernetes API和扩展接口的二次创新产品，例如前文提到的Istio等等。Docker公司在Kubernetes社区崛起和壮大后，败下阵来。\n2017年，Docker公司将容器运行时部分Containerd捐献给CNCF社区，并在自己主打产品Docker企业版中内置Kubernetes项目，持续了两年的容器编排之争终于落下帷幕，Kubernetes成为了最后的胜利者，而Docker输掉了最关键的一仗，失去了成为云原生时代操作系统的机会。\nDocker在最重要的容器编排之战中失败，带给我们的教训包括：\n 开源不等于免费，开源是一种商业模式，一个开源组织和开源项目要想生存下去，最重要的基础就是普遍被使用，不然很快就会被竞争者替代 开源技术终将走向商业，包括Docker，必然面临企业市场的挑战 Docker进入企业级市场，有优势也有劣势，优势是挟Docker的大量开发者，劣势是没有做过企业级市场，开发者市场和企业级市场的做法完全不同 Docker在竞争中失利，看起来是时机和生态构建的问题，但归根结底是基因和能力问题  此系列文章的前五部分，我们详细介绍了云原生的各种理念和技术。在最后一部分，我们将展开总结和思考，分析云原生时代的机遇与挑战。\n第六部分：机会与思考 上文主要介绍了Kubernetes与容器编排之战，本文的最后一部分将系统性的总结云原生能带给我们什么样的未来，相关的创业和投资机会在哪里。\n每一次IT产业架构的变革都会带来巨大的机遇和行业洗牌的挑战。过去的三四十年间，IT业经历了多次重大的变革，包括20世纪七八十年代从大型机向小型机的转移、九十年代C/S架构的普及，以及21世纪初互联网的兴起，先后造就了IBM、思科、惠普、Oracle、EMC、SAP等巨头企业。\n历次IT技术革命还有个共同特点：无论原有的基础软硬件公司此前有多么牢不可破的垄断地位，一旦不能符合新的IT技术变革的趋势，洗牌在所难免。\n现代云计算的浪潮开始于2000年以后，已经造就了VMware、ServiceNow、Salesforce、Shopify等数百亿美金的明星企业，以及无数的独角兽公司。\n云计算是通过互联网的方式按需交付基础设施（硬件/服务器）、存储、数据库和各种应用服务，通常这些服务是由AWS、Azure等公有云或者私有云平台提供的。\n而云原生是一种理念和架构，用于以针对云环境优化的方式组装上述所有基于云的组件。因此云原生也是一个目的地：对于那些希望实现基础设施和流程现代化，甚至组织文化现代化的企业来说，最终的目标是仔细选择最适合其具体情况的云技术。\n要从云计算中获得最佳效果，需要使用云原生架构；云原生的普及又会促进云计算的加速发展。\n从统计数据和发展趋势来看，云原生被接受的程度和普及速度正在大大加快，例如下图显示，自从2016年以来容器的使用量每年都在快速上升。IDC预计，到2022年90%的应用程序将采用微服务架构和第三方代码，35%的生产应用程序将诞生于云端。由于容器和敏捷方法的采用，预计2018-2023年间将诞生5亿个新应用程序。由数字化转型，以及接受和采用新技术的需求驱动，云原生将更深入地渗透到大型企业组织中。这意味着云原生技术和方法可能会遵循敏捷和DevOps的模式，越来越多地吸引更多的利益相关者，包括管理者和业务线领导人，在未来几年内覆盖一半或更多的组织。\n各种场景容器使用量都在逐步上升\n但目前不是所有的云计算技术和产品都能很好的满足云原生架构分布式、自动化、轻量化的要求，传统的IT基础设施正在受到越来越大的冲击，例如传统集中式数据库正在逐渐被分布式数据库所取代，虚拟机技术受到了容器的巨大冲击，分布式监控系统完全替代了传统的监控产品，而传统的安全产品也远远无法满足云原生安全性的要求。\n还需要注意的是，云原生的概念不仅仅只意味着容器、Kubernetes或Serverless，也为下一项技术留下了足够的空间。\n云原生投资的分层\n对于大多数软件开发组织来说，仍然处于采用微服务和容器的早期阶段。新机遇一方面源自于云原生在各行各业的应用，一方面则是云原生相关新的基础设施。\nCNCF全景图呈现了比较完整的云原生项目和分类，我们可以将其简化成如下图所示的几种大的分类：\n一共分为AppDev \u0026amp; DevOps；Management；Runtimes；Infrastructure and Services；Serverless；Observability；Security八个大的模块。\n从广义的角度来讲，云原生应用的设计、开发、管理、运维、分析与传统应用有非常大的不同，生态的每个环节、技术的每个领域都会有许多机会，例如云原生应用的设计、咨询、开发、培训，需要有方案商、供应商、实施商；在基础设施层面，数据库、开发工具、核心中间件、安全产品等等都会有巨大市场需求，例如Service Mesh+安全、Serverless+安全、容器+安全、多云+安全，例如云原生数据的分析处理，例如云原生架构的灾备管理。\n我个人将云原生的生态分为三层：\n 技术层  技术层包括云原生技术相关的基础设施，主要分为两种类型：\n 原有技术的替代品：例如ETCD取代传统的数据库 全新基础设施：新技术相关产品，例如Istio和OpenFaaS   应用层  应用层主要是云原生在各行业的具体应用。\n 服务层  包括云原生相关的培训、咨询、认证等相关服务。\n下面我重点讲讲技术层和应用层。\n云原生技术层\n下面的表格里代表性的列举了云原生技术层的几个领域及相关项目。\n下图展示了当前这些项目的市场占有率情况。\n可以看到技术层涉及的范围非常广，机会非常多，本文仅展开介绍其中我比较看好的一个领域-云原生安全。\n据CNCF统计，采用容器技术的挑战中，开发团队面临的文化挑战、安全性、复杂性、就绪性和监控分别排在前五位。\n使用容器的挑战\n在云原生架构中，安全问题显得尤其突出的原因有以下几点：\n 快速迁移到云原生架构对企业安全状况和运营产生了深远的影响。在容器、微服务和编排框架的世界中，以持久“状态”运行在“服务器”上的“应用程序”的概念已经过时。现在，该应用程序或服务是一个分布式系统，由多个组件组成，这些组件运行在数量可变的节点上，处于几乎恒定的变化状态。依赖于机器隔离和可预测的系统状态的传统安全控制是无效的。对服务到服务的通信视而不见的安全策略以及缺乏水平可扩展的控件，根本无法跟上当今微服务应用程序的步伐。 随着企业将工作负载从数据中心转移到AWS、Google Cloud Platform和Microsoft Azure，它们已经改变了购买安全性的方式。他们需要独立于平台的安全工具，这样就不会被绑定到特定的云平台中。 复杂系统可以创建大量的警报和事件日志，这会是一项惊人的任务。安全项目被堆积如山的繁忙工作所淹没，分析师们疲惫不堪。随着分析师对惊人的数据量变得不敏感，真正的问题就从他们的手指间溜走了。 DevOps是一种协作方法，它将开发人员和IT操作统一起来，以加快应用程序的构建、测试和部署，它也影响了IT安全。当开发人员可以直接将他们的应用程序部署到生产服务器上，因为业务敏捷性需要它时，他们就不能停下来找出安全问题。DevOps提供了一种完全不同的安全方式，安全自动化有很多机会。  为了在云本机环境中保护业务资产，组织必须将安全实践和技术与它们要保护的系统纳入体系结构中。正如DevOps支持持续开发和部署一样，“DevSecOps”也必须支持持续的安全管道。这意味着要建立全新的方法、功能和工具，以确保旨在保护云原生系统的解决方案呈现以下基本特征：\n 全局的实时可见性：局部的或事后的可见性是不够的。无论位于何处，基础架构层和应用程序都必须可见。 快速、迭代的反馈循环：反馈循环允许安全措施不断适应快速变化的环境。 解决安全问题的工程方法：自动化、连续测量和受控实验将是解决整个企业安全问题的主要方法，取代手动分析和控制更新。  因此，像Netflix、Lyft和Square等组织已经开始将云原生安全作为工程问题来处理，使用自动化来避免这些陷阱，并使安全团队更加有效。他们还规避了将检测、响应和开发团队分开的烟囱式结构，在构建安全检测机制并将它们与响应编排集成时遵循DevOps的思想。\n来自Netflix的安全检测组件示例\nKubernetes官网\n云原生的安全分为4C，即代码、容器、集群、云四个层级。\nCNCF全景图中安全与合规子分类里包含的项目如下图所示。\n像在我多篇文章里曾经提及的新一代云安全公司，市值189亿美金的CrowdStrike，直接将自己定义为云原生的端点保护平台（Cloud-Native Endpoint Protection Platform），以此同传统的端点保护产品区分开来。\n下面我介绍几家和云原生安全相关的初创企业。\n1、Capsule8（B轮）\nCapsule8是一家由经验丰富的黑客和安全企业家创建的高新科技初创型企业，总部位于纽约布鲁克林，成立于2016年秋季，在2018年8月获得1500万美元的B轮融资。\nCapsule8开发了业界第一个也是唯一一个针对Linux的实时0day攻击检测平台，可主动保护用户的Linux基础设施免受攻击。Capsule8实时0day攻击检测平台可显著改善和简化当今基础架构的安全性，同时为未来的容器化环境提供弹性的支持。\n混合云架构已经成为企业IT基础设施的重要架构，但其复杂性也使企业面临多种攻击的风险，根据Capsule8与ESG Research赞助的一项新研究表明，仅2017一年就有42%的企业报告了混合云环境受到攻击，28%的企业表示0day攻击是这些攻击的起源。\n混合云环境由于存在多云服务商，缺乏中心控制和完整的合规性规划，存在边界模糊，访问策略不一致等问题，加上公有云的暴露面增大，攻击者容易通过攻击薄弱点进入，这也是近年来如软件定义边界SDP、移动目标防护MTD等新方案兴起的原因。\n无论是传统环境，还是混合环境，防护利用0day漏洞的高级威胁需要企业安全团队全方位持续防护资产、获得环境的可视性，检测恶意行为。\nCapsules8平台整体架构图如下所示：\n假设客户生产环境是一个混合云环境，服务器部署于客户侧数据中心、公有云AWS和Azure中。Capsule8的整个工作流程主要分为感知、检测、阻断、调查四步。\n2、Aqua Security（C轮）\nAqua Security成立于2015年，它为基于容器、Serverless和云原生应用提供保护解决方案。2019年，Aqua Security完成了6200万美金的C轮融资，累计融资超过1亿美元。它的客户包括能源、航空航天、互联网、媒体、旅游、零售、制药和酒店业的100多家知名企业。\nAqua Security的云原生安全平台使用现代化的零接触方法来检测和预防威胁，在整个应用程序生命周期内提供全面的可见性和安全自动化。例如在漏洞管理方面，Aqua可以实现：\n扫描镜像和功能：Aqua几乎与所有CI/CD工具集成在一起，可在构建镜像和功能时主动扫描，及早发现问题并允许快速修复。\n关注应用风险：下一个挑战是大规模提供安全性。这种情况是指可能要扫描成千上万个镜像的漏洞。但是，其中许多镜像实际上并未在生产中部署，因此即使处于脆弱状态风险也不高。Aqua提供了对正在运行的工作负载中易受攻击组件的实例化的可见性，这使安全团队可以集中精力修复最容易遭受利用风险的那些组件。\n提供可行建议：Aqua提供了有关漏洞的具体可行建议，通常是建议升级到特定的版本或者改变配置和环境变量。\n3、Twistlock（被收购）\n位于CNCF全景图里的Twistlock创立于2015年。曾经在以色列著名的网安黄埔8200部队服役，并在微软企业安全部门工作的Ben Bernstein以不到30万美元的种子轮开始起家，定位容器安全。Twistlock自己贴的标签除了容器安全，就是云原生安全。Twistlock的融资节奏很好，2015年5月天使轮280万美元，2016年7月A轮1000万美元，2017年4月B轮1700万美元，2018年8月C轮3300万美元，2019年就被Palo Alto Networks以4.1亿美金的价格收购。\nTwistlock产品界面\n现在，Twistlock已经能为Amazon ECS、Azure、Docker、GCP、Pivotal、OpenShift、Istio等多个平台提供安全方案。Twistlock的自己一句话介绍是“领先的全栈，全生命周期容器安全解决方案，保护容器环境及其中运行的应用程序，具有轻量级，可扩展和自动化特性，自动化的策略构建和全开发生命周期内的无缝集成”。\n截至目前，Twistlock总结了6方面的核心能力，分别是漏洞管理、合规、运行时防护、持续集成和持续交付、云原生防火墙和访问控制。像运行时防护包括网络和应用程序防火墙，支持Docker和AWS Fargate运行安全以及主机防护，可以通过机器学习为每个应用程序进行自动建模，保护网络，文件系统，进程和系统调用。云原生防火墙方面，Twistlock包括3层防火墙和7层防火墙，它可以自动学习应用程序的网络拓扑，并为所有微服务提供应用程序的微分段，可以检测和阻止XSS攻击、SQL注入等威胁，还可以自动模拟所有微服务之间的所有流量，并允许安全团队集中查看和实施安全流量，同时自动阻止异常，无需手动创建和管理规则。\n除了云原生安全领域，以及前文介绍过的Kong、RapidAPI之外，我再介绍三家知名的云原生技术层创业企业。\n1、Rancher（D轮）\n在本文第一部分我们提过Rancher（中文意思是放牧人）这家公司，它的创始人梁胜职业生涯贯穿软件开发与云计算的发展历史。作为耶鲁大学计算机博士、Java语言J2SE平台核心组件JNI的作者、JVM的领导设计与开发者，梁胜2000年离开Sun创办了应用防火墙软件公司Teros Networks并担任CTO，2001年公司被Citrix收购。2008年梁胜第二次创业创建了Cloud.com，并推出了著名的云计算管理软件CloudStack，他也因此被誉为“CloudStack之父”，2011年Cloud.com被Citrix又以2亿美金收购，他成为Citrix首位华人CTO。随后2014年梁胜创立了容器管理公司Rancher Labs。这是他创建公司的初衷。\nRancher是一个容器管理平台，通过Rancher可以实现Docker和Kubernetes的轻松部署。Rancher由基础设施编排、容器编排与调度、应用商店、企业级权限管理组成。下图展示了Rancher的主要组件和功能。\n今年3月份，Rancher对外公布了4000万美元的D轮融资，由此Rancher累计融资高达9500万美元。\n2、HashiCorp（E轮）\nHashiCorp（简称为Hashi，日语“桥梁”的含义）是我一直非常看好的一家云原生技术企业，不过最近因为禁止中国企业使用其商业产品而被刷屏。它成立于2012年，主要开发DevOps和云管理基础设施相关产品，日裔创始人及CTO Mitchell Hashimoto从12岁就开始创业，目前年仅30岁，公司主要产品都出自于他的手笔。\nHashiCorp旗下包含多款知名的云原生相关开源产品，我们自上而下的来看：\n Nomad：程序自动化，集群管理器和调度器，专为微服务和批量处理工作流设计。与Kubernetes相比，Nomad通用性更强。 Vault：安全自动化，企业级私密信息管理工具。 Terraform：基础架构自动化，安全有效地构建、更改和版本控制基础设施的工具。 Packer：镜像工具，旨在通过简易的方式自动化构建镜像。 Vagrant：用于创建和部署虚拟化开发环境的工具，由Mitchell Hashimoto在23岁时开发，并成为其创建HashiCorp的基石。 Consul：网络自动化、服务网格解决方案，它提供了一个功能齐全的控制平面，主要功能包括服务发现、健康检查、键值存储、安全服务通信、多数据中心等等。  今年3月HashiCorp对外公布了1.75亿美元的E轮融资，投后估值为51亿美元。\n3、Snowflake（G轮）\nSnowflake成立于2012年，创始人Bob Muglia曾在微软工作23年，拥有丰富的数据库经验。Bob Muglia认为，NoSQL型数据库并不能完全适应业务要求，基于云端的数据仓库省去了相关软硬件的设置需要，降低了使用门槛。Snowflake包括数据引擎在内的几乎所有技术都是自己研发的，在数据库和数据处理方面拥有非常多的专利，它是一个云原生的SQL数据仓库，完全针对云计算特点设计，部署在AWS等云端平台上，可以将用户所有的数据集中在一个地方，用户只需加载数据然后运行查询就可以查找到各种结构化或半结构化的数据。\n为什么要使用云原生数据仓库？\n作为一个类别，云原生的数据仓库提供了许多好处。首先，它们使公司摆脱了对设备和机器的担忧：在过去的物理服务器时代，公司需要操心服务器机房，或者至少是运行软件或存储数据的特定机器。构建这个物理基础设施是启动或扩展软件公司的一个巨大障碍。现在，服务器成本要低得多，只需点击几下鼠标就可以创建云端数据仓库。公司只需要按需处理和存储数据，并为他们使用的东西付费。云的使用还可以为公司提供更多的冗余和支持，因为他们不再需要担心单个服务器的故障和整个操作的崩溃。大型云服务提供商拥有多个备份系统，可以在全球数据中心之间自动扩展，以保持一切正常运行。这对客户公司来说是双赢的。\n作为一个基于云的数据仓库，Snowflake具有很强的灵活性和可伸缩性。Snowflake基于订阅的模型将存储和计算服务分离，允许它们独立运行。当用户构建插入Snowflake的新解决方案时，他们只支付存储数据或根据需要分析数据的费用。此外，该系统还构建了一个相互连接的云服务器阵列，将数据分散，允许组织内的单个用户或组访问他们需要的特定数据，而无需复杂的数据传输，简化了连接和分析。\n对于云原生数据仓库来说，能够在不影响底层的情况下快速查询数据并使用实时数据执行分析是一个强大的功能。由于数据不断地被各种各样的系统所创建，其中许多系统最初都是云端固有的，因此实时分析这些数据的能力对现代公司至关重要。实时分析会根据需要，只对特定实例和项目收费而不产生更高的成本。\nSnowflake在今年2月份完成了4.79亿美元的G轮融资，估值高达124亿美元，投资机构包括Salesforce Ventures，Snowflake还由此宣布了与Salesforce的战略合作伙伴关系。Snowflake在《福布斯》最新的“云100强”榜单中位列第二，仅次于Stripe。\n云原生技术层的机会我还在《信天研报 | 虚拟化与超融合（一）》系列里提到过，由于容器技术对于传统虚拟机的冲击，众多创业公司正在解构VMware，这将在该系列详细讨论。\n云原生应用层\n云原生能广泛应用在所有的行业，并发挥其快速、灵活、弹性、扩展性强、迁移能力强等多种优势。在这里我仅抛砖引玉，分析下云原生游戏的优点。\n围绕云游戏的许多讨论都集中在其“杀死控制台”的潜力上，从而消除了本地硬件玩游戏的需求。但是，对硬件的持续关注未能抓住云游戏的真正潜力。云游戏的真正创新不仅仅在于我们怎么玩游戏方式，还在于我们玩什么游戏：“云原生”游戏将完全颠覆游戏体验本身，以及这些游戏的销售和销售方式。\n云原生游戏是专门为云开发的游戏，其中客户端和服务器托管在同一架构中，有可能产生全新的游戏体验和商业模式。\n病毒式传播\n大多数MMO（Massively Multiplayer Online，大型多人在线）游戏具有固有的网络效应，这意味着与更多玩家一起玩游戏会更加有趣。然而，MMO通常会遇到冷启动问题：一开始，没有足够的参与者来创造积极的体验，从而导致新用户的流失。与朋友合作玩耍是最好的招募和留住新用户的方式，但是在此过程中可能会遇到很多障碍。例如，用户可以在不同时间或在不同平台上玩。由于不透明的配对规则和服务器限制，在游戏中寻找朋友可能很麻烦。\n利用云原生开发的MMO游戏本质上是跨平台的，因此可以从任何设备上访问。没有下载、安装，或者加载时间，用户不用再为了补丁或者一个游戏的副本需要等待三个小时。\n为了简化入门过程，云原生游戏可以使用深层链接来无缝地允许新玩家加入朋友的游戏会话。同时，想要获得更轻松体验的用户可以实时选择确切的时点来参加比赛或作为旁观者。\n这些支持云的功能共同加速了多人游戏固有的网络效果。如果成功的话，第一个云原生MMO游戏可能会完全通过玩家主导的招募而快速发展，其病毒增长曲线比传统的MMO更类似于Facebook。\n创造视频营销机会\n除了更强大的病毒性之外，云原生游戏还将为AAA（3A大作，高成本、高体量、高质量）游戏提供新的营销形式。传统上AAA游戏依赖于广告牌和展示广告等营销方式。在没有安装时间的情况下，潜在玩家将能够单击链接立即尝试一款游戏—这是一个巨大的进步。\n随着云游戏的普及，视频和有影响力的营销将变得越来越重要。销售佣金和“点击加入”可能会成为云游戏经济中网络大V收入的最大来源。\n实现AI驱动的实时内容生成\n由于客户端和服务器在同一个网络中，云原生游戏可以方便的跟踪和收集用户旅程中几乎所有的数据，这使得我们可以以开创性的方式在游戏中增强人工智能和机器学习能力。\n例如，游戏长期以来通过出售改变玩家外观或周围世界的化妆品来赚钱。由于云提供无限的数据、处理能力和最小的客户端-服务器延迟，人工智能可以实时生成完全动态的环境。以下是基于Nvidia深度学习系统的剪辑，显示用户在AI的帮助下修改了一个逼真的虚拟环境：\n将来，实时内容生成可能会催生新的、沉浸式的故事讲述方法。下一代的“选择你自己的冒险”可能是一个虚拟世界，实时适应你的选择。为了使这些虚拟世界货币化、个性化，自发性的广告可能会出现，类似于《少数派报告》中的生物识别广告。\n更远的未来，AI驱动、程序生成的世界可以为用户提供一个无尽的游乐场，那时距离《头号玩家》里的绿洲世界或者著名的网络世界-元界（Metaverse）已经不远。\n预计我们将在两三年内看到第一款云原生游戏上市，在谷歌、微软、亚马逊和其他许多公司的投资推动下，下一代云原生游戏将有潜力重塑我们所知道的游戏体验。\n在上述认知的推动下，A16Z、腾讯、淡马锡投资了免费沙盒MMO游戏Roblox的1.5亿美金的G轮，相应估值高达40亿美元，他们认为未来游戏将不再只是游戏，甚至将比电影和音乐加在一起的规模还大。游戏的发展也将推动技术革新，而Roblox作为世界上最大的社交平台和多人游戏平台之一，接下来将有望成为未来的Metaverse。\n写在最后\n至此，这篇接近4万字的《云原生时代》已接近尾声。\n我们再来梳理下本文的核心观点：\n 云原生、中台、微服务、CI/CD、Devops、SaaS背后的理念是一致的 即更快速、更灵活、更轻量、更自动，从开发开始，不断实现企业的产品目标和业务目标 类似理念涉及的维度包括开发、产品、运维、销售，从产品、服务到组织结构  如何判断云原生技术层的项目？\n 是否拥有核心技术是关键 单点产品的价值和延展性要足够强。参照Rancher、HashiCorp、Kong 面向客户提供一整套产品化的解决方案具有更大价值 在云原生体系里，开源项目比普通商业项目更占优势。开源项目更容易被其它产品支持和集成；云原生架构早期使用者以开发者为主，开源项目更容易快速建立口碑和影响力；在社区支持下，开源项目质量更容易得到保证 尽量选择成熟和被市场验证的技术和产品  国内的创业机会是否已经到来？\n国内已经出现了像PingCap、Kylin、SkyWalking、Dubbo、ServiceComb等优秀的开源项目，在云原生技术不断成熟和普及、国内开源文化和社区逐渐兴起、去IOE和自主可控的时代背景下，国内对标海外的创业机会将会不断涌现。不过由于国内企业IT水平参差不齐，像API集成、API管理等领域的创业时机尚早，所以选择合适的产品切入点和行业将成为成败的关键，另外团队对软件本质的理解、销售和客户服务能力也是相当重要的因素。\n最后，我真心希望未来3到5年中国新一代的基础软件企业能够高举国产化的大旗，灯火辉煌。\n参考  绿盟科技解读2019创新沙盒 被Palo Alto 4.1亿美元收购的Twistlock是一家什么公司？ DETECTION ENGINEERING FOR CLOUD-NATIVE SECURITY 一文搞懂蓝绿发布、灰度发布和滚动发布 深入剖析Kubernetes学习笔记：“控制器”模型（16） 技术专栏 | 云原生应用之路 极简Docker和Kubernetes发展史 Docker生态到底会不会重蹈Hadoop的覆辙 金丝雀发布、滚动发布、蓝绿发布到底有什么差别？关键点是什么？ 15 Most Interesting Cloud Native Trends From The CNCF Survey 10分钟看懂Docker和K8S 极简Docker和Kubernetes发展史 “中台不就是微服务吗？有啥区别？” 火热的云原生到底是什么？一文了解云原生四要素！ 大神告诉你如何理解微服务框架 Service Mesh 和 API Gateway 关系深度探讨 一文详解微服务架构 Martin Fowler关于微服务的原文翻译（一） 微服务架构的理论基础 - 康威定律 A text interpretation of the cloud native (rpm) 走访了十几家美国企业服务公司，我们写下了这篇万字文章 | GGV投资笔记第一期 从Uber微服务看最佳实践如何炼成？ Mashape 和 RapidAPI 合并，组成全球最大的应用编程接口（API）集市！ 放弃微服务，改用宏服务，Uber 这波什么操作？ 腾讯大牛深入浅出详解云原生 【零壹视界】从Salesforce收购Mulesoft说起，白话讲讲企业数据交换  EnjoyingSoft之Mule ESB开发教程第一篇：初识Mule ESB 微服务架构 持续集成、持续交付、持续部署 为什么你必须了解云原生？！  What is Cloud-Native? Is It Hype or The Future of Software Development?   本文转载自：蒋宇捷的企业服务投资洞察。\n 云原生时代（一）云原生及CNCF基金会 云原生时代（二）：DevOps与CI/CD 云原生时代（三）：微服务、API管理与集成 云原生时代（四）：容器和Docker 云原生时代（五）：Kubernetes与容器编排之战 云原生时代（六）：机会与思考  ","permalink":"https://cloudnative.to/blog/cloud-native-era/","tags":["Cloud Native"],"title":"云原生时代——投资人视角下的云原生趋势思考"},{"categories":["Kubernetes"],"contents":"前言 这个问题 flannel 和 calico 的 VXLAN 模式下都会发生，部分人的集群的A记录 UDP 下查询可能有问题。原因是 v1.17+ 的 kubernetes 某部分会引起内核的某个 UDP 相关的 BUG 而不是 CNI 的软件层面， WEAVE 没有这个问题，原因后面会说到。写这篇文章的日期是05/28，最开始发现是上周五也就是05/23号，文章从时间线写起，因为很多时候想发文章但是没空。\n由来 上周五我经过同事的工位看到同事的桌面是 kubectl get po 的输出，问他咋开始学 Kubernetes 了，他说跟着视频学下。看了下用的 kubeadm 部署了一套1.18.2的集群。1.18的 kube-proxy 的 ipvs 包的 parseIP 有 bug ，我推荐他换v1.17.5。他当时在部署一个入门的 SVC 实验，无法解析域名。使用dig命令排查了下，下面是对照:\n dig @\u0026lt;podIP\u0026gt; +short kubernetes.default.svc.cluster.local 能解析 dig @10.96.0.10 +short kubernetes.default.svc.cluster.local 超时  很多市面上的kubeadm部署教程都是直接命令 kubeadm init 的，所以我推荐同事去按照我文章的 kubeadm部署 一套后再试试，叫他用v1.17的最新版本v1.17.5，结果还是上面一样。 coredns 实际上还有 metrics 的 http 接口，从 http 层测了下：\n curl -I 10.96.0.10:9153/metrics 超时，很久之后才有返回 curl -I \u0026lt;podIP\u0026gt;:9153/metrics 能直接返回  涉及到本次排查的信息为：\n$ kubectl get node -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME master Ready master 7d8h v1.18.2 10.0.100.3 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-957.el7.x86_64 docker://19.3.8 node1 Ready \u0026lt;none\u0026gt; 7d7h v1.18.2 10.0.100.4 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-957.el7.x86_64 docker://19.3.8 node2 Ready \u0026lt;none\u0026gt; 7d7h v1.18.2 10.0.100.15 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-957.el7.x86_64 docker://19.3.8 $ kubectl get po -o wide -n kube-system -l k8s-app=kube-dns NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES coredns-546565776c-v5wwg 1/1 Running 2 25h 10.244.2.73 node2 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 多次尝试发现很久的时间都是一样，用 time 命令观察了下一直是63秒返回。包括其他任何 SVC 都是这样。\n$ time curl -I 10.96.0.10:9153/metrics HTTP/1.1 200 OK Content-Type: text/plain; version=0.0.4; charset=utf-8 Date: Wed, 25 May 2020 08:39:35 GMT real\t1m3.091s user\t0m0.002s sys\t0m0.007s proxyMode 是 ipvs ，用 ipvsadm 看下超时的时候的状态，一直是SYN_RECV，也就是发送了 SYN ，没收到回包。\n$ ipvsadm -lnc |\u0026amp; grep 9153 TCP 00:59 SYN_RECV 10.96.0.10:41282 10.96.0.10:9153 10.244.2.73:9153 抓包 因为 CNI 使用的 flannel ，用的 VXLAN 模式。master 上抓9153和flannel.1的 8472 端口，coredns 的 POD 所在 node 上抓 flannel 的 VXLAN 包，下面三个是对应的:\n[root@master /root]# tcpdump -nn -i flannel.1 port 9153 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes 16:30:56.705696 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17148909 ecr 0,nop,wscale 7], length 0 16:30:57.708489 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17149912 ecr 0,nop,wscale 7], length 0 16:30:59.712458 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17151916 ecr 0,nop,wscale 7], length 0 16:31:03.716441 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17155920 ecr 0,nop,wscale 7], length 0 16:31:11.732562 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17163936 ecr 0,nop,wscale 7], length 0 16:31:27.764498 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17179968 ecr 0,nop,wscale 7], length 0 16:31:59.828493 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17212032 ecr 0,nop,wscale 7], length 0 16:31:59.829565 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [S.], seq 435819916, ack 911217172, win 27960, options [mss 1410,sackOK,TS val 17212067 ecr 17212032,nop,wscale 7], length 0 16:31:59.829611 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 0 16:31:59.829714 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [P.], seq 1:88, ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 87 16:31:59.829897 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [.], ack 88, win 219, options [nop,nop,TS val 17212067 ecr 17212033], length 0 16:31:59.831300 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [P.], seq 1:113, ack 88, win 219, options [nop,nop,TS val 17212069 ecr 17212033], length 112 16:31:59.831322 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 113, win 342, options [nop,nop,TS val 17212034 ecr 17212069], length 0 16:31:59.831435 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [F.], seq 88, ack 113, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 16:31:59.831633 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [F.], seq 113, ack 89, win 219, options [nop,nop,TS val 17212069 ecr 17212035], length 0 16:31:59.831660 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 114, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 [root@master /root]# tcpdump -nn -i eth0 port 8472 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 16:30:56.705718 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17148909 ecr 0,nop,wscale 7], length 0 16:30:57.708523 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17149912 ecr 0,nop,wscale 7], length 0 16:30:59.712478 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17151916 ecr 0,nop,wscale 7], length 0 16:31:03.716452 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17155920 ecr 0,nop,wscale 7], length 0 16:31:11.732590 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17163936 ecr 0,nop,wscale 7], length 0 16:31:27.764513 IP 10.0.100.3.48683 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17179968 ecr 0,nop,wscale 7], length 0 16:31:59.828541 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17212032 ecr 0,nop,wscale 7], length 0 16:31:59.829521 IP 10.0.100.15.56771 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [S.], seq 435819916, ack 911217172, win 27960, options [mss 1410,sackOK,TS val 17212067 ecr 17212032,nop,wscale 7], length 0 16:31:59.829617 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 0 16:31:59.829729 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [P.], seq 1:88, ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 87 16:31:59.829883 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [.], ack 88, win 219, options [nop,nop,TS val 17212067 ecr 17212033], length 0 16:31:59.831292 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [P.], seq 1:113, ack 88, win 219, options [nop,nop,TS val 17212069 ecr 17212033], length 112 16:31:59.831327 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 113, win 342, options [nop,nop,TS val 17212034 ecr 17212069], length 0 16:31:59.831448 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [F.], seq 88, ack 113, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 16:31:59.831612 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [F.], seq 113, ack 89, win 219, options [nop,nop,TS val 17212069 ecr 17212035], length 0 16:31:59.831665 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 114, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 [root@node2 /root]# tcpdump -nn -i eth0 port 8472 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 16:31:59.836137 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [S], seq 911217171, win 43690, options [mss 65495,sackOK,TS val 17212032 ecr 0,nop,wscale 7], length 0 16:31:59.836328 IP 10.0.100.15.56771 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [S.], seq 435819916, ack 911217172, win 27960, options [mss 1410,sackOK,TS val 17212067 ecr 17212032,nop,wscale 7], length 0 16:31:59.836811 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 0 16:31:59.836910 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [P.], seq 1:88, ack 1, win 342, options [nop,nop,TS val 17212033 ecr 17212067], length 87 16:31:59.836951 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [.], ack 88, win 219, options [nop,nop,TS val 17212067 ecr 17212033], length 0 16:31:59.838385 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [P.], seq 1:113, ack 88, win 219, options [nop,nop,TS val 17212069 ecr 17212033], length 112 16:31:59.838522 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 113, win 342, options [nop,nop,TS val 17212034 ecr 17212069], length 0 16:31:59.838621 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [F.], seq 88, ack 113, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 16:31:59.838703 IP 10.0.100.15.34571 \u0026gt; 10.0.100.3.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.2.73.9153 \u0026gt; 10.244.0.0.2201: Flags [F.], seq 113, ack 89, win 219, options [nop,nop,TS val 17212069 ecr 17212035], length 0 16:31:59.838836 IP 10.0.100.3.56618 \u0026gt; 10.0.100.15.8472: OTV, flags [I] (0x08), overlay 0, instance 1 IP 10.244.0.0.2201 \u0026gt; 10.244.2.73.9153: Flags [.], ack 114, win 342, options [nop,nop,TS val 17212035 ecr 17212069], length 0 先看上面的第一部分，搜了下资料，得知 TCP 默认 SYN 报文最大 retry 5次，每次超时了翻倍，1s -\u0026gt; 3s -\u0026gt; 7s -\u0026gt; 15s -\u0026gt; 31s -\u0026gt; 63s。只有63秒的时候 node 的机器上才收到了 VXLAN 的报文。说明 POD 所在 node 压根没收到63秒之前的。\n一般 LVS 的 dr 模式下 TCP 的时间戳混乱或者其他几个 ARP 的内核参数不对下 SYN 是一直收不到的而不是63秒后有结果，所以和内核相关参数无关。于是同样上面的步骤 tcpdump 抓包，加上-w filename.pcap选项把抓的包导出下来导入到 wireshark 里准备看看。\n报文分析 9153的包 wireshark 里看63秒前面都是 TCP 的 SYN 重传，看到了 master 上向外发送的 VXLAN 报文的时候有了发现。\n可以看到 UDP 的 checksum 是0xffff，我对 UDP 报文不太熟悉， UDP 的 header 的 Checksum 没记错的话CRC32校验的，不可能是这种两个字节都置1的 0xffff ，明显就是 UDP 的 header 的校验出错了。后面几个正常包的 Checksum 都是 missing 的。\nwireshark 的编辑-\u0026gt;首选项-\u0026gt;Protocols-\u0026gt;UDP-\u0026gt;Validate the UDP checksum if possible 勾上更直观看。\n不是根本的解决方法 搜了下wireshark linux udp checksum incorrect，都是推荐把 Checksum Offload disable 掉就行了，例如我这里是 flannel ，则是：\n$ /sbin/ethtool -K flannel.1 tx-checksum-ip-generic off Actual changes: tx-checksumming: off tx-checksum-ip-generic: off tcp-segmentation-offload: off tx-tcp-segmentation: off [requested on] tx-tcp-ecn-segmentation: off [requested on] tx-tcp6-segmentation: off [requested on] tx-tcp-mangleid-segmentation: off [requested on] udp-fragmentation-offload: off [requested on] 再测下正常，而 WEAVE 他们也用的 VXLAN 模式，但是他们在创建网卡的时候把这个已经 off 掉了，所以 WEAVE 的 VXLAN 模式在v1.17+集群没出现这个问题。\n$ time curl -I 10.96.0.10:9153 HTTP/1.1 404 Not Found Content-Type: text/plain; charset=utf-8 X-Content-Type-Options: nosniff Date: Wed, 27 May 2020 02:14:04 GMT Content-Length: 19 real\t0m0.009s user\t0m0.005s sys\t0m0.003s 你以为这样就完了？其实并没有，因为我自己维护了一套 ansible 部署 kubernetes 的方案，每次新版本发布我都会实际测下。并且同事反映了他同样云主机开出来用我 ansible 部署v1.17.5没有这个问题。这就很奇怪了，原因后面说，请接着继续看。\n什么是checksum offload Checksum Offload 是网卡的一个功能选项。如果该选项开启，则网卡层面会计算需要发送或者接收到的消息的校验和，从而节省 CPU 的计算开销。此时，在需要发送的消息到达网卡前，系统会在报头的校验和字段填充一个随机值。但是，尽管校验和卸载能够降低 CPU 的计算开销，但受到计算能力的限制，某些环境下的一些网络卡计算速度不如主频超过 400MHz 的 CPU 快。\n正文 对照组 很奇怪的就是为啥就是我的 ansible 部署的二进制就正常没这个问题，而 kubeadm 部署的就不正常，后面我花时间整了以下几个对照组(期间同事也帮我做了几个条件下的测试，但是不是系统用错了就是版本整错了。。。)，终于找到了问题的范围，下面是我自己统计的对照组信息， kubeadm 和 ansible 版本均为1.17.5测试。os 不重要，因为最终排查出和 os 无关：\n   os type(kubeadm or ansible) flannel version flannel is running in pod? will 63 sec delay?     7.6 kubeadm v0.11.0 yes yes   7.6 kubeadm v0.12.0 yes yes   7.6 kubeadm v0.11.0 no yes   7.6 kubeadm v0.12.0 no yes   7.6 ansible v0.11.0 yes no   7.6 ansible v0.12.0 yes no   7.6 ansible v0.11.0 no no   7.6 ansible v0.12.0 no no    这就看起来很迷了。但是排查出和 flannel 无关，感觉 kube-proxy 有关系，然后今天05/28针对 kube-proxy 做了个对照组：\n   os type(kubeadm or ansible) kube-proxy version kube-proxy is running in pod? will 63 sec delay?     7.6 kubeadm v1.17.5 yes yes   7.6 kubeadm v1.17.5 no no   7.6 kubeadm v1.16.9 yes no   7.6 kubeadm v1.16.9 no no   7.6 ansible v1.17.5 yes yes   7.6 ansible v1.17.5 no no    可以看出就是1.17以上的 kube-proxy 如果使用 POD 则会有这个问题，而非 POD 则不会， 在github 上 compare 了下v1.17.0和v1.16.3。\n发现了 Dockerfile的改动 ， 1.17.0里的 Dockerfile 的BASEIMAGE是用 指定了一个源安装了最新的iptables，然后利用update-alternatives把脚本/usr/sbin/iptables-wrapper去替代iptables 来检测应该使用nft还是legacy， hack 下镜像回自带源里的 iptables 验证下。\nFROMregistry.aliyuncs.com/google_containers/kube-proxy:v1.17.5RUN rm -f /usr/sbin/iptables \u0026amp;\u0026amp;  clean-install iptables构建的镜像推送到了 dockerhub 上zhangguanzhang/hack-kube-proxy:v1.17.5，更改下集群 kube-proxy ds 的镜像。\n$ kubectl -n kube-system get ds kube-proxy -o yaml | grep image: image: zhangguanzhang/hack-kube-proxy:v1.17.5 测试访问成功。\n$ time curl -I 10.96.0.10:9153 HTTP/1.1 404 Not Found Content-Type: text/plain; charset=utf-8 X-Content-Type-Options: nosniff Date: Thu, 28 May 2020 04:47:21 GMT Content-Length: 19 real\t0m0.008s user\t0m0.003s sys\t0m0.003s 对于这个问题我在 flannel 的 pr 下面也参与了回复，同时在官方 github 上提了一个 issue。\n这个问题的触发是由于v1.17+的 kube-proxy 的 docker 镜像里安装了最新的 iptables ， --random-fully选项会触发内核vxlan的bug。\n总结 目前解决问题三种办法:\n 关闭 CNI 的 VXLAN 网卡的 checksum offload 更改 Docker 镜像 升级到新内核，具体版本就不知道了，只要在这个 内核pr 合并后出的内核版本都行，有人说这些可以 Stable kernels 5.6.13, 5.4.41, 4.19.123, 4.14.181 and later have the checksum patch included.  参考链接  TCP超时重传定时器梳理 wireshark文档 offloading  ","permalink":"https://cloudnative.to/blog/kubernetes-1-17-vxlan-63s-delay/","tags":["tcpdump","vxlan","wireshark"],"title":"Kubernetes v1.17+ 集群下 CNI 使用 VXLAN 模式 SVC 有 63 秒延迟的触发原因定位"},{"categories":["OAM"],"contents":"(译)OAM和Crossplane: 构建现代应用的下一个阶段 OAM和Crossplane社区共同致力于建设一个聚焦在标准化的应用和基础设施上的开放社区。\n前言 在2020年三月份，在来自Crossplane社区的协作和巨大贡献下，开放应用模型（即OAM）项目发布了其v1alpha2规范，旨在为OAM本身和任何采用OAM的Kubernetes应用平台带来绝佳的可扩展性。在2020年5月份，随着Crossplane最新的v0.11版本发布，Crossplane现在具备了OAM规范的标准实现。我们十分激动看到两个社区间的合作，合作将标准的应用和基础设施定义与实施一起带入了云原生社区。\n旅程的开始 从Kubernetes工程师的角度来说，我们很接受现在的Kubernetes抽象层级：容器和基础设施API资源。但是对于平台的终端用户而言还是太过底层。\n为了在一定程度上提高终端用户的体验，一些团队试图通过引入PaaS或者GUI来向终端用户隐藏Kubernetes API。初看上去，这似乎是一个好主意。但事实上，这极大的限制了平台的能力。Kubernetes资源模型强调系统的所有能力都要能够可以表达成\u0026quot;数据\u0026rdquo;，例如API对象。向终端用户隐藏这些对象本质上会使得你的PaaS缺乏可扩展性，因而无法利用在生态圈中数不胜数的插件的能力。\n带着我们必须使平台构建者能够定义应用级别的抽象而不引入对平台可扩展性限制的理念，我们开始探索这个领域。\n建模你的应用，而不仅仅是描述 因为我们要定义应用级别的抽象，那么第一个问题就是：什么是应用？ 一个现代应用通常是若干部分的组合(如上图所示)。这样的模式广泛存在于现实世界：多层应用，机器学习训练应用（参数服务器和工作节点），更不用提微服务架构。但是经常被遗忘的是，这些应用的组件经常需要绑定一系列的运行策略。另外，分组策略也是一个特殊类型的运行策略。例如，我们需要在一个组内设置多个组件的安全组。\n因此直观的方法是使用CRD作为描述应用的高级抽象。并且这样可以与应用运行所需的所有其他部分（如运行策略、基础设施）一起合并成一个YAML文件，如下：\n上面的这个例子其实就是阿里巴巴“应用”定义的1.0版本。可以想象，开发人员会抱怨这样的“应用”太过于复杂，尽管它的初衷是使他们的生活更加简单。同样的，我们发现维护这个对象十分的混乱，并且基本上不可能扩展。更糟糕的是，越来越多的能力被安装到我们的Kubernetes集群中，这些都需要加进这个对象——Kubernetes社区发展的十分迅速！\n事实上，如果你仔细检查上述YAML文件，会发现开发者真正关心的只是运行他们应用的定义里的一些较小片段，如\u0026quot;commands\u0026quot;和\u0026quot;package\u0026rdquo;。\n因此为何我们不把这个YAML分解成多个片段呢？开发人员只需要根据他们自己掌握的部分定义\u0026quot;运行什么(what to run)\u0026quot;，运维人员（或者系统管理员）定义运行策略，基础设施运维人员处理基础设施部分。\n在接触了社区中的各个公司之后，我们发现“关注点分离”的想法与微软的团队非常契合。在与微软经过了数周的合作之后，我们定义了如下的顶层草图：\n看到了吗？与all-in-one式的CRD把所有东西揉在一起不同的是，OAM的核心思想本质上是一个\u0026quot;框架（frame）\u0026quot;。因此，开发人员和运维人员可以在整个应用表单的“空格”里填充他们自己片段的数据。这种灵活性保证了任何平台都可以采用这个定义而不会受限于特定的工作负载和能力类型，并且这个系统可以支持任何工作负载（容器、函数、甚至虚拟机）与运行能力（例如autoscaling、ingress、security policy)。\n我们称这种方法为“应用模型”，因为当一个用户需要组合多个片段为一个应用时需要遵循这个规范，他们需要去思考哪些空白需要去填充，例如是否是描述“运行什么”？或者是否是运行策略？这个过程和数学建模十分类似，数学建模使用数学概念和语言来描述系统。我们现在使用OAM概念来描述应用的不同部分。好处是现在平台可以理解这些不同片段的类别，这样可以保证片段的拓扑，或是检查运行策略的兼容性——可发现性和可管理性是现代产品级应用平台的核心。\n我们最终将这个理念发布为OAM spec v1alpha1\nCrossplane + OAM：构建Kubernetes之上的现代应用 OAM spec v1alpha1在阿里云的企业级分布式应用服务（EDAS）以及内部平台上得到了快速采用。然而，我们同样发现了一个在\u0026quot;运行什么\u0026quot;片段中的问题(之前称之为ComponentSchematic)，我们需要发布新版本的ComponentSchematic来进行YAML中的任何修改。这是因为它被设计成了一个模式（schematic）对象，因此开发者可以定义他们需要部署的任何工作负载并与他人分享。一个类似的问题同样存在于运行策略部分（我们称之为\u0026quot;traits\u0026rdquo;）——它的模式同样将schematic暴露给了终端用户。\n在12月份举行的KubeCon北美大会上，我们会见了来自Upbound.io的Crossplane维护者。我们讨论了OAM，以及如何通过利用CRD作为模式(CRD as schemas)的方法将OAM规范与Crossplane无缝集成。我们都认为这个方向是有希望的，在经过了数月的头脑风暴，提案以及无数次的激烈讨论之后，这个想法最终演进成为了如下的OAM spec v1alpha2:\nOAM spec v1alpha2采用了Kubernetes资源模型，因此Kubernetes中的任何数据片段都可以通过简单的定义一个WorkloadDefinition或者TraitDefinition来无缝引用为一个OAM中的工作负载或者特征(trait)。一个关于OAM spec v1alpha2的更深入的博客即将发布，这里可以先看看一个详细的说明。\n在实现方面，我们开发了一个基于Go的实现版本，称之为oam-kubernetes-runtime，作为Crossplane的一部分。现在我们有一个用于OAM的标准Kubernetes运行时。\n组合：完成整个图景 就像你可能看到的，我们仍然缺乏关于OAM的一个部分：我们如何定义组件依赖的基础设施片段，例如，一个来自阿里云MySQL数据库实例（RDS）？如何使这个定义适用于不同的云，就像OAM组件那样。\n在Kubernetes中定义这样应用中心的和可移植的基础设施绝非易事，社区中有一些operator和产品来做这个事情，但是没有像Crossplane中的Composition那样好。Composition组合多个基础设施片段，然后将其发布到与平台无关的CRD中，例如组合CRD来将VPC与RDS描述为一个新的数据库CRD。这个CRD，可以在之后引用为一个OAM的WorkloadDefinition并且成为一个应用的一部分。搞定！\n组合的结果十分的有力，以团队为中心的平台，可以让基础设施运维人员为应用定义和组合供应商无关的基础设施，并且可以使应用开发人员和应用运维人员以OAM的方式定义，运行和管理可移植的应用，不用再关心基础设施的复杂性。基础设施运维人员现在可以管理运行这些应用的基础设施。OAM和Crossplane一起提供了面向应用开发者和基础设施运维人员的优雅的解决方案。\n下一步？ OAM的核心理念是让开发人员描述自己的应用，使应用可以运行在一个无服务器平台，或者在一个本地的Kubernetes集群而无需修改应用的描述。这是阿里巴巴和微软一直在努力的云边协同（cloud/edge consistency）故事的一部分。很明显，与Crossplane的合作弥补了这个故事真正实现所缺失的重要部分，那就是在一个系统中同时涵盖统一的应用定义和基础设施定义。我们将继续努力使Crossplane成为OAM的标准Kubernetes实现，并且具有更好的工作负载/特征可移植性，互操作性，丰富的运行能力；构建一个聚焦于标准应用和基础设施的开放社区。\n（原文地址：OAM and Crossplane: The Next Stage for Building Modern Application）\n","permalink":"https://cloudnative.to/blog/oam-crossplane/","tags":["OAM","Microservices","Crossplane"],"title":"(译)OAM和Crossplane: 构建现代应用的下一个阶段"},{"categories":["Istio"],"contents":"在上一篇文章一文带你彻底厘清 Kubernetes 中的证书工作机制中，我们介绍了 Kubernetes 中证书的工作机制。在这篇文章中，我们继续探讨 Istio 是如何使用证书来实现网格中服务的身份认证和安全通信的。\n本文是对 Istio 认证工作机制的深度分析，假设读者已经了解 Service Mesh 以及 Istio 的相关基础概念，因此在本文对此类基础概念不再解释。对于 Istio 不熟悉的读者，建议先阅读 Istio 官方网站上的的这篇基础介绍 What is Istio?。\nIstio 安全架构 Istio 为微服务提供了无侵入，可插拔的安全框架。应用不需要修改代码，就可以利用 Istio 提供的双向 TLS 认证实现服务身份认证，并基于服务身份信息提供细粒度的访问控制。Istio 安全的高层架构如下图所示：\n图1. Istio Security Architecture，图片来源istio.io\n图中展示了 Istio 中的服务认证和授权两部分内容。让我们暂时忽略掉授权部分，先关注认证部分。服务认证是通过控制面和数据面一起实现的：\n 控制面：Istiod 中实现了一个 CA （Certificate Authority，证书机构） 服务器。该 CA 服务器负责为网格中的各个服务签发证书，并将证书分发给数据面的各个服务的sidecar代理。 数据面：在网格中的服务相互之间发起 plain HTTP/TCP 通信时，和服务同一个 pod 中的sidecar代理会拦截服务请求，采用证书和对端服务的sidecar代理进行双向 TLS 认证并建立一个 TLS 连接，使用该 TLS 连接来在网络中传输数据。  控制面证书签发流程 图1是对 Istio 安全架构的一个高度概括的描述，让我们把图1中控制面的交互展开，看一下其中的细节。\n图2. Istio 证书分发流程\n我们先暂时忽略图中右边蓝色虚线的部分（稍后会在 控制面身份认证 部分讲到），图中左半部分描述了 Istio 控制面向 Envoy 签发证书的流程：\n Envoy 向 pilot-agent 发起一个 SDS (Secret Discovery Service) 请求，要求获取自己的证书和私钥。 Pilot-agent 生成私钥和 CSR （Certificates Signing Request，证书签名请求），向 Istiod 发送证书签发请求，请求中包含 CSR 和该 pod 中服务的身份信息。 Istiod 根据请求中服务的身份信息（Service Account）为其签发证书，将证书返回给 Pilot-agent。 Pilot-agent 将证书和私钥通过 SDS 接口返回给 Envoy。  为什么要通过 Pilot-agent 中转？ 从图2可以看到，Istio 证书签发的过程中涉及到了三个组件： Istiod (Istio CA) \u0026mdash;\u0026gt; Pilot-agent \u0026mdash;\u0026gt; Enovy。为什么其他 xDS 接口都是由 Istiod 直接向 Envoy 提供，但 SDS 却要通过 Pilot-agent 进行一次中转，而不是直接由 Envoy 通过 SDS 接口从 Istiod 获取证书呢？这样做主要有两个原因。\n首先，在 Istio 的证书签发流程中，由 Pilot-agent 生成私钥和 CSR，再通过 CSR 向 Istiod 中的 CA 申请证书。在整个过程中，私钥只存在于本地的 Istio-proxy 容器中。如果去掉中间 Pilot-agent 这一步，直接由 Envoy 向 Isitod 申请证书，则需要由 Istiod 生成私钥，并将私钥和证书一起通过网络返回给 Envoy，这将大大增加私钥泄露的风险。\n另一方面，通过 Pilot-agent 来提供 SDS 服务，由 Pilot-agent 生成标准的 CSR 证书签名请求，可以很容易地对接不同的 CA 服务器，方便 Istio 和其他证书机构进行集成。\n控制面身份认证 要通过服务证书来实现网格中服务的身份认证，必须首先确保服务从控制面获取自身证书的流程是安全的。Istio 通过 Istiod 和 Pilog-agent 之间的 gRPC 通道传递 CSR 和证书，因此在这两个组件进行通信时，双方需要先验证对方的身份，以避免恶意第三方伪造 CSR 请求或者假冒 Istiod CA 服务器。在目前的版本中(Istio1.6)，Pilot-agent 和 Istiod 分布采用了不同的认证方式。\n Istiod 身份认证  Istiod 采用其内置的 CA 服务器为自身签发一个服务器证书（图2中的 Istiod certificate），并采用该服务器证书对外提供基于 TLS 的 gPRC 服务。 Istiod 调用 Kube-apiserver 生成一个 ConfigMap， 在该 ConfigMap 中放入了 Istiod 的 CA 根证书(图2中的 istio-ca-root-cert)。 该 ConfigMap 被 Mount 到 Istio-proxy 容器中，被 Pilot-agent 用于验证 Istiod 的服务器证书。 在 Pilot-agent 和 Istiod 建立 gRPC 连接时，Pilot-agent 采用标准的 TLS 服务器认证流程对 Istiod 的服务器证书进行认证。   Pilot-agent 身份认证  在 Kubernetes 中可以为每一个 pod 关联一个 Service Account，以表明该 pod 中运行的服务的身份信息。例如 bookinfo 中 reviews 服务的 service accout 是 “bookinfo-reviews” 。 Kubernetes 会为该 service account 生成一个 jwt token，并将该 token 通过 secret 加载到 pod 中的一个文件。 Pilot-agent 在向 Istiod 发送 CSR 时，将其所在 pod 的 service account token 也随请求发送给 Istiod。 Istiod 调用 Kube-apiserver 接口验证请求中附带的 service account token，以确认请求证书的服务身份是否合法。    备注：除了 Kubernetes 之外， Istio 也支持虚机部署，在虚机部署的场景下，由于没有 service account，Pilot-agent 和 Pilotd 之间的身份认证方式有所不同。由于 Istio 的主要使用场景还是 Kubernetes，本文只分析 Kubernetes 部署场景。\nSDS 工作原理 和其他 xDS 接口一样，SDS 也是 Envoy 支持的一种动态配置服务接口。Envoy 可以通过 SDS（secret discovery service） 接口从 SDS 服务器自动获取证书。和之前的方式相比，SDS 最大的好处就是简化了证书管理。在没有使用 SDS 前，Istio 中的服务证书被创建为 Kubernetes secret，并挂载到代理容器中。如果证书过期了，则需要更新 secret 并重启 Envoy 容器，以启用新的证书。使用SDS后，SDS 服务器（Pilot-agent充当了 SDS 服务器的角色）将向 Envoy 实例主动推送证书。如果证书过期，SDS 服务器只需将新的证书推送到 Envoy 例中，Envoy 会使用新的证书来创建链接，无需重新启动。\n图3. Envoy SDS 服务\n可以看到，Istio 采用 SDS 后，避免了在证书更新后重启 Envoy，大大减少了证书更新对业务的影响。同时，由于 Pilot-agent 和 Envoy 处于同一容器中，私钥只存在于本地容器，避免了在网络中传递私钥，也降低了私钥泄露的安全风险。\nSDS 服务向 Envoy 下发的数据结构为extensions.transport_sockets.tls.v3.Secret,其结构如下：\n{\r\u0026#34;name\u0026#34;: \u0026#34;...\u0026#34;, // Secret 名称\r\u0026#34;tls_certificate\u0026#34;: \u0026#34;{...}\u0026#34;, // 数字证书\r\u0026#34;session_ticket_keys\u0026#34;: \u0026#34;{...}\u0026#34;,\r\u0026#34;validation_context\u0026#34;: \u0026#34;{...}\u0026#34;, // 证书验证信息\r\u0026#34;generic_secret\u0026#34;: \u0026#34;{...}\u0026#34;\r}\r其中在 Istio 中用到的主要是 tls_certificate 和 validation_context。 分别用于传递数字证书和验证对方证书使用到的根证书。下面是这两个字段的结构，结构中标注了我们主要需要关注的内容。\ntls_certificate\n{\r\u0026#34;certificate_chain\u0026#34;: \u0026#34;{...}\u0026#34;, // 证书内容\r\u0026#34;private_key\u0026#34;: \u0026#34;{...}\u0026#34;, // 证书的私钥\r\u0026#34;private_key_provider\u0026#34;: \u0026#34;{...}\u0026#34;,\r\u0026#34;password\u0026#34;: \u0026#34;{...}\u0026#34;\r}\rvalidation_context\n{\r\u0026#34;trusted_ca\u0026#34;: \u0026#34;{...}\u0026#34;, // CA 根证书\r\u0026#34;verify_certificate_spki\u0026#34;: [],\r\u0026#34;verify_certificate_hash\u0026#34;: [],\r\u0026#34;match_subject_alt_names\u0026#34;: [], // 需要验证的 subject alt name\r\u0026#34;crl\u0026#34;: \u0026#34;{...}\u0026#34;,\r\u0026#34;allow_expired_certificate\u0026#34;: \u0026#34;...\u0026#34;,\r\u0026#34;trust_chain_verification\u0026#34;: \u0026#34;...\u0026#34;\r}\r网格 Sidecar 证书配置 在 Istio 的 Enovy sidecar 配置中，有两处需要通过 SDS 来配置证书：\n Inbound Listener：由于Enovy 通过 Listener 对外提供服务，需要通过 SDS 配置服务器证书，服务器证书私钥，以及验证下游客户端证书的 CA 根证书。 Outbound Cluster：对于上游的 Cluster 而言，Envoy 是客户端的角色，因此需要在 Cluster 中通过 SDS 配置客户端证书，客户端证书私钥，以及验证上游服务器的 CA 根证书。  下面我们来看一下 bookinfo 示例中 Envoy sidecar代理上 reviews 微服务相关的证书配置，以对 Istio 中 SDS 的运作机制有一个更清晰的认识。为了简略起见，本文只显示了部分关键的配置。你也可以查看 Github 上的完整配置。\n通过 Envoy 的管理端口，可以导出 Envoy 中的当前配置，导出命令如下：\nkubectl exec reviews-v1-6d8bc58dd7-ts8kw -c istio-proxy curl http://127.0.0.1:15000/config_dump \u0026gt; config_dump\r配置文件中 SDS 服务器的定义如下，Pilot-agent 在 /etc/istio/proxy/SDS 这路径上通过 unix domain socket 提供了一个 SDS 服务器。\n{\r\u0026#34;name\u0026#34;: \u0026#34;sds-grpc\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;STATIC\u0026#34;,\r\u0026#34;connect_timeout\u0026#34;: \u0026#34;10s\u0026#34;,\r\u0026#34;hidden_envoy_deprecated_hosts\u0026#34;: [\r{\r\u0026#34;pipe\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/etc/istio/proxy/SDS\u0026#34;\r}\r}\r],\r\u0026#34;http2_protocol_options\u0026#34;: {}\r}\rDetails Pod 在 9080 端口对外提供服务，因此需要通过 SDS 配置 9080 端口上的服务端证书和验证客户端证书的 CA 根证书。\n{\r\u0026#34;name\u0026#34;: \u0026#34;virtualInbound\u0026#34;, // 15006端口上的虚拟入向监听器\r\u0026#34;active_state\u0026#34;: {\r\u0026#34;version_info\u0026#34;: \u0026#34;2020-05-14T03:59:54Z/25\u0026#34;,\r\u0026#34;listener\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.Listener\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;virtualInbound\u0026#34;,\r\u0026#34;address\u0026#34;: {\r\u0026#34;socket_address\u0026#34;: {\r\u0026#34;address\u0026#34;: \u0026#34;0.0.0.0\u0026#34;,\r\u0026#34;port_value\u0026#34;: 15006\r}\r},\r\u0026#34;filter_chains\u0026#34;: [\r{\r\u0026#34;filter_chain_match\u0026#34;: {\r\u0026#34;prefix_ranges\u0026#34;: [\r{\r\u0026#34;address_prefix\u0026#34;: \u0026#34;10.44.0.8\u0026#34;,\r\u0026#34;prefix_len\u0026#34;: 32\r}\r],\r\u0026#34;destination_port\u0026#34;: 9080 // 用于处理发向reviews服务9080端口的业务请求的filter chain\r},\r\u0026#34;filters\u0026#34;: [...],\r\u0026#34;transport_socket\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;envoy.transport_sockets.tls\u0026#34;,\r\u0026#34;typed_config\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.auth.DownstreamTlsContext\u0026#34;,\r\u0026#34;common_tls_context\u0026#34;: {\r\u0026#34;alpn_protocols\u0026#34;: [\r\u0026#34;h2\u0026#34;,\r\u0026#34;http/1.1\u0026#34;\r],\r\u0026#34;tls_certificate_sds_secret_configs\u0026#34;: [ // 配置服务器端证书\r{\r\u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;, // 服务器证书 Secret 名称\r\u0026#34;sds_config\u0026#34;: {\r\u0026#34;api_config_source\u0026#34;: {\r\u0026#34;api_type\u0026#34;: \u0026#34;GRPC\u0026#34;,\r\u0026#34;grpc_services\u0026#34;: [\r{\r\u0026#34;envoy_grpc\u0026#34;: {\r\u0026#34;cluster_name\u0026#34;: \u0026#34;sds-grpc\u0026#34; // 配置用于获取服务器端证书的 SDS 服务器\r}\r}\r]\r}\r}\r}\r],\r\u0026#34;combined_validation_context\u0026#34;: {\r\u0026#34;default_validation_context\u0026#34;: {},\r\u0026#34;validation_context_sds_secret_config\u0026#34;: { // 配置验证客户端证书的 CA 根证书\r\u0026#34;name\u0026#34;: \u0026#34;ROOTCA\u0026#34;, // CA 根证书 Secret 名称\r\u0026#34;sds_config\u0026#34;: {\r\u0026#34;api_config_source\u0026#34;: {\r\u0026#34;api_type\u0026#34;: \u0026#34;GRPC\u0026#34;,\r\u0026#34;grpc_services\u0026#34;: [\r{\r\u0026#34;envoy_grpc\u0026#34;: {\r\u0026#34;cluster_name\u0026#34;: \u0026#34;sds-grpc\u0026#34; // 配置用于获取 CA 根证书的 SDS 服务器\r}\r}\r]\r}\r}\r}\r}\r},\r\u0026#34;require_client_certificate\u0026#34;: true\r}\r}\r}\r],\r}\r}\r客户端 Pod 上的 Enovy 通过 reviews outbound cluster 访问上游 reviews 服务，因此需要在该 cluster 上配置客户端证书以及验证服务器端证书的 CA 根证书。在这里我们需要注意的是，Envoy 在验证服务器端证书时会同时验证证书中的 subject alternative name 字段。该字段中设置的是 reviews 服务 Pod 关联的 Service Account 名称。 由于 Service Account 是 Istio 中认可的一种用户账户，因此通过为 Service Account 设置不同的资源访问权限，可以进一步实现细粒度的权限控制，例如按照 URL 进行授权。\n{\r\u0026#34;version_info\u0026#34;: \u0026#34;2020-05-14T03:15:47Z/18\u0026#34;,\r\u0026#34;cluster\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.Cluster\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;outbound|9080||reviews.default.svc.cluster.local\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;EDS\u0026#34;,\r\u0026#34;eds_cluster_config\u0026#34;: {\r\u0026#34;eds_config\u0026#34;: {\r\u0026#34;ads\u0026#34;: {}\r},\r\u0026#34;service_name\u0026#34;: \u0026#34;outbound|9080||reviews.default.svc.cluster.local\u0026#34;\r},\r\u0026#34;service_name\u0026#34;: \u0026#34;outbound|9080||reviews.default.svc.cluster.local\u0026#34;\r},\r\u0026#34;circuit_breakers\u0026#34;: {...},\r\u0026#34;filters\u0026#34;: [...],\r\u0026#34;transport_socket_matches\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;tlsMode-istio\u0026#34;,\r\u0026#34;match\u0026#34;: {\r\u0026#34;tlsMode\u0026#34;: \u0026#34;istio\u0026#34;\r},\r\u0026#34;transport_socket\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;envoy.transport_sockets.tls\u0026#34;,\r\u0026#34;typed_config\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.auth.UpstreamTlsContext\u0026#34;,\r\u0026#34;common_tls_context\u0026#34;: {\r\u0026#34;alpn_protocols\u0026#34;: [\r\u0026#34;istio-peer-exchange\u0026#34;,\r\u0026#34;istio\u0026#34;\r],\r\u0026#34;tls_certificate_sds_secret_configs\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;, // 配置用于访问 reviews 服务的客户端证书\r\u0026#34;sds_config\u0026#34;: {\r\u0026#34;api_config_source\u0026#34;: {\r\u0026#34;api_type\u0026#34;: \u0026#34;GRPC\u0026#34;,\r\u0026#34;grpc_services\u0026#34;: [\r{\r\u0026#34;envoy_grpc\u0026#34;: {\r\u0026#34;cluster_name\u0026#34;: \u0026#34;sds-grpc\u0026#34; // 配置用于获取客户端证书的 SDS 服务器\r}\r}\r]\r}\r}\r}\r],\r\u0026#34;combined_validation_context\u0026#34;: {\r\u0026#34;default_validation_context\u0026#34;: {\r\u0026#34;verify_subject_alt_name\u0026#34;: [\r\u0026#34;spiffe://cluster.local/ns/default/sa/bookinfo-reviews\u0026#34; // 验证服务器证书时需要验证 SAN 中的 service account 名称\r]\r},\r\u0026#34;validation_context_sds_secret_config\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;ROOTCA\u0026#34;, // 配置验证 reviews 服务器证书的 CA 根证书\r\u0026#34;sds_config\u0026#34;: {\r\u0026#34;api_config_source\u0026#34;: {\r\u0026#34;api_type\u0026#34;: \u0026#34;GRPC\u0026#34;,\r\u0026#34;grpc_services\u0026#34;: [\r{\r\u0026#34;envoy_grpc\u0026#34;: {\r\u0026#34;cluster_name\u0026#34;: \u0026#34;sds-grpc\u0026#34; // 配置用于获取 CA 根证书的 SDS 服务器\r}\r}\r]\r}\r}\r}\r}\r},\r\u0026#34;sni\u0026#34;: \u0026#34;outbound_.9080_._.reviews.default.svc.cluster.local\u0026#34;\r}\r}\r},\r]\r},\r\u0026#34;last_updated\u0026#34;: \u0026#34;2020-05-14T03:16:33.061Z\u0026#34;\r}\r上面配置中 SAN 中的 service account 名称来自于 reviews pod 中的 service account 配置。\napiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: reviews-v1\rlabels:\rapp: reviews\rversion: v1\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: reviews\rversion: v1\rtemplate:\rmetadata:\rlabels:\rapp: reviews\rversion: v1\rspec:\rserviceAccountName: bookinfo-reviews // 设置 reviews pod 的 service account\rcontainers:\r- name: reviews\rimage: docker.io/istio/examples-bookinfo-reviews-v1:1.15.0\rimagePullPolicy: IfNotPresent\renv:\r- name: LOG_DIR\rvalue: \u0026#34;/tmp/logs\u0026#34;\rports:\r- containerPort: 9080\r...\r在导出的配置中可以看到 Envoy 通过 SDS 服务器获取到的证书（为了简略起见，省略了证书中间的部分内容）。\n{\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.admin.v3.SecretsConfigDump\u0026#34;,\r\u0026#34;dynamic_active_secrets\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;version_info\u0026#34;: \u0026#34;05-14 03:16:30.900\u0026#34;,\r\u0026#34;last_updated\u0026#34;: \u0026#34;2020-05-14T03:16:31.125Z\u0026#34;,\r\u0026#34;secret\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.Secret\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;,\r\u0026#34;tls_certificate\u0026#34;: {\r\u0026#34;certificate_chain\u0026#34;: {\r\u0026#34;inline_bytes\u0026#34;: \u0026#34;LS0tLS1CRUdJTiBDRVJUSUZJQ0FUXXXXXXXXXXXXXXUZJQ0FURS0tLS0tCg==\u0026#34; // details 服务的证书，该证书被同时用作了服务器证书和客户端证书\r},\r\u0026#34;private_key\u0026#34;: {\r\u0026#34;inline_bytes\u0026#34;: \u0026#34;W3JlZGFjdGVkXQ==\u0026#34; // detatils 服务证书对应的私钥\r}\r}\r}\r},\r{\r\u0026#34;name\u0026#34;: \u0026#34;ROOTCA\u0026#34;,\r\u0026#34;version_info\u0026#34;: \u0026#34;2020-05-14 03:16:31.300416193 +0000 UTC m=+1.537483882\u0026#34;,\r\u0026#34;last_updated\u0026#34;: \u0026#34;2020-05-14T03:16:31.343Z\u0026#34;,\r\u0026#34;secret\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.Secret\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;ROOTCA\u0026#34;,\r\u0026#34;validation_context\u0026#34;: {\r\u0026#34;trusted_ca\u0026#34;: {\r\u0026#34;inline_bytes\u0026#34;: \u0026#34;LS0tLS1CRUdJTiBDRVJUSUZJQ0XXXXXXXXXXXXXXXXXXXXJQ0FURS0tLS0tCg==\u0026#34; // 用于验证通信对方证书的 CA 根证书\r}\r}\r}\r}\r]\r}\r通过上面的配置，我们可以看到，虽然需要在 Enovy sidecar配置文件中不同的位置为 Envoy 配置服务器、客户端证书以及验证对方的 CA 根证书，但 Istio 中实际上只采用了一个服务证书和 CA 根证书。Isito 将名称为 default 的证书被同时用于 Inbound Listener 的服务器证书和 Outbound Cluster 的客户端证书，并将名称为 ROOTCA 的证书被用于验证下游客户端证书和上游服务器证书的根证书。\nGateway 证书配置 除了需要和网格内部的服务进行通信之外，Ingress Gateway 和 Egress Gateway 还需要连接到网格外部的系统。如果这些外部连接也需要采用 TLS，则 Gateway 中也要配置这些外部系统的相关证书。\nIngress Gateway 中需要如下证书相关的配置：\n 作为客户端和网格内部其他服务进行通信的客户端证书和私钥，和其他服务使用的证书类似，该证书也是由 Istio CA 颁发的。 验证网格内其他服务证书的 CA 根证书，该根证书是 Istio CA 的根证书。 作为网关向网格外部提供服务使用的服务器端证书和私钥，该证书一般是由一个权威 CA 或者第三方 CA 签发的。如果有多个 host，需要为每一个 host 分别配置配置不同的证书。 如果对外提供的服务需要双向 TLS 认证，还需要配置用于验证客户端证书的 CA 根证书。  Egress Gateway 中需要如下证书相关的配置：\n 作为服务器接受网格内部其他服务访问的服务器证书和私钥，和其他服务使用的证书类似，该证书也是由 Istio CA 颁发的。 验证网格内其他服务证书的 CA 根证书，该根证书是 Istio CA 的根证书。 作为出口网关访问外部服务时，如果该外部服务采用了 TLS，则需要配置一个验证该服务器证书的 CA 根证书来验证该服务器。该根证书一般是一个权威 CA 或者第三方 CA。 如果访问的外部服务要求双向 TLS 认证，则还需要网关配置一个该外部服务认可的客户端证书。该证书一般是由一个权威 CA 或者第三方 CA 签发的。  由于 Gateway 中配置的和外部系统相关的证书不是通过 SDS 从 Istio CA 获取的，而是采用第三方 CA 颁发的，因此到期后并不能自动更新，而需要手动进行更新。因此需要注意这些证书的有效期，在证书过期前及时重新申请证书并更新到 Gateway 配置中，以避免影响业务。\n在 Gateway 上配置第三方证书的方法是采用 Kubernetes Secret 和 Istio Gateway CRD。例如我们可以采用下面的步骤在 Ingress Gateway 上配置对外提供服务使用的服务器证书。\n首先创建一个 secret，该 secret 中包含了服务器证书和私钥：\nkubectl create -n istio-system secret tls bookinfo-credential --key=bookinfo.example.com.key --cert=bookinfo.example.com.crt\r然后通过 Gateway CRD 定义一个对外提供服务的虚拟主机，并指定使用刚才定义的 secret。\napiVersion: networking.istio.io/v1alpha3\rkind: Gateway\rmetadata:\rname: mygateway\rspec:\rselector:\ristio: ingressgateway\rservers:\r- port:\rnumber: 443\rname: https\rprotocol: HTTPS\rtls:\rmode: SIMPLE\rcredentialName: httpbin-credential # 在此处设置包含了服务器证书和私钥的 secret\r hosts:\r- bookinfo.example.com\rIstio 将此配置通过 xDS 接口下发到 Ingress Gateway Pod 中的 Envoy 上，可以在该 Envoy 的配置导出中看到 Ingress 网关对外提供的 443 端口上的证书配置（配置文件中的端口是8443，这是因为 Pod 内使用了8443端口，但对外暴露的 LoadBalancer 上的端口是443）。\n{\r\u0026#34;name\u0026#34;: \u0026#34;0.0.0.0_8443\u0026#34;,\r\u0026#34;active_state\u0026#34;: {\r\u0026#34;version_info\u0026#34;: \u0026#34;2020-05-27T07:43:51Z/21\u0026#34;,\r\u0026#34;listener\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.Listener\u0026#34;,\r\u0026#34;name\u0026#34;: \u0026#34;0.0.0.0_8443\u0026#34;,\r\u0026#34;address\u0026#34;: {\r\u0026#34;socket_address\u0026#34;: {\r\u0026#34;address\u0026#34;: \u0026#34;0.0.0.0\u0026#34;,\r\u0026#34;port_value\u0026#34;: 8443\r}\r},\r\u0026#34;filter_chains\u0026#34;: [\r{\r\u0026#34;filter_chain_match\u0026#34;: {\r\u0026#34;server_names\u0026#34;: [\r\u0026#34;bookinfo.example.com\u0026#34;\r]\r},\r\u0026#34;filters\u0026#34;: [...],\r\u0026#34;transport_socket\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;envoy.transport_sockets.tls\u0026#34;,\r\u0026#34;typed_config\u0026#34;: {\r\u0026#34;@type\u0026#34;: \u0026#34;type.googleapis.com/envoy.api.v2.auth.DownstreamTlsContext\u0026#34;,\r\u0026#34;common_tls_context\u0026#34;: {\r\u0026#34;alpn_protocols\u0026#34;: [\r\u0026#34;h2\u0026#34;,\r\u0026#34;http/1.1\u0026#34;\r],\r\u0026#34;tls_certificate_sds_secret_configs\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;bookinfo-credential\u0026#34;, // Ingress Gateway 中配置的 Kubernetes secret\r\u0026#34;sds_config\u0026#34;: {\r\u0026#34;api_config_source\u0026#34;: {\r\u0026#34;api_type\u0026#34;: \u0026#34;GRPC\u0026#34;,\r\u0026#34;grpc_services\u0026#34;: [\r{\r\u0026#34;google_grpc\u0026#34;: {\r\u0026#34;target_uri\u0026#34;: \u0026#34;unix:/var/run/ingress_gateway/sds\u0026#34;, // 从本地 unix domain socket 上的 SDS 服务器获取服务器证书\r\u0026#34;stat_prefix\u0026#34;: \u0026#34;sdsstat\u0026#34;\r}\r}\r]\r}\r}\r}\r]\r},\r\u0026#34;require_client_certificate\u0026#34;: false\r}\r}\r}\r],\r},\r}\r}\r从配置中可以看出，Ingress Gateway 使用的服务器证书也是通过 SDS 服务获取的。Pilot-agent 在路径unix:/var/run/ingress_gateway/sds 上为 Ingress Gateway 提供了一个基于 unix domain socket 的 SDS 服务。Ingress Gateway 中的 Envoy 向该 SDS 服务器请求上述配置文件中的 secret，Pilot-agent 从 Kubernetes 中查到该 同名 secret，然后转换为 SDS 消息返回给 Envoy。\n备注：\n Ingress Gateway 用于和网格内其他服务通信的服务身份证书还是由 Istio CA 颁发的，其证书获取的流程同图2。 Egress Gateway 未使用 SDS 获取用于访问外部服务的客户端证书（1.6 现状，后续也许会修改）。  图4. Ingress Gateway 证书获取流程\n数据面使用的所有证书 下图中以 bookinfo 来举例说明 Istio 在数据面使用到的所有证书。为了方便说明 Gateway 的证书配置，我们假设在 Ingress Gateway 上以 bookinfo.example.com 的主机名对外提供服务，并且 ratings 服务通过 Egress Gateway 访问了一个网格外部的第三方 TLS 服务。\n图中不同颜色边框的图标代表了不同的证书。该示例中一共使用了七个不同的证书，分别为3个服务的证书（同时用作服务器和客户端证书），Ingress Gateway 自身的客户端证书，Ingress Gateway 对外部提供服务的服务器证书，Egress Gateway 自身的服务器证书，Egress Gateway 访问外部服务使用的客户端证书。\n除了 Ingress Gateway 对外提供服务的服务器证书和 Egress Gateway 访问第三方服务的客户端证书之外，其他证书都是 Envoy 通过 SDS 服务从 Istio CA 获取的，因此都使用 Istio Root CA 证书进行验证。这两个第三方证书则需要采用第三方 CA 根证书进行验证。\n图5. Istio 数据面使用到的所有证书\n小结 微服务应用本质上是一个分布式的网络程序，在微服务应用内存在大量的服务间网络通信。在云化部署环境中，服务间的身份认证和安全通信是微服务面临的一大挑战。Istio 建立了一套以数字证书为基础的服务认证安全框架，在不修改应用的前提下提供了服务之间的身份认证和安全通信，并以身份认证为基础提供了强大的授权机制。\n参考文档  Istio Secure Gateways Istio Egress Gateways with TLS Origination  ","permalink":"https://cloudnative.to/blog/istio-certificate/","tags":["Istio"],"title":"一文带你彻底厘清 Isito 中的证书工作机制"},{"categories":["DevOps"],"contents":"这篇文章是基于 Tekton Pipeline 的最新版本v0.12.1版本。\n快速入门请参考：云原生 CICD: Tekton Pipeline 实战 ，实战是基于版本 v0.10.x。\nPipeline CRD 与核心资源的关系 $ k api-resources --api-group=tekton.dev NAME SHORTNAMES APIGROUP NAMESPACED KIND clustertasks tekton.dev false ClusterTask conditions tekton.dev true Condition pipelineresources tekton.dev true PipelineResource pipelineruns pr,prs tekton.dev true PipelineRun pipelines tekton.dev true Pipeline taskruns tr,trs tekton.dev true TaskRun tasks tekton.dev true Task Tekton Pipelines提供了上面的CRD，其中部分CRD与Kubernetes core中资源相对应\n Task =\u0026gt; Pod Task.Step =\u0026gt; Container  工作原理 (图片来自tekton.dev)\nTekton Pipeline 是基于 Knative 的实现，pod tekton-pipelines-controller 中有两个 Knative Controller的实现：PipelineRun 和 TaskRun。\nTask的执行顺序 PipelineRun Controller 的 #reconcile()方法，监控到有PipelineRun被创建。然后从PipelineSpec的 tasks 列表，构建出一个图（graph），用于描述Pipeline中 Task 间的依赖关系。依赖关系是通过runAfter和from，进而控制Task的执行顺序。与此同时，准备PipelineRun中定义的PipelineResources。\n// Node represents a Task in a pipeline. type Node struct { // Task represent the PipelineTask in Pipeline \tTask Task // Prev represent all the Previous task Nodes for the current Task \tPrev []*Node // Next represent all the Next task Nodes for the current Task \tNext []*Node } // Graph represents the Pipeline Graph type Graph struct { //Nodes represent map of PipelineTask name to Node in Pipeline Graph \tNodes map[string]*Node } func Build(tasks Tasks) (*Graph, error) { ... } PipelineRun中定义的参数（parameters）也会注入到PipelineSpec中：\npipelineSpec = resources.ApplyParameters(pipelineSpec, pr) 接下来就是调用dag#GetSchedulable()方法，获取未完成（通过Task状态判断）的 Task 列表；\nfunc GetSchedulable(g *Graph, doneTasks ...string) (map[string]struct{}, error) { ... } 为 Task A 创建TaskRun，假如Task配置了Condition。会先为 condition创建一个TaskRun，只有在 condition 的TaskRun运行成功，才会运行 A 的TaskRun；否则就跳过。\nStep的执行顺序 这一部分篇幅较长，之前的文章 控制 Pod 内容器的启动顺序 中提到过。\n这里补充一下Kubernetes Downward API的使用，Kubernetes Downward API的引入，控制着 Task 的第一个 Step 在何时执行。\nTaskRun Controller 在 reconciling 的过程中，在相应的 Pod 状态变为Running时，会将tekton.dev/ready=READY写入到 Pod 的 annotation 中，来通知第一个Step的执行。\nPod的部分内容：\nspec: containers: - args: - -wait_file - /tekton/downward/ready - -wait_file_content - -post_file - /tekton/tools/0 - -termination_path - /tekton/termination - -entrypoint - /ko-app/git-init - -- - -url - ssh://git@gitlab.nip.io:8022/addozhang/logan-pulse.git - -revision - develop - -path - /workspace/git-source command: - /tekton/tools/entrypoint volumeMounts: - mountPath: /tekton/downward name: tekton-internal-downward volumes: - downwardAPI: defaultMode: 420 items: - fieldRef: apiVersion: v1 fieldPath: metadata.annotations[\u0026#39;tekton.dev/ready\u0026#39;] path: ready name: tekton-internal-downward 对原生的排序step container进一步处理：启动命令使用entrypoint提供，并设置执行参数：\nentrypoint.go\nfunc orderContainers(entrypointImage string, steps []corev1.Container, results []v1alpha1.TaskResult) (corev1.Container, []corev1.Container, error) { initContainer := corev1.Container{ Name: \u0026#34;place-tools\u0026#34;, Image: entrypointImage, Command: []string{\u0026#34;cp\u0026#34;, \u0026#34;/ko-app/entrypoint\u0026#34;, entrypointBinary}, VolumeMounts: []corev1.VolumeMount{toolsMount}, } if len(steps) == 0 { return corev1.Container{}, nil, errors.New(\u0026#34;No steps specified\u0026#34;) } for i, s := range steps { var argsForEntrypoint []string switch i { case 0: argsForEntrypoint = []string{ // First step waits for the Downward volume file. \t\u0026#34;-wait_file\u0026#34;, filepath.Join(downwardMountPoint, downwardMountReadyFile), \u0026#34;-wait_file_content\u0026#34;, // Wait for file contents, not just an empty file. \t// Start next step. \t\u0026#34;-post_file\u0026#34;, filepath.Join(mountPoint, fmt.Sprintf(\u0026#34;%d\u0026#34;, i)), \u0026#34;-termination_path\u0026#34;, terminationPath, } default: // All other steps wait for previous file, write next file. \targsForEntrypoint = []string{ \u0026#34;-wait_file\u0026#34;, filepath.Join(mountPoint, fmt.Sprintf(\u0026#34;%d\u0026#34;, i-1)), \u0026#34;-post_file\u0026#34;, filepath.Join(mountPoint, fmt.Sprintf(\u0026#34;%d\u0026#34;, i)), \u0026#34;-termination_path\u0026#34;, terminationPath, } } ... } 自动运行的容器 这些自动运行的容器作为 pod 的initContainer会在 step 容器运行之前运行\ncredential-initializer 用于将 ServiceAccount 的相关secrets持久化到容器的文件系统中。比如 ssh 相关秘钥、config文件以及know_hosts文件；docker registry 相关的凭证则会被写入到 docker 的配置文件中。\nworking-dir-initializer 收集Task内的各个Step的workingDir配置，初始化目录结构\nplace-scripts 假如Step使用的是script配置（与command+args相对），这个容器会将脚本代码（script字段的内容）持久化到/tekton/scripts目录中。\n注：所有的脚本会自动加上#!/bin/sh\\nset -xe\\n，所以script字段里就不必写了。\nplace-tools 将entrypoint的二进制文件，复制到/tekton/tools/entrypoint.\nTask/Step间的数据传递 针对不同的数据，有多种不同的选择。比如Workspace、Result、PipelineResource。对于由于Task的执行是通过Pod来完成的，而Pod会调度到不同的节点上。因此Task间的数据传递，需要用到持久化的卷。\n而Step作为Pod中的容器来运行，\nWorkspace 工作区，可以理解为一个挂在到容器上的卷，用于文件的传递。\npersistentVolumeClaim 引用已存在persistentVolumeClaim卷（volume）。这种工作空间，可多次使用，需要先进行创建。比如 Java 项目的 maven，编译需要本地依赖库，这样可以节省每次编译都要下载依赖包的成本。\nworkspaces: - name: m2 persistentVolumeClaim: claimName: m2-pv-claim apiVersion: v1 kind: PersistentVolume metadata: name: m2-pv labels: type: local spec: storageClassName: manual capacity: storage: 10Gi accessModes: - ReadWriteMany hostPath: path: \u0026#34;/data/.m2\u0026#34; --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: m2-pv-claim spec: storageClassName: manual # volumeName: m2-pv accessModes: - ReadWriteMany resources: requests: storage: 10Gi volumeClaimTemplate 为每个PipelineRun或者TaskRun创建PersistentVolumeClaim卷（volume）的模板。比如一次构建需要从 git 仓库克隆代码，而针对不同的流水线代码仓库是不同的。这里就会用到volumeClaimTemplate，为每次构建创建一个PersistentVolumeClaim卷。（从0.12.0开始）\n生命周期同PipelineRun或者TaskRun，运行之后释放。\nworkspaces: - name: git-source volumeClaimTemplate: spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi 相较于persistantVolumeClain类型的workspace，volumeClaimTemplate不需要在每次在PipelineRun完成后清理工作区；并发情况下可能会出现问题。\nemptyDir 引用emptyDir卷，跟随Task生命周期的临时目录。适合在Task的Step间共享数据，无法在多个Task间共享。\nworkspaces: - name: temp emptyDir: {} configMap 引用一个configMap卷，将configMap卷作为工作区，有如下限制：\n 挂载的卷是只读的 需要提前创建configMap configMap的大小限制为1MB（Kubernetes的限制）  使用场景，比如使用maven编译Java项目，配置文件settings.xml可以使用configMap作为工作区\nworkspaces: - name: maven-settings configmap: name: maven-settings secret 用于引用secret卷，同configMap工作区一样，也有限制：\n 挂载的卷是只读的 需要提前创建secret secret的大小限制为1MB（Kubernetes的限制）  results results字段可以用来配置多个文件用来存储Tasks的执行结果，这些文件保存在/tekton/results目录中。\n在Pipeline中，可以通过tasks.[task-nanme].results.[result-name]注入到其他Task的参数中。\napiVersion: tekton.dev/v1beta1 kind: Task metadata: name: print-date annotations: description: | A simple task that prints the date spec: results: - name: current-date-unix-timestamp description: The current date in unix timestamp format - name: current-date-human-readable description: The current date in human readable format steps: - name: print-date-unix-timestamp image: bash:latest script: | #!/usr/bin/env bash date +%s | tee $(results.current-date-unix-timestamp.path) - name: print-date-humman-readable image: bash:latest script: | #!/usr/bin/env bash date | tee $(results.current-date-human-readable.path) --- apiVersion: tekton.dev/v1beta1 kind: PipelineRun metadata: name: pass-date spec: pipelineSpec: tasks: - name: print-date taskRef: name: print-date - name: read-date runAfter: #配置执行顺序 - print-date taskSpec: params: - name: current-date-unix-timestamp type: string - name: current-date-human-readable type: string steps: - name: read image: busybox script: | echo $(params.current-date-unix-timestamp) echo $(params.current-date-human-readable) params: - name: current-date-unix-timestamp value: $(tasks.print-date.results.current-date-unix-timestamp) # 注入参数 - name: current-date-human-readable value: $(tasks.print-date.results.current-date-human-readable) # 注入参数  执行结果：\n┌──────Logs(tekton-pipelines/pass-date-read-date-rhlf2-pod-9b2sk)[all] ────────── │ │ place-scripts stream closed ││ step-read 1590242170 │ │ step-read Sat May 23 13:56:10 UTC 2020 ││ step-read + echo 1590242170 │ │ step-read + echo Sat May 23 13:56:10 UTC 2020 │ │ place-tools stream closed │ │ step-read stream closed │ │ PipelineResource PipelineResource在最后提，因为目前只是alpha版本，何时会进入beta或者弃用目前还是未知数。有兴趣的可以看下这里：Why Aren’t PipelineResources in Beta?\n简单来说，PipelineResource可以通过其他的方式实现，而其本身也存在弊端：比如实现不透明，debug有难度；功能不够强；降低了Task的重用性等。\n比如git类型的PipelineResource，可以通过workspace和git-clone Task来实现；存储类型的，也可以通过workspace来实现。\n这也就是为什么上面介绍workspace的篇幅比较大。个人也偏向于使用workspace，灵活度高；使用workspace的Task重用性强。\n参考  云原生 CICD: Tekton Pipeline 实战 控制 Pod 内容器的启动顺序 Knative Controller Why Aren’t PipelineResources in Beta?  ","permalink":"https://cloudnative.to/blog/how-tekton-works/","tags":["Tekton","CICD"],"title":"Tekton 的工作原理"},{"categories":["Kubernetes"],"contents":"接触 Kubernetes 以来，我经常看到 Kubernetes 在不同的地方使用了证书（Certificate），在 Kubernetes 安装和组件启动参数中也需要配置大量证书相关的参数。但是 Kubernetes 的文档在解释这些证书的工作机制方面做得并不是太好。经过大量的相关阅读和分析工作后，我基本弄清楚了 Kubernetes 中证书的使用方式。在本文中，我将试图以一种比官方文档更容易理解的方式来说明 Kubernetes 证书相关的工作机制，如果你也存在这方面的疑惑，希望这篇文章对你有所帮助。\nKubernetes 组件的认证方式 首先让我们来看一下 Kubernetes 中的组件：在 Kubernetes 中包含多个以独立进程形式运行的组件，这些组件之间通过 HTTP/gRPC 相互通信，以协同完成集群中应用的部署和管理工作。\nkubernetes 组件，图片来源kubernetes.io\n从图中可以看到，Kubernetes 控制平面中包含了 etctd，kube-api-server，kube-scheduler，kube-controller-manager 等组件，这些组件会相互进行远程调用，例如 kube-api-server 会调用 etcd 接口存储数据，kube-controller-manager 会调用 kube-api-server 接口查询集群中的对象状态；同时，kube-api-server 也会和在工作节点上的 kubelet 和 kube-proxy 进行通信，以在工作节点上部署和管理应用。\n以上这些组件之间的相互调用都是通过网络进行的。在进行网络通信时，通信双方需要验证对方的身份，以避免恶意第三方伪造身份窃取信息或者对系统进行攻击。为了相互验证对方的身份，通信双方中的任何一方都需要做下面两件事情：\n 向对方提供标明自己身份的一个证书 验证对方提供的身份证书是否合法，是否伪造的？  在 Kubernetes 中使用了数字证书来提供身份证明，我们可以把数字证书简单理解为我们在日常生活中使用的“身份证”，上面标注了证书拥有者的身份信息，例如名称，所属组织机构等。为了保证证书的权威性，会采用一个通信双方都信任的 CA（证书机构，Certificate Authority）来颁发证书。这就类似于现实生活中颁发“身份证”的政府机构。数字证书中最重要的内容实际上是证书拥有者的公钥，该公钥代表了用户的身份。本文假设读者已经了解数字证书和 CA 的基本原理，如果你对此不太清楚，或者希望重新温习一下相关知识，可以先阅读一下这篇文章《数字证书原理》。\nCA （证书机构），图片来源www.trustauth.cn\n在 Kubernetes 的组件之间进行通信时，数字证书的验证是在协议层面通过 TLS 完成的，除了需要在建立通信时提供相关的证书和密钥外，在应用层面并不需要进行特殊处理。采用 TLS 进行验证有两种方式：\n 服务器单向认证：只需要服务器端提供证书，客户端通过服务器端证书验证服务的身份，但服务器并不验证客户端的身份。这种情况一般适用于对 Internet 开放的服务，例如搜索引擎网站，任何客户端都可以连接到服务器上进行访问，但客户端需要验证服务器的身份，以避免连接到伪造的恶意服务器。 双向 TLS 认证：除了客户端需要验证服务器的证书，服务器也要通过客户端证书验证客户端的身份。这种情况下服务器提供的是敏感信息，只允许特定身份的客户端访问。  在 Kubernetes 中，各个组件提供的接口中包含了集群的内部信息。如果这些接口被非法访问，将影响集群的安全，因此组件之间的通信需要采用双向 TLS 认证。即客户端和服务器端都需要验证对方的身份信息。在两个组件进行双向认证时，会涉及到下面这些证书相关的文件：\n 服务器端证书：服务器用于证明自身身份的数字证书，里面主要包含了服务器端的公钥以及服务器的身份信息。 服务器端私钥：服务器端证书中包含的公钥所对应的私钥。公钥和私钥是成对使用的，在进行 TLS 验证时，服务器使用该私钥来向客户端证明自己是服务器端证书的拥有者。 客户端证书：客户端用于证明自身身份的数字证书，里面主要包含了客户端的公钥以及客户端的身份信息。 客户端私钥：客户端证书中包含的公钥所对应的私钥，同理，客户端使用该私钥来向服务器端证明自己是客户端证书的拥有者。 服务器端 CA 根证书：签发服务器端证书的 CA 根证书，客户端使用该 CA 根证书来验证服务器端证书的合法性。 客户端端 CA 根证书：签发客户端证书的 CA 根证书，服务器端使用该 CA 根证书来验证客户端证书的合法性。  下面这张来自The magic of TLS, X509 and mutual authentication explained 文章中的图形象地解释了双向 TLS 认证的原理。如果你需要了解更多关于 TLS 认证的原理，可以阅读一下 medium 上的原文。\n图片来源The magic of TLS, X509 and mutual authentication explained\nKubernetes 中使用到的CA和证书 Kubernetes 中使用了大量的证书，本文不会试图覆盖到所有可能使用到的证书，但会讨论到主要的证书。理解了这些证书的使用方法和原理后，也能很快理解其他可能遇到的证书文件。下图标识出了在 kubernetes 中主要使用到的证书和其使用的位置：\nKubernetes 中使用到的主要证书\n上图中使用序号对证书进行了标注。图中的箭头表明了组件的调用方向，箭头所指方向为服务提供方，另一头为服务调用方。为了实现 TLS 双向认证，服务提供方需要使用一个服务器证书，服务调用方则需要提供一个客户端证书，并且双方都需要使用一个 CA 证书来验证对方提供的证书。为了简明起见，上图中只标注了证书使用方提供的证书，并没有标注证书的验证方验证使用的 CA 证书。图中标注的这些证书的作用分别如下：\n  etcd 集群中各个节点之间相互通信使用的证书。由于一个 etctd 节点既为其他节点提供服务，又需要作为客户端访问其他节点，因此该证书同时用作服务器证书和客户端证书。\n  etcd 集群向外提供服务使用的证书。该证书是服务器证书。\n  kube-apiserver 作为客户端访问 etcd 使用的证书。该证书是客户端证书。\n  kube-apiserver 对外提供服务使用的证书。该证书是服务器证书。\n  kube-controller-manager 作为客户端访问 kube-apiserver 使用的证书，该证书是客户端证书。\n  kube-scheduler 作为客户端访问 kube-apiserver 使用的证书，该证书是客户端证书。\n  kube-proxy 作为客户端访问 kube-apiserver 使用的证书，该证书是客户端证书。\n  kubelet 作为客户端访问 kube-apiserver 使用的证书，该证书是客户端证书。\n  管理员用户通过 kubectl 访问 kube-apiserver 使用的证书，该证书是客户端证书。\n  kubelet 对外提供服务使用的证书。该证书是服务器证书。\n  kube-apiserver 作为客户端访问 kubelet 采用的证书。该证书是客户端证书。\n  kube-controller-manager 用于生成和验证 service-account token 的证书。该证书并不会像其他证书一样用于身份认证，而是将证书中的公钥/私钥对用于 service account token 的生成和验证。kube-controller-manager 会用该证书的私钥来生成 service account token，然后以 secret 的方式加载到 pod 中。pod 中的应用可以使用该 token 来访问 kube-apiserver， kube-apiserver 会使用该证书中的公钥来验证请求中的 token。我们将在文中稍后部分详细介绍该证书的使用方法。\n  通过这张图，对证书机制比较了解的读者可能已经看出，我们其实可以使用多个不同的 CA 来颁发这些证书。只要在通信的组件中正确配置用于验证对方证书的 CA 根证书，就可以使用不同的 CA 来颁发不同用途的证书。但我们一般建议采用统一的 CA 来颁发 kubernetes 集群中的所有证书，这是因为采用一个集群根 CA 的方式比采用多个 CA 的方式更容易管理，可以避免多个CA 导致的复杂的证书配置、更新等问题，减少由于证书配置错误导致的集群故障。\nKubernetes 中的证书配置 前面我们介绍了 Kubernetes 集群中主要使用到的证书。下面我们分别看一下如何将这些证书及其对应的私钥和 CA 根证书需要配置到 Kubernetes 中各个组件中，以供各个组件进行使用。这里假设使用一个集群根 CA 来颁发所有相关证书，因此涉及到 CA 的配置对应的证书文件名都是相同的。\netcd 证书配置 需要在 etcd 的启动命令行中配置以下证书相关参数：\n etcd 对外提供服务的服务器证书及私钥。 etcd 节点之间相互进行认证的 peer 证书、私钥以及验证 peer 的 CA。 etcd 验证访问其服务的客户端的 CA。  /usr/local/bin/etcd \\\\\r--cert-file=/etc/etcd/kube-etcd.pem \\\\ # 对外提供服务的服务器证书\r--key-file=/etc/etcd/kube-etcd-key.pem \\\\ # 服务器证书对应的私钥\r--peer-cert-file=/etc/etcd/kube-etcd-peer.pem \\\\ # peer 证书，用于 etcd 节点之间的相互访问\r--peer-key-file=/etc/etcd/kube-etcd-peer-key.pem \\\\ # peer 证书对应的私钥\r--trusted-ca-file=/etc/etcd/cluster-root-ca.pem \\\\ # 用于验证访问 etcd 服务器的客户端证书的 CA 根证书\r--peer-trusted-ca-file=/etc/etcd/cluster-root-ca.pem\\\\ # 用于验证 peer 证书的 CA 根证书\r...\rkube-apiserver 证书配置 需要在 kube-apiserver 中配置以下证书相关参数：\n kube-apiserver 对外提供服务的服务器证书及私钥。 kube-apiserver 访问 etcd 所需的客户端证书及私钥。 kube-apiserver 访问 kubelet 所需的客户端证书及私钥。 验证访问其服务的客户端的 CA。 验证 etcd 服务器证书的 CA 根证书。 验证 service account token 的公钥。  /usr/local/bin/kube-apiserver \\\\ --tls-cert-file=/var/lib/kubernetes/kube-apiserver.pem \\\\ # 用于对外提供服务的服务器证书\r--tls-private-key-file=/var/lib/kubernetes/kube-apiserver-key.pem \\\\ # 服务器证书对应的私钥\r--etcd-certfile=/var/lib/kubernetes/kube-apiserver-etcd-client.pem \\\\ # 用于访问 etcd 的客户端证书\r--etcd-keyfile=/var/lib/kubernetes/kube-apiserver-etcd-client-key.pem \\\\ # 用于访问 etcd 的客户端证书的私钥\r--kubelet-client-certificate=/var/lib/kubernetes/kube-apiserver-kubelet-client.pem \\\\ # 用于访问 kubelet 的客户端证书\r--kubelet-client-key=/var/lib/kubernetes/kube-apiserver-kubelet-client-key.pem \\\\ # 用于访问 kubelet 的客户端证书的私钥\r--client-ca-file=/var/lib/kubernetes/cluster-root-ca.pem \\\\ # 用于验证访问 kube-apiserver 的客户端的证书的 CA 根证书\r--etcd-cafile=/var/lib/kubernetes/cluster-root-ca.pem \\\\ # 用于验证 etcd 服务器证书的 CA 根证书 --kubelet-certificate-authority=/var/lib/kubernetes/cluster-root-ca.pem \\\\ # 用于验证 kubelet 服务器证书的 CA 根证书\r--service-account-key-file=/var/lib/kubernetes/service-account.pem \\\\ # 用于验证 service account token 的公钥\r...\r采用 kubeconfig 访问 kube-apiserver Kubernetes 中的各个组件，包括kube-controller-mananger、kube-scheduler、kube-proxy、kubelet等，采用一个kubeconfig 文件中配置的信息来访问 kube-apiserver。该文件中包含了 kube-apiserver 的地址，验证 kube-apiserver 服务器证书的 CA 证书，自己的客户端证书和私钥等访问信息。\n在一个使用 minikube 安装的集群中，生成的 kubeconfig 配置文件如下所示，这四个文件分别为 admin 用户， kube-controller-mananger、kubelet 和 kube-scheduler 的kubeconfig配置文件。\n$ ls /etc/kubernetes/\radmin.conf controller-manager.conf kubelet.conf scheduler.conf\r我们打开 controller-manager.conf 来看一下，为了节约篇幅，这里没有写出证书和私钥的完整内容。\napiVersion: v1\rclusters:\r- cluster: # 用于验证 kube-apiserver 服务器证书的 CA 根证书  certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX0tLS0tCg==\rserver: https://localhost:8443\rname: kubernetes\rcontexts:\r- context:\rcluster: kubernetes\ruser: system:kube-controller-manager\rname: system:kube-controller-manager@kubernetes\rcurrent-context: system:kube-controller-manager@kubernetes\rkind: Config\rpreferences: {}\rusers:\r- name: system:kube-controller-manager\ruser:\r# 用于访问 kube-apiserver 的客户端证书\r client-certificate-data: LS0tLS1CRUdJTiXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXQ0FURS0tLS0tCg==\r# 客户端证书对应的私钥\r client-key-data: LS0tLS1CRUdXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXtFWS0tLS0tCg==\r可以看到，访问 kube-apiserver 所需要的相关证书内容已经被采用 base64 编码写入了文件中。其他几个文件中的内容也是类似的，只是配置的用户名和客户端证书有所不同。\n在启动这些组件时，需要在参数中指出 kubeconfig 文件的路径，例如 kube-controller-manager 的启动命令如下。\n/usr/local/bin/kube-controller-manager \\\\\r--kubeconfig=/etc/kubernetes/controller-manager.conf # 下面几个证书和访问 kube-apiserver 无关，我们会在后面介绍到\r--cluster-signing-cert-file=/var/lib/kubernetes/cluster-root-ca.pem # 用于签发证书的 CA 根证书\r--cluster-signing-key-file=/var/lib/kubernetes/cluster-root-ca-key.pem # 用于签发证书的 CA 根证书的私钥 --service-account-private-key-file=/var/lib/kubernetes/service-account-key.pem # 用于对 service account token 进行签名的私钥\r... Service Account 证书 Kubernetes 中有两类用户，一类为 user account，一类为 service account。 service account 主要被 pod 用于访问 kube-apiserver。 在为一个 pod 指定了 service account 后，kubernetes 会为该 service account 生成一个 JWT token，并使用 secret 将该 service account token 加载到 pod 上。pod 中的应用可以使用 service account token 来访问 api server。service account 证书被用于生成和验证 service account token。该证书的用法和前面介绍的其他证书不同，因为实际上使用的是其公钥和私钥，而并不需要对证书进行验证。\n我们可以看到 service account 证书的公钥和私钥分别被配置到了 kube-apiserver 和 kube-controller-manager 的命令行参数中，如下所示：\n/usr/local/bin/kube-apiserver \\\\ --service-account-key-file=/var/lib/kubernetes/service-account.pem \\\\ # 用于验证 service account token 的公钥\r...\r/usr/local/bin/kube-controller-manager \\\\\r--service-account-private-key-file=/var/lib/kubernetes/service-account-key.pem # 用于对 service account token 进行签名的私钥\r... 下图展示了 kubernetes 中生成、使用和验证 service account token 的过程。\n认证方法：客户端证书还是 token ？ 我们可以看到，Kubernetes 提供了两种客户端认证的方法，控制面组件采用的是客户端数字证书;而在集群中部署的应用则采用了 service account token 的方式。为什么 Kubernetes 不为 service account 也生成一个证书，并采用该证书进行身份认证呢？ 实际上 Istio 就是这样做的，Istio 会自动为每个 service account 生成一个证书，并使用该证书来在 pod 中的应用之间建立双向 tls 认证。我没有找到 Kubernetes 这个设计决策的相关说明，如果你知道原因或对此有自己的见解，欢迎联系我进行探讨。\nKubernetes 证书签发 Kubernetes 提供了一个 certificates.k8s.io API，可以使用配置的 CA 根证书来签发用户证书。该 API 由 kube-controller-manager 实现，其签发证书使用的根证书在下面的命令行中进行配置。我们希望 Kubernetes 采用集群根 CA 来签发用户证书，因此在 kube-controller-manager 的命令行参数中将相关参数配置为了集群根 CA。\n/usr/local/bin/kube-controller-manager \\\\\r--cluster-signing-cert-file=/var/lib/kubernetes/cluster-root-ca.pem # 用于签发证书的 CA 根证书\r--cluster-signing-key-file=/var/lib/kubernetes/cluster-root-ca-key.pem # 用于签发证书的 CA 根证书的私钥 ... 关于更多 Kubernetes 证书签发 API 的内容，可以参见 管理集群中的 TLS 认证。\n使用 TLS bootstrapping 简化 Kubelet 证书制作 在安装 Kubernetes 时，我们需要为每一个工作节点上的 Kubelet 分别生成一个证书。由于工作节点可能很多，手动生成 Kubelet 证书的过程会比较繁琐。为了解决这个问题，Kubernetes 提供了 TLS bootstrapping  的方式来简化 Kubelet 证书的生成过程。其原理是预先提供一个 bootstrapping token，kubelet 通过该 kubelet 调用 kube-apiserver 的证书签发 API 来生成 自己需要的证书。要启用该功能，需要在 kube-apiserver 中启用 --enable-bootstrap-token-auth ，并创建一个 kubelet 访问 kube-apiserver 使用的 bootstrap token secret。如果使用 kubeadmin 安装，可以使用 kubeadm token create命令来创建 token。\n采用TLS bootstrapping 生成证书的流程如下：\n 调用 kube-apiserver 生成一个 bootstrap token。 将该 bootstrap token 写入到一个 kubeconfig 文件中，作为 kubelet 调用 kube-apiserver 的客户端验证方式。 通过 --bootstrap-kubeconfig 启动参数将 bootstrap token 传递给 kubelet 进程。 Kubelet 采用bootstrap token 调用 kube-apiserver API，生成自己所需的服务器和客户端证书。 证书生成后，Kubelet 采用生成的证书和 kube-apiserver 进行通信，并删除本地的 kubeconfig 文件，以避免 bootstrap token 泄漏风险。  小结 Kubernetes 中使用了大量的证书来确保集群的安全，弄清楚这些证书的用途和配置方法将有助于我们深入理解 kubernetes 的安装过程和组件的配置。本文是笔者在学习 过程中整理的 Kubernetes 集群中主要使用到的证书，由于笔者对 Kubernetes 的理解有限，文章中难免存在部分错误，欢迎指正。\n参考文档  Kubernetes PKI 证书和要求 kubernetes the hard way Kubernetes 之 二进制安装(二) 证书详解 TLS bootstrapping 数字证书原理  ","permalink":"https://cloudnative.to/blog/k8s-certificate/","tags":["Kubernetes"],"title":"一文带你彻底厘清 Kubernetes 中的证书工作机制"},{"categories":["Service Mesh"],"contents":"前言 Service Mesh 在企业落地中有诸多挑战，当与传统微服务应用共同部署治理时可用性挑战更为严峻。本文将以 Service Mesh 与 Spring Cloud 应用互联互通共同治理为前提，着重介绍基于 Consul 的注册中心高可用方案，通过各种限流、熔断策略保证后端服务的高可用，以及通过智能路由策略（负载均衡、实例容错等）实现服务间调用的高可用。\nService Mesh 与 Spring Cloud 应用的互通、互联 微服务是时下技术热点，大量互联网公司都在做微服务架构的推广和落地。同时，也有很多传统企业基于微服务和容器，在做互联网技术转型。而在这个技术转型中，国内有一个现象，以 Spring Cloud 与 Dubbo 为代表的微服务开发框架非常普及和受欢迎。近年来， 新兴的 Service Mesh 技术也越来越火热，受到越来越多开发者的关注，大有后来居上的趋势。\n在听到社区里很多人谈到微服务技术选型时，注意到他们讨论一个非此即彼的问题：采用 Spring Cloud 还是以 Istio 为代表的 Service Mesh 技术？然而这个答案并非非黑即白、非你即我，一部分应用采用 Spring Cloud，另一部分采用 Service Mesh（Istio）是完全可能的。今天我就和大家一起来讨论这个问题。\n首先，我们来看一下 Spring Cloud 这个传统侵入式微服务框架。它包含以下优点：\n 集大成者，Spring Cloud 包含了微服务架构的方方面面；选用目前各家公司开发的比较成熟的、经得住实践考验的服务框架； 轻量级组件，Spring Cloud 整合的组件大多比较轻量级，且都是各自领域的佼佼者； 开发简便，Spring Cloud 对各个组件进行了大量的封装，从而简化了开发； 开发灵活，Spring Cloud 的组件都是解耦的，开发人员可以灵活按需选择组件。  特别感谢 Netflix ，这家很早就成功实践微服务的公司，几年前把自家几乎整个微服务框架栈贡献给了社区，早期的 Spring Cloud 主要是对 Netflix 开源组件的进一步封装。不过近两年，Spring Cloud 社区开始自研了很多新的组件，也接入了其他一些互联网公司的优秀实践。\n接下来，我们简单看一下 Service Mesh 框架。它带来了两大变革：微服务治理与业务逻辑的解耦，异构系统的统一治理。此外，服务网格相对于传统微服务框架，还拥有三大技术优势：可观察性、流量控制、安全。服务网格带来了巨大变革并且拥有其强大的技术优势，被称为第二代“微服务架构”。\n然而就像之前说的软件开发没有银弹，传统微服务架构有许多痛点，而服务网格也不例外，也有它的局限性。这些局限性包括：增加了链路与运维的复杂度、需要更专业的运维技能、带来了一定的延迟以及对平台的适配。\n更多关于 Spring Cloud 与 Service Mesh 的优缺点与比较，请阅读 Istio-Handbook [Service Mesh 概述]。\n前面提到过，对于传统微服务框架 Spring Cloud 与新兴微服务框架 Service Mesh，并非是个非黑即白，非你即我，延伸到微服务与单体架构，它们也是可以共存的。\n也可以将其与混合云相类比，混合云中包含了公有云、私有云，可能还有其它的自有基础设施。目前来看，混合云是一种流行的实践方式；实际上，可能很难找到一个完全单一云模式的组织。对多数组织来说，将一个单体应用完全重构为微服务的过程中，对开发资源的调动是一个很严峻的问题；采用混合微服务策略是一个较好的方式，对开发团队来说，这种方式让微服务架构触手可及；否则的话，开发团队可能会因为时间、经验等方面的欠缺，无法接受对单体应用的重构工作。\n构建混合微服务架构的最佳实践：\n 最大化收益的部分优先重构； 非 Java 应用优先采用 Service Mesh 框架。  混合微服务出现的原因是为了更好的支持平滑迁移，最大限度的提升服务治理水平，降低运维通信成本等，并且可能会在一个较长的周期存在着。而实现这一架构的前提，就是各服务的“互联互通”。\n要想实现上述“混合微服务架构”，运行时支撑服务必不可少，它主要包括服务注册中心、服务网关和集中式配置中心三个产品。\n传统微服务和 Service Mesh 双剑合璧（双模微服务），即“基于 SDK 的传统微服务”可以和“基于 Sidecar 的 Service Mesh 微服务”实现下列目标：\n 互联互通：两个体系中的应用可以相互访问； 平滑迁移：应用可以在两个体系中迁移，对于调用该应用的其他应用，做到透明无感知； 灵活演进：在互联互通和平滑迁移实现之后，我们就可以根据实际情况进行灵活的应用改造和架构演进。  这里还包括对应用运行平台的要求，即两个体系下的应用，既可以运行在虚拟机之上，也可以运行在容器 /K8s 之上。我们不希望把用户绑定在 K8s 上，因此 Service Mesh 没有采用 K8s 的 Service 机制来做服务注册与发现，这里就突出了注册中心的重要性。\n百度智能云 CNAP 团队实现了上述混合微服务架构，即实现了两个微服务体系的应用互联互通、平滑迁移、灵活演进。上述混合微服务架构图包括以下几个组件：\n API Server：前后端解耦，接口权限控制、请求转发、异常本地化处理等等； 微服务控制中心：微服务治理的主要逻辑，包括服务注册的多租户处理、治理规则（路由、限流、熔断）的创建和转换、微服务配置的管理； 监控数据存储、消息队列：主要是基于 Trace 的监控方案使用的组件； 配置中心：微服务配置中心，最主要的功能是支持配置管理，包括治理规则、用户配置等所有微服务配置的存储和下发，微服务配置中心的特色是借助 SDK 可以实现配置/规则热更新。  接下来主要看一下注册中心的服务注册和发现机制：\n Spring Cloud 应用通过 SDK、Service Mesh 应用实现 Sidecar 分别向注册中心注册，注册的请求先通过微服务控制中心进行认证处理与多租户隔离； Mesh 控制面直接对接注册中心获取服务实例、Spring Cloud 应用通过 SDK 获取服务实例； 双模异构，支持容器与虚机两种模型。  注册中心与高可用方案 前面提到过，要想实现实现混合微服务架构，注册中心很关键。谈到注册中心，目前主流的开源注册中心包括：\n Zookeeper：Yahoo 公司开发的分布式协调系统，可用于注册中心，目前仍有很多公司使用其作为注册中心； Eureka：Netflix 开源组件，可用于服务注册发现组件，被广大 Spring Cloud 开发者熟知，遗憾的是目前已经不再维护，也不再被 Spring Cloud 生态推荐使用； Consul： HashiCorp 公司推出的产品，其可作为实现注册中心，也是本文介绍的重点； Etcd：Etcd 官方将其定义为可靠的分布式 KV 存储。  我们注册中心选择了 Consul，Consul 包含了以下几个重要的功能：\n 服务发现：可以注册服务，也可以通过 Http 或 DNS 的方式发现已经注册的服务； 丰富的健康检查机制； 服务网格能力，最新版本已经支持 Envoy 作为数据面； KV 存储：可以基于 Consul KV 存储实现一个分布式配置中心； 多数据中心：借助多数据中心，无需使用额外的抽象层，即可构建多地域的场景，支持多 DC 数据同步、异地容灾。  上图是 Consul 官网提供的架构图。Consul 架构中几个核心的概念如下：\n Agent: Agent 是运行在 Consul 集群的每个节点上的 Daemon 进程，通过 Consul Agent 命令将其启动，Agent 可以运行在 Client 或者 Server 模式下； Client：Client 是一种 Agent，其将会重定向所有的 RPC 请求到 Server，Client 是无状态的，其主要参与 LAN Gossip 协议池，其占用很少的资源，并且消耗很少的网络带宽； Server：Server 是一种 Agent，其包含了一系列的责任包括：参与 Raft 协议写半数（Raft Quorum）、维护集群状态、响应 RPC 响应、和其他 Datacenter 通过 WAN gossip 交换信息和重定向查询请求至 Leader 或者远端 Datacenter； Datacenter: Datacenter 其是私有的、低延迟、高带宽的网络环境，去除了在公共网络上的网络交互。  注册中心作为基础组件，其自身的可用性显得尤为重要，高可用的设计需要对其进行分布式部署，同时因在分布式环境下的复杂性，节点因各种原因都有可能发生故障，因此在分布式集群部署中，希望在部分节点故障时，集群依然能够正常对外服务。注册中心作为微服务基础设施，因此对其容灾和其健壮性有一定的要求，主要体现在：\n 注册中心作为微服务基础设施，因此要求出现某些故障（如节点挂掉、网络分区）后注册中心仍然能够正常运行； 当注册中心的发生故障时，不能影响服务间的正常调用。  Consul 使用 Raft 协议作为其分布式一致性协议，本身对故障节点有一定的容忍性，在单个 DataCenter中 Consul 集群中节点的数量控制在 2*n + 1 个节点，其中 n 为可容忍的宕机个数。Quorum size: Raft 协议选举需要半数以上节点写入成功。\nQ1: 节点的个数是否可以为偶数个？\nA2：答案是可以的，但是不建议部署偶数个节点。一方面如上表中偶数节点4和奇数节点3可容忍的故障数是一样的，另一方面，偶数个节点在选主节点的时候可能会出现瓜分选票的情形（虽然 Consul 通过重置 election timeout 来重新选举），所以还是建议选取奇数个节点。\nQ2: 是不是 Server 节点个数越多越好？\nA2：答案是否定的，虽然上表中显示 Server 数量越多可容忍的故障数越多，熟悉 Raft 协议的读者肯定熟悉 Log Replication（ 如上文介绍，日志复制时过半写成功才返回写成功），随着 Server 的数量越来越多，性能就会越低，所以结合实际场景一般建议 Server 部署3个节点。\n推荐采用三节点或五节点，最为有效，且能容错。\n注册中心设计的一个重要前提是：注册中心不能因为自身的原因或故障影响服务之间的相互调用。因此在实践过程中，如果注册中心本身发生了宕机故障/不可用，绝对不能影响服务之间的调用。这要求对接注册中心的 SDK 针对这种特殊情况进行客户端容灾设计，『客户端缓存』就是一种行之有效的手段。当注册中心发生故障无法提供服务时，服务本身并不会更新本地客户端缓存，利用其已经缓存的服务列表信息，正常完成服务间调用。\n我们在设计时采用同 Datacenter 集群内部部署3个 Server 节点，来保障高可用性，当集群中1个节点发生故障后，集群仍然能够正常运行，同时这3个节点部署在不同的机房，达到机房容灾的能力。\n在云上环境，涉及多 region 环境，因此在架构设计设计时，我们首先将 Consul 的一个 Datacenter 对应云上一个 region，这样更符合 Consul 对于 Datecenter 的定义（DataCenter 数据中心是私有性、低延迟、高带宽的网络环境）。中间代理层实现了服务鉴权、多租户隔离等功能；还可以通过中间代理层，对接多注册中心。\n云上环境存在多租户隔离的需求，即：A租户的服务只能发现A租户服务的实例。针对此场景，需要在 『中间代理层』完成对多租户隔离功能的实现，其主要实践思路为使用 Consul Api Feature 具备 Filtering 功能：\n 利用 Filtering 功能实现租户隔离需求； 减少查询注册中心接口时网络负载。  通过治理策略保证服务高可用 什么是高可用？维基百科这么定义：系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。我们通常用 N 个9来定义系统的可用性，如果能达到4个9，则说明系统具备自动恢复能力；如果能达到5个9，则说明系统极其健壮，具有极高可用性，而能达到这个指标则是非常难的。\n常见的系统不可用因素包括：程序和配置出 bug、机器故障、机房故障、容量不足、依赖服务出现响应超时等。高可用的抓手包括：研发质量、测试质量、变更管理、监控告警、故障预案、容量规划、放火盲测、值班巡检等。这里，将主要介绍通过借助治理策略采用高可用设计手段来保障高可用。\n高可用是一个比较复杂的命题，所以设计高可用方案也涉及到了方方面面。这中间将会出现的细节是多种多样的，所以我们需要对这样一个微服务高可用方案进行一个顶层的设计。\n比如服务冗余：\n 冗余策略：每个机器每个服务都可能出现问题，所以第一个考虑到的就是每个服务必须不止一份，而是多份。所谓多份一致的服务就是服务的冗余，这里说的服务泛指了机器的服务、容器的服务、还有微服务本身的服务。在机器服务层面需要考虑，各个机器间的冗余是否有在物理空间进行隔离冗余。 无状态化：我们可以随时对服务进行扩容或者缩容，想要对服务进行随时随地的扩缩容，就要求我们的服务是一个无状态化，所谓无状态化就是每个服务的服务内容和数据都是一致的。  比如柔性化/异步化：\n 所谓的柔性化，就是在我们业务允许的情况下，做不到给予用户百分百可用的，通过降级的手段给到用户尽可能多的服务，而不是非得每次都交出去要么 100 分或 0 分的答卷。柔性化更多是一种思维，需要对业务场景有深入的了解。 异步化：在每一次调用，时间越长存在超时的风险就越大，逻辑越复杂执行的步骤越多，存在失败的风险也就越大。如果在业务允许的情况下，用户调用只给用户必须要的结果，不是需要同步的结果可以放在另外的地方异步去操作，这就减少了超时的风险也把复杂业务进行拆分减低复杂度。  上面讲到的几种提高服务高可用的手段，大多需要从业务以及部署运维的角度实现。而接下来会重点介绍，可以通过 SDK/Sidecar 手段提供服务高可用的治理策略，这些策略往往对业务是非侵入或者弱侵入的，能够让绝大多数服务轻松实现服务高可用。\n微服务之间一旦建立起路由，就意味着会有数据在服务之间流通。由于不同服务可以提供的资源和对数据流量的承载能力不尽相同，为了防止单个 Consumer 占用 Provider 过多的资源，或者突发的大流量冲击导致 Provider 故障，需要服务限流来保证服务的高可用。\n在服务治理中，虽然我们可以通过限流规则尽量避免服务承受过高的流量，但是在实际生产中服务故障依然难以完全避免。当整个系统中某些服务产生故障时，如果不及时采取措施，这种故障就有可能因为服务之间的互相访问而被传播开来，最终导致故障规模的扩大，甚至导致整个系统奔溃，这种现象我们称之为“雪崩”。熔断降级其实不只是服务治理中，在金融行业也有很广泛的应用。比如当股指的波动幅度超过规定的熔断点时，交易所为了控制风险采取的暂停交易措施。\n负载均衡是高可用架构的一个关键组件，主要用来提高性能和可用性，通过负载均衡将流量分发到多个服务器，同时多服务器能够消除这部分的单点故障。\n以上治理规则在某种程度上可以在 Spring Cloud 与 Service Mesh 两个框架上进行对齐，即同一套治理配置，可以通过转换分发到 Spring Cloud 应用的 SDK 上以及 Service Mesh 的 Sidecar 上。可以由 Config-server 负责规则下发，也可以由 Service Mesh 的控制面负责下发，取决于具体的架构方案。\n服务限流 对于一个应用系统来说一定会有极限并发/请求数，即总有一个 TPS/QPS 阀值，如果超了阀值则系统就会不响应用户请求或响应的非常慢，因此我们最好进行过载保护，防止大量请求涌入击垮系统。限流的目的是通过对并发访问/请求进行限速或者一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务或进行流量整形。\n常用的微服务限流架构包括：\n 接入层（api-gateway）限流：  单实例； 多实例：分布式限流算法；   调用外部限流服务限流：  微服务收到请求后，通过限流服务暴露的 RPC 接口查询是否超过阈值； 需单独部署限流服务；   切面层限流（SDK）：  限流功能集成在微服务系统切面层，与业务解耦； 可结合远程配置中心使用；    常用的限流策略包括：\n 拒绝策略：  超过阈值直接返回错误； 调用方可做熔断降级处理。   延迟处理：  前端设置一个流量缓冲池，将所有的请求全部缓冲进这个池子，不立即处理。然后后端真正的业务处理程序从这个池子中取出请求依次处理，常见的可以用队列模式来实现（MQ：削峰填谷）； 用异步的方式去减少了后端的处理压力。   特权处理：  这个模式需要将用户进行分类，通过预设的分类，让系统优先处理需要高保障的用户群体，其它用户群的请求就会延迟处理或者直接不处理。    常用的限流算法包括：\n  固定时间窗口限流：\n 首先需要选定一个时间起点，之后每次接口请求到来都累加计数器，如果在当前时间窗口内，根据限流规则（比如每秒钟最大允许 100 次接口请求），累加访问次数超过限流值，则限流熔断拒绝接口请求。当进入下一个时间窗口之后，计数器清零重新计数； 缺点在于：限流策略过于粗略，无法应对两个时间窗口临界时间内的突发流量。    滑动时间窗口算法：\n 流量经过滑动时间窗口算法整形之后，可以保证任意时间窗口内，都不会超过最大允许的限流值，从流量曲线上来看会更加平滑，可以部分解决上面提到的临界突发流量问题，是对固定时间窗口算法的一种改进； 缺点在于：需要记录在时间窗口内每个接口请求到达的时间点，对内存的占用会比较多。    令牌桶算法：\n 接口限制 t 秒内最大访问次数为 n，则每隔 t/n 秒会放一个 token 到桶中； 桶中最多可以存放 b 个 token，如果 token 到达时令牌桶已经满了，那么这个 token 会被丢弃； 接口请求会先从令牌桶中取 token，拿到 token 则处理接口请求，拿不到 token 就阻塞或者拒绝服务。    漏桶算法：\n 对于取令牌的频率也有限制，要按照 t/n 固定的速度来取令牌； 实现往往依赖于队列，请求到达如果队列未满则直接放入队列，然后有一个处理器按照固定频率从队列头取出请求进行处理。如果请求量大，则会导致队列满，那么新来的请求就会被抛弃； 令牌桶和漏桶算法的算法思想大体类似，漏桶算法作为令牌桶限流算法的改进版本。    令牌桶算法和漏桶算法，在某些场景下（内存消耗、应对突发流量），这两种算法会优于时间窗口算法成为首选。\n熔断 断路器模式是微服务架构中广泛采用的模式之一，旨在将故障的影响降到最低，防止级联故障和雪崩，并确保端到端性能。我们将比较使用两种不同方法实现它的优缺点: Hystrix 和 Istio。\n在电路领域中，断路器是为保护电路而设计的一种自动操作的电气开关。它的基本功能是在检测到故障后中断电流，然后可以重置(手动或自动)，以在故障解决后恢复正常操作。这看起来与我们的问题非常相似：为了保护应用程序不受过多请求的影响，最好在后端检测到重复出现的错误时立即中断前端和后端之间的通信。Michael Nygard 在他的《Release It》一书中使用了这个类比，并为应用于上述超时问题的设计模式提供了一个典型案例，可以用上图来总结。\nIstio 通过 DestinationRule 实现断路器模式，或者更具体的路径 TrafficPolicy (原断路器) -\u0026gt; OutlierDetection，根据上图模型：\n consecutiveErrors 断路器打开前的出错次数； interval 断路器检查分析的时间间隔； baseEjectionTime 最小的开放时间，该电路将保持一段时间等于最小弹射持续时间和电路已打开的次数的乘积； maxEjectionPercent 可以弹出的上游服务的负载平衡池中主机的最大百分比，如果驱逐的主机数量超过阈值，则主机不会被驱逐。  与上述公称断路器相比，有两个主要偏差:\n 没有半开放的状态。然而，断路器持续打开的时间取决于被调用服务之前失败的次数，持续的故障服务将导致断路器的开路时间越来越长。 在基本模式中，只有一个被调用的应用程序(后端)。在更实际的生产环境中，负载均衡器后面可能部署同一个应用程序的多个实例。某些情况下有些实例可能会失败，而有些实例可能会工作。因为 Istio 也有负载均衡器的功能，能够追踪失败的实例，并把它们从负载均衡池中移除，在一定程度上: ‘maxEjectionPercent’ 属性的作用是保持一小部分的实例池。  Hystrix 提供了一个断路器实现，允许在电路打开时执行 fallback 机制。最关键的地方就在 HystrixCommand 的方法 run() 和 getFallback()：\n run() 是要实际执行的代码 e.g. 从报价服务中获取价格； getFallback() 获取当断路器打开时的 fallback 结果 e.g. 返回缓存的价格。  Spring Cloud 是建立在 Spring Boot 之上的框架，它提供了与 Spring 的良好集成。它让开发者在处理 Hystrix 命令对象的实例化时，只需注释所需的 fallback 方法。\n实现断路器的方法有两种，一种是黑盒方式，另一种是白盒方式。Istio 作为一种代理管理工具，使用了黑盒方式，它实现起来很简单，不依赖于底层技术栈，而且可以在事后配置。另一方面，Hystrix 库使用白盒方式，它允许所有不同类型的 fallback:\n 单个默认值； 一个缓存； 调用其他服务。  它还提供了级联回退（cascading fallbacks）。这些额外的特性是有代价的：它需要在开发阶段就做出fallback 的决策。\n这两种方法之间的最佳匹配可能会依靠自己的上下文: 在某些情况下，如引用的服务，一个白盒战略后备可能是一个更好的选择，而对于其他情况下快速失败可能是完全可以接受的，如一个集中的远程登录服务。\n常用的熔断方法包括自动熔断与手动熔断。发生熔断时也可以选择 fail-fast 或者 fallback。这些用户都可以基于需求灵活使用。\n智能路由 最后，我们来看一下智能路由带来的高可用。智能路由这里包括（客户端）负载均衡与实例容错策略。对于 Spring Cloud 框架来说，这部分能力由 Ribbon 来提供，Ribbon 支持随机、轮询、响应时间权重等负载均衡算法。而对于 Service Mesh 框架，这部分能力由 Envoy 提供，Envoy 支持随机、轮询（加权）、环哈希等算法。为了实现两套系统的规则统一对齐，可以采用其交集。\n而容错策略包括：\n failover：失败后自动切换其他服务器，支持配置重试次数； failfast：失败立即报错，不再重试； failresnd：将失败请求放入缓存队列、异步处理，搭配 failover 使用。  Istio 支持重试策略配置，而 fail-fast 即对应与重试次数为0。\n总结 微服务的高可用是一个复杂的问题，往往需要从多个角度去看，包括：\n 从手段看高可用。主要使用的技术手段是服务和数据的冗余备份和失效转移，一组服务或一组数据都能在多节点上，之间相互备份。当一台机器宕机或出现问题的时候，可以从当前的服务切换到其他可用的服务，不影响系统的可用性，也不会导致数据丢失。 从架构看高可用。保持简单的架构，目前多数网站采用的是比较经典的分层架构，应用层、服务层、数据层。应用层是处理一些业务逻辑，服务层提供一些数据和业务紧密相关服务，数据层负责对数据进行读写。简单的架构可以使应用层，服务层可以保持无状态化进行水平扩展，这个属于计算高可用。同时在做架构设计的时候，也应该考虑 CAP 理论。 从硬件看高可用。首先得确认硬件总是可能坏的，网络总是不稳定的。解决它的方法也是一个服务器不够就来多几个，一个机柜不够就来几个，一个机房不够就来几个。 从软件看高可用。软件的开发不严谨，发布不规范也是导致各种不可用出现，通过控制软件开发过程质量监控，通过测试，预发布，灰度发布等手段也是减少不可用的措施。 从治理看高可用。将服务规范化，事前做好服务分割，做好服务监控，预判不可用的出现，在不可用出现之前发现问题，解决问题。比如在服务上线后，根据经验，配置服务限流规则以及自动熔断规则。  参考资料  Service Mesh 概述 Consul 作为注册中心在云环境的实践与应用 有了这三个锦囊，再也不用担心微服务治理了 一文理解微服务高可用的常用手段 微服务断路器模式实现：Istio vs Hystrix  ","permalink":"https://cloudnative.to/blog/microservices-ha-practice/","tags":["service mesh","Microservices","Spring Cloud"],"title":"混合微服务高可用在企业级生产中的实践"},{"categories":["其他"],"contents":"2020 年伊始，受新冠疫情影响，全球各地的员工开启了在家办公的模式，因此人与人之间的距离感觉被拉远了。但是云原生圈子里有我们这样一群人，因为一个共同的愿景聚集到了一起，组建了社区管理委员会，并在过去的三个月里利用业余时间，齐心协力完成了社区的筹备工作。今天我们要正式宣布云原生社区正式成立了。\n成立背景  Software is eating the world. —— Marc Andreessen\n “软件正在吞噬这个世界” 已被大家多次引用，随着云原生（Cloud Native）的崛起，我们想说的是“Cloud Native is eating the software”。随着越来越多的企业将服务迁移上云，企业原有的开发模式以及技术架构已无法适应云的应用场景，其正在被重塑，向着云原生的方向演进。\n那么什么是云原生？云原生是一系列架构、研发流程、团队文化的最佳实践组合，以此支撑更快的创新速度、极致的用户体验、稳定可靠的用户服务、高效的研发效率。开源社区与云原生的关系密不可分，正是开源社区尤其是终端用户社区的存在，极大地促进了以容器、服务网格、微服务等为代表的云原生技术的持续演进！\n随着云计算的不断发展，云原生技术在全球范围内变得越来越受关注，同时国内社区同学也展现了对云原生技术热爱。近些年中国已经孕育众多的云原生技术爱好者，也有自发组织的一些相关技术交流和 meetup，同时在云原生领域也涌现了众多优秀的开源项目，在这样的背景下，一个有理想，有组织，有温度的云原生社区应运而生。\n关于云原生社区 云原生社区是一个有技术、有温度、有情怀的开源社区。由一群开源的狂热爱好者自发成立，秉持“共识、共治、共建、共享”的原则。社区的宗旨是：连接、中立、开源。立足中国，面向世界，企业中立，关注开源，回馈开源。\n关于云原生社区初创成员请查看初创成员列表。\n加入云原生社区，你将获得：\n 更接近源头的知识资讯 更富有价值的人际网络 更专业个性的咨询解答 更亲近意见领袖的机会 更快速高效的个人成长 更多知识分享曝光机会 更多行业人才挖掘发现  加入社区 云原生社区免费申请加入，关注云原生社区官方微信公众号，在公众号中回复关键词 加入，即可获得申请链接。\n","permalink":"https://cloudnative.to/blog/cnc-announcement/","tags":["社区"],"title":"云原生社区成立"},{"categories":null,"contents":"招聘对象 本次实习生招聘的要求为 将于 2021 年毕业且可以在 2020 年来实习的同学。\n岗位类型 研发类：操作系统、虚拟化、容器、安全、网络等方向，Go、Rust、C/C++、Java 等语言\n蚂蚁集团可信原生技术部介绍 蚂蚁集团可信原生技术部(TNT)是蚂蚁集团的计算基础设施的维护者，领域涵盖操作系统与虚拟化、容器与调度系统、网络与服务网格、中间件与平台服务等，更肩负着面向金融和民生服务的全栈可信的使命。\n我们也是开源社区的重要贡献力量，这里有Kata Containers 的创始团队，这里维护着 MOSN、SOFAStack、Occlum 等开源项目，还是 Kubernetes、Istio 等开源社区的积极贡献者。我们期待着你的加入。\n招聘流程 简历投递 -\u0026gt; 在线笔试及测评 -\u0026gt; 面试 -\u0026gt; 发放 offer -\u0026gt; 实习入职\nTips\n 一位同学不可以同时面好几个部门，进入哪个部门的招聘流程以同学首次确认的内推部门链接为准。 可以登录阿里巴巴集团招聘官网 https://job.alibaba.com 个人中心查看招聘进展。  实习与转正 拿到 offer 就可以正式入职，实习时长将根据同学的情况和业务实际情况进行安排，具体时间可以跟主管或 HR 商量。我们会在 8 到 9 月安排实习生转正面试，通过就会发放校招正式 offer！\n投递简历 请跳转到联系页面，填写表格，或者扫描二维码添加微信与我联系，欢迎邮件简历并说明对应的组，我们将尽快安排面试。\n关于蚂蚁集团云原生团队 蚂蚁集团云原生团队是服务于整个蚂蚁集团集团的核心技术团队，打造了世界领先的金融级分布式基础架构平台，拥有世界规模最大的 Kubernetes 集群，是 Service Mesh 领域的破局者和引路人，同时在积极探索 Serverless 领域，并将持续在云原生领域探索和深耕。\n","permalink":"https://cloudnative.to/job/intern-tnt/","tags":null,"title":"[实习生招聘] 蚂蚁集团可信原生技术部"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/art-institute.1/","tags":null,"title":"Art Institute of Chicago"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/art-institute/","tags":null,"title":"Art Institute of Chicago"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/carpe-diem/","tags":null,"title":"Carpe Diem Santorini"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/carryyip/","tags":null,"title":"Carry Yip"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/celebrate-with/","tags":null,"title":"Celebrate with Stoli"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/essential-looks.1/","tags":null,"title":"Essential Looks Trend Report"},{"categories":null,"contents":"Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit.\nQuia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\nBenifits of service Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n Quality Services Clients Satisfaction Quality Services Clients Satisfaction Quality Services Clients Satisfaction  Business Strategy Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia dese runt mollit anim id est laborum. sed ut perspiciatis unde omnis iste natus error sit voluptatem acusantium.\n Quality Services Clients Satisfaction Quality Services  Analyze your business Quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam.\n","permalink":"https://cloudnative.to/project/essential-looks/","tags":null,"title":"Essential Looks Trend Report"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/zhangliying/","tags":null,"title":"张丽颖"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/cherylhuang/","tags":null,"title":"Cheryl Hung"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/nipengfei/","tags":null,"title":"倪朋飞"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/jimmysong/","tags":null,"title":"宋净超（Jimmy Song）"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/suwei/","tags":null,"title":"粟伟"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/luoguangming/","tags":null,"title":"罗广明"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/dongyitao/","tags":null,"title":"董一韬"},{"categories":null,"contents":"","permalink":"https://cloudnative.to/team/longheng/","tags":null,"title":"龙恒"}]